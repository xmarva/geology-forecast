{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":95697,"databundleVersionId":11372669,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.auto import tqdm\nfrom scipy.special import logsumexp\nfrom collections import OrderedDict\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.signal import savgol_filter\nfrom scipy.ndimage import gaussian_filter1d\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\n\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:27.005368Z","iopub.execute_input":"2025-04-20T17:32:27.005532Z","iopub.status.idle":"2025-04-20T17:32:36.912564Z","shell.execute_reply.started":"2025-04-20T17:32:27.005516Z","shell.execute_reply":"2025-04-20T17:32:36.911810Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nSEED = 42\nseed_everything(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:36.913337Z","iopub.execute_input":"2025-04-20T17:32:36.913568Z","iopub.status.idle":"2025-04-20T17:32:36.922389Z","shell.execute_reply.started":"2025-04-20T17:32:36.913547Z","shell.execute_reply":"2025-04-20T17:32:36.921878Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def init_wandb(project_name=\"geology-forecast-challenge-sweep-gpu-bayes-30\", config=None):\n    if wandb.run is not None:\n        return wandb.run\n    try:\n        user_secrets = UserSecretsClient()\n        \n        wandb_api_key = user_secrets.get_secret(\"wandb\")\n        os.environ['WANDB_API_KEY'] = wandb_api_key\n        \n        wandb.login(key=wandb_api_key)\n        \n        run = wandb.init(\n            project=project_name,\n            config=config,\n            tags=[\"LSTM\", \"Geology Forecast Challenge\", \"Feature Engineering\"],\n            reinit=True\n        )\n        \n        print(\"W&B successfully initialized\")\n        return run\n    \n    except Exception as e:\n        print(f\"Error initializing W&B: {str(e)}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:36.924042Z","iopub.execute_input":"2025-04-20T17:32:36.924330Z","iopub.status.idle":"2025-04-20T17:32:36.939511Z","shell.execute_reply.started":"2025-04-20T17:32:36.924307Z","shell.execute_reply":"2025-04-20T17:32:36.938920Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:36.940027Z","iopub.execute_input":"2025-04-20T17:32:36.940202Z","iopub.status.idle":"2025-04-20T17:32:37.014038Z","shell.execute_reply.started":"2025-04-20T17:32:36.940188Z","shell.execute_reply":"2025-04-20T17:32:37.013294Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/geology-forecast-challenge-open/data/train.csv\").fillna(0)\ntest = pd.read_csv(\"/kaggle/input/geology-forecast-challenge-open/data/test.csv\").fillna(0)\nsub = pd.read_csv('/kaggle/input/geology-forecast-challenge-open/data/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:37.014909Z","iopub.execute_input":"2025-04-20T17:32:37.015134Z","iopub.status.idle":"2025-04-20T17:32:39.633685Z","shell.execute_reply.started":"2025-04-20T17:32:37.015110Z","shell.execute_reply":"2025-04-20T17:32:39.632757Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"FEATURES = [c for c in test.columns if c != 'geology_id']\nTARGETS = [c for c in sub.columns if c != 'geology_id']\nsolution = train[['geology_id'] + TARGETS].copy()\ntrain_sub = train[['geology_id'] + TARGETS].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.634639Z","iopub.execute_input":"2025-04-20T17:32:39.635021Z","iopub.status.idle":"2025-04-20T17:32:39.702598Z","shell.execute_reply.started":"2025-04-20T17:32:39.634995Z","shell.execute_reply":"2025-04-20T17:32:39.701786Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def engineer_features(data, is_test=False):\n    feature_data = pd.DataFrame({'geology_id': data['geology_id']})\n    \n    historical_cols = [col for col in data.columns if col != 'geology_id' and col.startswith('-') or col == '0']\n    \n    historical_cols.sort(key=lambda x: int(x) if x.isdigit() else int(x))\n    \n    historical_data = data[historical_cols].values\n    \n    # 1. Calculate local slopes (first derivative)\n    slopes = np.zeros_like(historical_data)\n    for i in range(1, historical_data.shape[1]):\n        slopes[:, i] = historical_data[:, i] - historical_data[:, i-1]\n    \n    # 2. Calculate curvature (second derivative)\n    curvature = np.zeros_like(historical_data)\n    for i in range(1, slopes.shape[1]-1):\n        curvature[:, i] = slopes[:, i+1] - slopes[:, i]\n    \n    # 3. Create rolling statistics for last N points\n    window_sizes = [5, 10, 20]\n    for window in window_sizes:\n\n        if historical_data.shape[1] >= window:\n            \n            feature_data[f'mean_last_{window}'] = np.mean(historical_data[:, -window:], axis=1)\n            feature_data[f'std_last_{window}'] = np.std(historical_data[:, -window:], axis=1)\n\n            x = np.arange(window)\n            \n            for i in range(historical_data.shape[0]):\n                \n                y = historical_data[i, -window:]\n                \n                if np.all(y == 0):\n                    feature_data.loc[i, f'trend_last_{window}'] = 0\n                else:\n                    slope = np.polyfit(x, y, 1)[0]\n                    feature_data.loc[i, f'trend_last_{window}'] = slope\n    \n    # 4. Calculate smoothed versions of data (different levels of smoothing)\n    smooth_windows = [3, 5, 9]\n    for window in smooth_windows:\n        # Savitzky-Golay filter requires window_length > polyorder\n        if window <= 3: \n            continue\n        \n        if historical_data.shape[1] >= window:\n            sg_window = window if window % 2 == 1 else window + 1\n            \n            for i in range(historical_data.shape[0]):\n                data_slice = historical_data[i, -50:]\n                if len(data_slice) >= sg_window:\n                    try:\n                        polyorder = 2 if sg_window <= 5 else 3\n                        smoothed = savgol_filter(data_slice, sg_window, polyorder, mode='nearest')\n                        feature_data.loc[i, f'sg_smooth_{window}'] = smoothed[-1]\n                        \n                        if len(smoothed) >= 3:\n                            feature_data.loc[i, f'sg_smooth_slope_{window}'] = smoothed[-1] - smoothed[-2]\n                    except Exception as e:\n                        feature_data.loc[i, f'sg_smooth_{window}'] = data_slice[-1]\n                        if len(data_slice) >= 3:\n                            feature_data.loc[i, f'sg_smooth_slope_{window}'] = data_slice[-1] - data_slice[-2]\n                else:\n                    feature_data.loc[i, f'sg_smooth_{window}'] = historical_data[i, -1] if historical_data.shape[1] > 0 else 0\n                    feature_data.loc[i, f'sg_smooth_slope_{window}'] = 0\n    \n    # 5. Calculate frequency-domain features (FFT-based)\n    if historical_data.shape[1] >= 32: \n        for i in range(historical_data.shape[0]):\n            fft_vals = np.abs(np.fft.rfft(historical_data[i, -32:]))\n            feature_data.loc[i, 'dominant_freq'] = np.argmax(fft_vals[1:]) + 1 if len(fft_vals) > 1 else 0\n            feature_data.loc[i, 'dominant_power'] = np.max(fft_vals[1:]) if len(fft_vals) > 1 else 0\n            feature_data.loc[i, 'total_power'] = np.sum(fft_vals[1:]) if len(fft_vals) > 1 else 0\n    \n    # 6. Detect potential fault indicators\n    if historical_data.shape[1] >= 5:\n        max_changes = []\n        for i in range(historical_data.shape[0]):\n            max_change = 0\n            for j in range(historical_data.shape[1] - 5):\n                change = np.max(historical_data[i, j:j+5]) - np.min(historical_data[i, j:j+5])\n                max_change = max(max_change, change)\n            max_changes.append(max_change)\n        feature_data['max_change_5pt'] = max_changes\n    \n    # 7. Calculate geological dip angle features\n    if historical_data.shape[1] >= 10:\n        dips = []\n        for i in range(historical_data.shape[0]):\n            # Use linear regression to find dip angle\n            x = np.arange(10)\n            y = historical_data[i, -10:]\n            slope = np.polyfit(x, y, 1)[0]\n            # Convert to degrees (slope is rise/run, arctangent gives angle)\n            dip_angle = np.degrees(np.arctan(slope))\n            dips.append(dip_angle)\n        feature_data['dip_angle'] = dips\n    \n    # 8. Add the raw historical data (last 50 points)\n    for i in range(min(50, historical_data.shape[1])):\n        feature_data[f'raw_{i}'] = historical_data[:, -(i+1)]\n    \n    # 9. Create interaction features from important raw features\n    if 'mean_last_5' in feature_data.columns and 'trend_last_10' in feature_data.columns:\n        feature_data['mean_trend_interaction'] = feature_data['mean_last_5'] * feature_data['trend_last_10']\n    \n    if 'dip_angle' in feature_data.columns and 'max_change_5pt' in feature_data.columns:\n        feature_data['dip_change_interaction'] = feature_data['dip_angle'] * feature_data['max_change_5pt']\n\n    # 10. Non-linear transformations of important features\n    for col in feature_data.columns:\n        if col != 'geology_id' and not col.startswith('raw_'):\n            feature_data[f'{col}_squared'] = feature_data[col] ** 2\n            # Log transform for any potentially positive-only features\n            if np.all(feature_data[col] > 0):\n                feature_data[f'{col}_log'] = np.log1p(feature_data[col])\n    \n    # Add the original features as well\n    for col in historical_cols:\n        feature_data[col] = data[col]\n    \n    return feature_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.703473Z","iopub.execute_input":"2025-04-20T17:32:39.703701Z","iopub.status.idle":"2025-04-20T17:32:39.720349Z","shell.execute_reply.started":"2025-04-20T17:32:39.703683Z","shell.execute_reply":"2025-04-20T17:32:39.719689Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class LSTMForecastModel(nn.Module):\n    def __init__(\n        self,\n        input_size,\n        hidden_size,\n        num_layers,\n        output_size,\n        dropout=0.2,\n    ):\n        super().__init__()\n        \n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0,\n        )\n        \n        self.layer_norm = nn.LayerNorm(hidden_size)\n        \n        self.fc1 = nn.Linear(hidden_size, hidden_size)\n        self.dropout = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_size, output_size)\n        self.activation = nn.GELU()\n        \n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        \n        lstm_out = lstm_out[:, -1, :]\n        \n        lstm_out = self.layer_norm(lstm_out)\n        \n        x = self.fc1(lstm_out)\n        x = self.activation(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.721245Z","iopub.execute_input":"2025-04-20T17:32:39.721573Z","iopub.status.idle":"2025-04-20T17:32:39.738861Z","shell.execute_reply.started":"2025-04-20T17:32:39.721554Z","shell.execute_reply":"2025-04-20T17:32:39.738197Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class TransformerForecastModel(nn.Module):\n    def __init__(\n        self,\n        input_size,\n        d_model=512,\n        nhead=8,\n        num_layers=4,\n        dim_feedforward=2048,\n        dropout=0.1,\n        output_size=300\n    ):\n        super().__init__()\n        \n        self.input_projection = nn.Linear(input_size, d_model)\n        \n        self.pos_encoder = PositionalEncoding(d_model, dropout)\n        \n        encoder_layers = nn.TransformerEncoderLayer(\n            d_model=d_model, \n            nhead=nhead, \n            dim_feedforward=dim_feedforward, \n            dropout=dropout,\n            batch_first=True\n        )\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n        \n        self.output_layer = nn.Sequential(\n            nn.Linear(d_model, d_model // 2),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(d_model // 2, output_size)\n        )\n        \n    def forward(self, x):\n        \n        x = self.input_projection(x)\n        \n        x = self.pos_encoder(x)\n        \n        transformer_output = self.transformer_encoder(x)\n\n        output = self.output_layer(transformer_output[:, -1, :])\n        \n        return output\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout=0.1, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(max_len, d_model)\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:x.size(1)]\n        return self.dropout(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.741020Z","iopub.execute_input":"2025-04-20T17:32:39.741240Z","iopub.status.idle":"2025-04-20T17:32:39.757991Z","shell.execute_reply.started":"2025-04-20T17:32:39.741224Z","shell.execute_reply":"2025-04-20T17:32:39.757325Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class TCNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout=0.2):\n        super().__init__()\n        \n        # Padding для сохранения размерности\n        padding = (kernel_size - 1) * dilation\n        \n        self.conv = nn.Conv1d(\n            in_channels, \n            out_channels, \n            kernel_size, \n            padding=padding, \n            dilation=dilation\n        )\n        \n        self.relu = nn.GELU()\n        self.dropout = nn.Dropout(dropout)\n        \n        self.residual = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n        \n        self.layer_norm = nn.LayerNorm(out_channels)\n        \n    def forward(self, x):\n        residual = self.residual(x)\n        \n        out = self.conv(x)\n        \n        out = out[:, :, :-self.conv.padding[0]]\n        \n        out = out + residual\n        \n        out = self.relu(out)\n        out = self.dropout(out)\n        \n        out = out.permute(0, 2, 1)\n        out = self.layer_norm(out)\n        out = out.permute(0, 2, 1) \n        \n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.758749Z","iopub.execute_input":"2025-04-20T17:32:39.759015Z","iopub.status.idle":"2025-04-20T17:32:39.775413Z","shell.execute_reply.started":"2025-04-20T17:32:39.758999Z","shell.execute_reply":"2025-04-20T17:32:39.774758Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class TCNForecastModel(nn.Module):\n    def __init__(\n        self,\n        input_size,\n        hidden_size=128,\n        kernel_size=3,\n        num_layers=8,\n        dropout=0.2,\n        output_size=300\n    ):\n        super().__init__()\n        \n        self.input_projection = nn.Linear(input_size, hidden_size)\n        \n        self.tcn_blocks = nn.ModuleList()\n        for i in range(num_layers):\n            dilation = 2 ** i  # 1, 2, 4, 8, ...\n            self.tcn_blocks.append(\n                TCNBlock(hidden_size, hidden_size, kernel_size, dilation, dropout)\n            )\n        \n        self.output_layer = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_size, output_size)\n        )\n        \n    def forward(self, x):\n        x = self.input_projection(x)\n        \n        x = x.permute(0, 2, 1)\n        \n        for block in self.tcn_blocks:\n            x = block(x)\n        \n        x = x[:, :, -1]\n        \n        x = self.output_layer(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.775949Z","iopub.execute_input":"2025-04-20T17:32:39.776112Z","iopub.status.idle":"2025-04-20T17:32:39.787721Z","shell.execute_reply.started":"2025-04-20T17:32:39.776099Z","shell.execute_reply":"2025-04-20T17:32:39.787198Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class HybridCNNLSTMModel(nn.Module):\n    def __init__(\n        self,\n        input_size,\n        cnn_filters=[64, 128, 128, 256],\n        kernel_size=3,\n        lstm_hidden=512,\n        lstm_layers=2,\n        dropout=0.2,\n        output_size=300\n    ):\n        super().__init__()\n        \n        self.cnn_layers = nn.ModuleList()\n        \n        self.cnn_layers.append(nn.Conv1d(input_size, cnn_filters[0], kernel_size, padding=kernel_size//2))\n        \n        for i in range(1, len(cnn_filters)):\n            self.cnn_layers.append(\n                nn.Conv1d(cnn_filters[i-1], cnn_filters[i], kernel_size, padding=kernel_size//2)\n            )\n        \n        self.batch_norms = nn.ModuleList([\n            nn.BatchNorm1d(filters) for filters in cnn_filters\n        ])\n        \n        self.act = nn.GELU()\n        self.dropout = nn.Dropout(dropout)\n        \n        self.lstm = nn.LSTM(\n            input_size=cnn_filters[-1],\n            hidden_size=lstm_hidden,\n            num_layers=lstm_layers,\n            batch_first=True,\n            dropout=dropout if lstm_layers > 1 else 0,\n            bidirectional=True \n        )\n        \n        self.layer_norm = nn.LayerNorm(lstm_hidden * 2) \n        \n        self.output_layer = nn.Sequential(\n            nn.Linear(lstm_hidden * 2, lstm_hidden),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(lstm_hidden, output_size)\n        )\n        \n    def forward(self, x):\n        x = x.permute(0, 2, 1)\n        \n        for i, (conv, bn) in enumerate(zip(self.cnn_layers, self.batch_norms)):\n            x = conv(x)\n            x = bn(x)\n            x = self.act(x)\n            x = self.dropout(x)\n        \n        x = x.permute(0, 2, 1)\n        \n        lstm_out, _ = self.lstm(x)\n        \n        lstm_out = lstm_out[:, -1, :]\n        \n        lstm_out = self.layer_norm(lstm_out)\n\n        x = self.output_layer(lstm_out)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.788430Z","iopub.execute_input":"2025-04-20T17:32:39.788666Z","iopub.status.idle":"2025-04-20T17:32:39.806631Z","shell.execute_reply.started":"2025-04-20T17:32:39.788645Z","shell.execute_reply":"2025-04-20T17:32:39.805914Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class GeologyDataset(Dataset):\n    def __init__(self, features, targets=None, is_test=False, scale_features=True):\n        self.features = features\n        self.targets = targets\n        self.is_test = is_test\n        \n        if scale_features:\n            self.feature_scaler = StandardScaler()\n            self.features = self.feature_scaler.fit_transform(self.features)\n        \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        x = self.features[idx]\n        \n        x = x.reshape(-1, 1)\n        \n        if self.is_test:\n            return x\n        else:\n            y = self.targets[idx]\n            return x, y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.807359Z","iopub.execute_input":"2025-04-20T17:32:39.807553Z","iopub.status.idle":"2025-04-20T17:32:39.822370Z","shell.execute_reply.started":"2025-04-20T17:32:39.807532Z","shell.execute_reply":"2025-04-20T17:32:39.821793Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def preprocess_data(df, engineered_features=None, target_cols=None, is_test=False):\n    if engineered_features is None:\n        # If no engineered features provided, use raw data\n        feature_cols = [c for c in df.columns if c != 'geology_id' and (c.startswith('-') or c == '0')]\n        X = df[feature_cols].values\n    else:\n        # Use the engineered features, dropping the ID column\n        X = engineered_features.drop('geology_id', axis=1).values\n    \n    if not is_test:\n        y = df[target_cols].values\n        return X, y\n    \n    return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.822968Z","iopub.execute_input":"2025-04-20T17:32:39.823130Z","iopub.status.idle":"2025-04-20T17:32:39.839340Z","shell.execute_reply.started":"2025-04-20T17:32:39.823118Z","shell.execute_reply":"2025-04-20T17:32:39.838726Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def compute_nll_score(solution, submission, row_id_column_name='geology_id'):\n    solution_copy = solution.copy()\n    submission_copy = submission.copy()\n    \n    del solution_copy[row_id_column_name]\n    del submission_copy[row_id_column_name]\n\n    NEGATIVE_PART = -299\n    LARGEST_CHUNK = 600\n    SMALLEST_CHUNK = 350\n    TOTAL_REALIZATIONS = 10\n    INFLATION_SIGMA = 600\n    \n    sigma_2 = np.ones((LARGEST_CHUNK+NEGATIVE_PART-1))\n    from_ranges = [1, 61, 245]\n    to_ranges_excl = [61, 245, 301]\n    log_slopes = [1.0406028049510443, 0.0, 7.835345062351012]\n    log_offsets = [-6.430669850650689, -2.1617411566043896, -45.24876794412965]\n\n    for growth_mode in range(len(from_ranges)):\n        for i in range(from_ranges[growth_mode], to_ranges_excl[growth_mode]):\n            sigma_2[i-1] = np.exp(np.log(i)*log_slopes[growth_mode]+log_offsets[growth_mode])\n\n    sigma_2 *= INFLATION_SIGMA\n  \n    cov_matrix_inv_diag = 1. / sigma_2\n    \n    num_rows = solution_copy.shape[0]\n    num_columns = LARGEST_CHUNK + NEGATIVE_PART - 1\n    \n    p = 1./TOTAL_REALIZATIONS\n    log_p = np.log(p)\n    \n    solution_arr = np.zeros((num_rows, TOTAL_REALIZATIONS, num_columns))\n    submission_arr = np.zeros((num_rows, TOTAL_REALIZATIONS, num_columns))\n    \n    for k in range(TOTAL_REALIZATIONS):\n        for i in range(num_columns):\n            if k == 0:\n                column_name = str(i+1)\n            else:\n                column_name = f\"r_{k}_pos_{i+1}\"\n            solution_arr[:, k, i] = solution_copy[column_name].values\n            submission_arr[:, k, i] = submission_copy[column_name].values\n\n    misfit = solution_arr - submission_arr\n    inner_product_matrix = np.sum(cov_matrix_inv_diag * misfit * misfit, axis=2)\n    \n    nll = -logsumexp(log_p - inner_product_matrix, axis=1)\n    \n    return nll.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.839966Z","iopub.execute_input":"2025-04-20T17:32:39.840211Z","iopub.status.idle":"2025-04-20T17:32:39.854983Z","shell.execute_reply.started":"2025-04-20T17:32:39.840191Z","shell.execute_reply":"2025-04-20T17:32:39.854323Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def train_model_with_nll_loss(model, train_loader, optimizer, device, epoch=0, total_epochs=30):\n    model.train()\n    train_losses = []\n    \n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{total_epochs}\")\n    \n    for data, target in pbar:\n        data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.float32)\n        \n        optimizer.zero_grad()\n        output = model(data)\n        \n        target_mean = target.mean(dim=0)\n        target_std = target.std(dim=0) + 1e-6\n        \n        normalized_output = (output - target_mean) / target_std\n        normalized_target = (target - target_mean) / target_std\n        \n        loss = F.mse_loss(normalized_output, normalized_target)\n        \n        if output.shape[1] > 1:\n            smoothness_penalty = torch.mean(torch.abs(output[:, 1:] - output[:, :-1]))\n            loss += 0.01 * smoothness_penalty\n        \n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        pbar.set_postfix({'loss': f\"{loss.item():.6f}\"})\n    \n    return np.mean(train_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.855676Z","iopub.execute_input":"2025-04-20T17:32:39.855888Z","iopub.status.idle":"2025-04-20T17:32:39.873539Z","shell.execute_reply.started":"2025-04-20T17:32:39.855874Z","shell.execute_reply":"2025-04-20T17:32:39.872918Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def validate_model(model, val_loader, device):\n    model.eval()\n    val_losses = []\n    val_preds = []\n    val_targets = []\n    \n    with torch.no_grad():\n        for data, target in tqdm(val_loader, desc=\"Validating\"):\n            data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.float32)\n            output = model(data)\n            \n            target_mean = target.mean(dim=0)\n            target_std = target.std(dim=0) + 1e-6\n            \n            normalized_output = (output - target_mean) / target_std\n            normalized_target = (target - target_mean) / target_std\n            \n            loss = F.mse_loss(normalized_output, normalized_target)\n            \n            val_losses.append(loss.item())\n            val_preds.append(output.cpu().numpy())\n            val_targets.append(target.cpu().numpy())\n    \n    val_preds = np.concatenate(val_preds)\n    val_targets = np.concatenate(val_targets)\n    \n    return np.mean(val_losses), val_preds, val_targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.874323Z","iopub.execute_input":"2025-04-20T17:32:39.874522Z","iopub.status.idle":"2025-04-20T17:32:39.892421Z","shell.execute_reply.started":"2025-04-20T17:32:39.874505Z","shell.execute_reply":"2025-04-20T17:32:39.891714Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def generate_diverse_realizations(base_predictions, num_samples=10, diversity_factor=0.2):\n    num_rows, num_cols = base_predictions.shape\n    realizations = np.zeros((num_samples, num_rows, num_cols))\n\n    realizations[0] = base_predictions\n\n    for i in range(1, num_samples):\n        realization = base_predictions.copy()\n        \n        for j in range(num_rows):\n            noise = np.random.normal(0, diversity_factor, num_cols)\n            \n            smoothed_noise = gaussian_filter1d(noise, sigma=5.0)\n            \n            position_factor = np.linspace(0.1, 1.0, num_cols)\n            scaled_noise = smoothed_noise * position_factor\n            \n            realization[j] += scaled_noise\n\n            for k in range(1, num_cols):\n\n                max_change = 2.0 * (k/num_cols + 0.1)  # Allow larger changes further away\n                diff = realization[j, k] - realization[j, k-1]\n                if abs(diff) > max_change:\n                    realization[j, k] = realization[j, k-1] + np.sign(diff) * max_change\n        \n        realizations[i] = realization\n    \n    return realizations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.893333Z","iopub.execute_input":"2025-04-20T17:32:39.893738Z","iopub.status.idle":"2025-04-20T17:32:39.910877Z","shell.execute_reply.started":"2025-04-20T17:32:39.893716Z","shell.execute_reply":"2025-04-20T17:32:39.910285Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def generate_fold_realizations(base_predictions, num_realizations=10):\n    realizations = generate_diverse_realizations(\n        base_predictions, \n        num_samples=num_realizations,\n        diversity_factor=0.15  # Control the diversity level\n    )\n    return realizations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.911544Z","iopub.execute_input":"2025-04-20T17:32:39.911773Z","iopub.status.idle":"2025-04-20T17:32:39.928335Z","shell.execute_reply.started":"2025-04-20T17:32:39.911757Z","shell.execute_reply":"2025-04-20T17:32:39.927712Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def visualize_features(train_features, y):\n    feature_cols = [col for col in train_features.columns if col != 'geology_id']\n    \n    target_cols = [str(i) for i in range(1, 11)]\n    target_cols = [col for col in target_cols if col in train.columns]\n    \n    correlations = []\n    for tcol in target_cols:\n        if tcol in train.columns:\n            for fcol in feature_cols:\n                corr = np.corrcoef(train_features[fcol], train[tcol])[0, 1]\n                correlations.append((fcol, tcol, abs(corr)))\n    \n    top_correlations = sorted(correlations, key=lambda x: x[2], reverse=True)[:15]\n    \n    plt.figure(figsize=(12, 8))\n    plot_data = pd.DataFrame(top_correlations, columns=['Feature', 'Target', 'Correlation'])\n    sns.barplot(data=plot_data, x='Correlation', y='Feature', hue='Target')\n    plt.title('Top Feature Correlations with Targets')\n    plt.tight_layout()\n    \n    try:\n        wandb.log({\"feature_correlations\": wandb.Image(plt)})\n    except:\n        pass\n    \n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.929376Z","iopub.execute_input":"2025-04-20T17:32:39.929594Z","iopub.status.idle":"2025-04-20T17:32:39.938796Z","shell.execute_reply.started":"2025-04-20T17:32:39.929576Z","shell.execute_reply":"2025-04-20T17:32:39.937987Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def get_default_config(model_type):    \n    if model_type == 'LSTM':\n        return {\n            'model_type': 'LSTM',\n            'hidden_size': 512,\n            'num_layers': 2,\n            'dropout': 0.2,\n            'learning_rate': 5e-4,\n            'weight_decay': 1e-5,\n            'batch_size': 128,\n            'epochs': 50,\n            'seed': SEED,\n            'feature_engineering': 'advanced',\n            'optimizer': 'adamw',\n            'scheduler': 'onecycle'\n        }\n    elif model_type == 'Transformer':\n        return {\n            'model_type': 'Transformer',\n            'd_model': 512,\n            'nhead': 8,\n            'num_layers': 4,\n            'dim_feedforward': 1024,\n            'dropout': 0.2,\n            'learning_rate': 4e-4,\n            'weight_decay': 1e-5,\n            'batch_size': 128,\n            'epochs': 50,\n            'seed': SEED,\n            'feature_engineering': 'advanced',\n            'optimizer': 'adamw',\n            'scheduler': 'cosine'\n        }\n    elif model_type == 'TCN':\n        return {\n            'model_type': 'TCN',\n            'hidden_size': 256,\n            'kernel_size': 3,\n            'num_layers': 8,\n            'dropout': 0.2,\n            'learning_rate': 5e-4,\n            'weight_decay': 1e-5,\n            'batch_size': 128,\n            'epochs': 50,\n            'seed': SEED,\n            'feature_engineering': 'advanced',\n            'optimizer': 'adam',\n            'scheduler': 'onecycle'\n        }\n    elif model_type == 'HybridCNNLSTM':\n        return {\n            'model_type': 'HybridCNNLSTM',\n            'cnn_filters': [64, 128, 128, 256],\n            'kernel_size': 3,\n            'hidden_size': 512,\n            'num_layers': 2,\n            'dropout': 0.3,\n            'learning_rate': 3e-4,\n            'weight_decay': 1e-5,\n            'batch_size': 128,\n            'epochs': 60,\n            'seed': SEED,\n            'feature_engineering': 'advanced',\n            'optimizer': 'adamw',\n            'scheduler': 'cosine'\n        }\n    else:\n        raise ValueError(f\"Неизвестный тип модели: {model_type}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.939521Z","iopub.execute_input":"2025-04-20T17:32:39.939727Z","iopub.status.idle":"2025-04-20T17:32:39.959193Z","shell.execute_reply.started":"2025-04-20T17:32:39.939712Z","shell.execute_reply":"2025-04-20T17:32:39.958503Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def create_model(config, device):\n    model_type = config['model_type']\n    input_features_size = 1 \n    output_size = 3000\n    \n    if model_type == 'LSTM':\n        model = LSTMForecastModel(\n            input_size=input_features_size,\n            hidden_size=config['hidden_size'],\n            num_layers=config['num_layers'],\n            output_size=output_size,\n            dropout=config['dropout']\n        )\n    elif model_type == 'Transformer':\n        model = TransformerForecastModel(\n            input_size=input_features_size,\n            d_model=config.get('d_model', 512),\n            nhead=config.get('nhead', 8),\n            num_layers=config['num_layers'],\n            dim_feedforward=config.get('dim_feedforward', 2048),\n            dropout=config['dropout'],\n            output_size=output_size\n        )\n    elif model_type == 'TCN':\n        model = TCNForecastModel(\n            input_size=input_features_size,\n            hidden_size=config['hidden_size'],\n            kernel_size=config.get('kernel_size', 3),\n            num_layers=config['num_layers'],\n            dropout=config['dropout'],\n            output_size=output_size\n        )\n    elif model_type == 'HybridCNNLSTM':\n        model = HybridCNNLSTMModel(\n            input_size=input_features_size,\n            cnn_filters=config.get('cnn_filters', [64, 128, 128, 256]),\n            kernel_size=config.get('kernel_size', 3),\n            lstm_hidden=config['hidden_size'],\n            lstm_layers=config['num_layers'],\n            dropout=config['dropout'],\n            output_size=output_size\n        )\n    else:\n        raise ValueError(f\"Неизвестный тип модели: {model_type}\")\n    \n    return model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.959987Z","iopub.execute_input":"2025-04-20T17:32:39.960689Z","iopub.status.idle":"2025-04-20T17:32:39.975459Z","shell.execute_reply.started":"2025-04-20T17:32:39.960662Z","shell.execute_reply":"2025-04-20T17:32:39.974830Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def train_and_predict_single_model(\n    X_train, \n    y_train,\n    X_val,\n    y_val,\n    X_test,\n    config,\n    run_name=None,\n    autofinish=True\n):\n    try:\n        run = init_wandb(project_name=run_name, config=config) if autofinish else wandb.run\n        \n        train_dataset = GeologyDataset(X_train, y_train)\n        val_dataset = GeologyDataset(X_val, y_val)\n        test_dataset = GeologyDataset(X_test, is_test=True)\n        \n        train_loader = DataLoader(\n            train_dataset, \n            batch_size=config['batch_size'], \n            shuffle=True,\n            pin_memory=True, \n            num_workers=2  \n        )\n        val_loader = DataLoader(\n            val_dataset, \n            batch_size=config['batch_size'], \n            shuffle=False,\n            pin_memory=True,\n            num_workers=2\n        )\n        test_loader = DataLoader(\n            test_dataset, \n            batch_size=config['batch_size'], \n            shuffle=False,\n            pin_memory=True,\n            num_workers=2\n        )\n        \n        model = create_model(config, device)\n        \n        if config.get('optimizer', 'adamw').lower() == 'adamw':\n            optimizer = optim.AdamW(\n                model.parameters(),\n                lr=config['learning_rate'],\n                weight_decay=config['weight_decay'],\n                eps=1e-8\n            )\n        elif config.get('optimizer', 'adamw').lower() == 'adam':\n            optimizer = optim.Adam(\n                model.parameters(),\n                lr=config['learning_rate'],\n                weight_decay=config['weight_decay'],\n                eps=1e-8\n            )\n        elif config.get('optimizer', 'adamw').lower() == 'sgd':\n            optimizer = optim.SGD(\n                model.parameters(),\n                lr=config['learning_rate'],\n                momentum=config.get('momentum', 0.9),\n                weight_decay=config['weight_decay']\n            )\n        \n        if config.get('scheduler', 'onecycle').lower() == 'onecycle':\n            steps_per_epoch = len(train_loader)\n            scheduler = optim.lr_scheduler.OneCycleLR(\n                optimizer,\n                max_lr=config['learning_rate'],\n                epochs=config['epochs'],\n                steps_per_epoch=steps_per_epoch,\n                pct_start=0.3,\n                div_factor=25,\n                final_div_factor=1000,\n            )\n        elif config.get('scheduler', 'onecycle').lower() == 'cosine':\n            scheduler = optim.lr_scheduler.CosineAnnealingLR(\n                optimizer, \n                T_max=config['epochs'] // 2,\n                eta_min=config['learning_rate'] / 1000\n            )\n        elif config.get('scheduler', 'onecycle').lower() == 'reduce':\n            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n                optimizer,\n                mode='min',\n                factor=0.5,\n                patience=5,\n                min_lr=config['learning_rate'] / 100\n            )\n        \n        best_val_loss = float('inf')\n        val_predictions = None\n        \n        # early stopping\n        patience = 5\n        counter = 0\n        min_delta = 1e-4\n        \n        print(f\"Training model {config['model_type']}...\")\n        for epoch in range(config['epochs']):\n            train_loss = train_model_with_nll_loss(\n                model, train_loader, optimizer, device, epoch, config['epochs']\n            )\n            \n            val_loss, val_preds, val_targets = validate_model(model, val_loader, device)\n            \n            val_predictions = val_preds\n            \n            if config.get('scheduler', 'onecycle').lower() in ['onecycle', 'cosine']:\n                scheduler.step()\n            elif config.get('scheduler', 'onecycle').lower() == 'reduce':\n                scheduler.step(val_loss)\n    \n            if run:\n                run.log({\n                    \"epoch\": epoch + 1,\n                    \"train_loss\": train_loss,\n                    \"val_loss\": val_loss,\n                    \"learning_rate\": optimizer.param_groups[0]['lr']\n                })\n            \n            print(f\"Epoch {epoch+1}/{config['epochs']} - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n            \n            # loss check\n            if epoch + 1 == 10 and val_loss > 1.0:\n                print(f\"Validation loss > 1.0 at epoch 10 ({val_loss:.6f}). Stopping training.\")\n                if run:\n                    run.log({\"early_stop_reason\": \"high_loss_at_epoch_10\", \"best_val_loss\": best_val_loss})\n                break\n            \n            if val_loss < best_val_loss:\n                best_val_loss = val_loss\n                model_path = f\"model_{config['model_type']}.pt\"\n                torch.save(model.state_dict(), model_path)\n                if run:\n                    run.save(model_path)\n                print(f\"Saved new best model with validation loss: {val_loss:.6f}\")\n                counter = 0 \n            else:\n\n                if val_loss > best_val_loss - min_delta:\n                    counter += 1\n                    if counter >= patience:\n                        print(f\"Early stopping triggered at epoch {epoch+1}. Best val_loss: {best_val_loss:.6f}\")\n                        if run:\n                            run.log({\"early_stop_reason\": \"no_improvement\", \"best_val_loss\": best_val_loss})\n                        break\n        \n        model.load_state_dict(torch.load(f\"model_{config['model_type']}.pt\"))\n        model.eval()\n        test_preds = []\n        \n        with torch.no_grad():\n            for data in tqdm(test_loader, desc=\"Predicting test data\"):\n                if isinstance(data, list):\n                    data = data[0]\n                data = data.to(device, dtype=torch.float32)\n                output = model(data)\n                test_preds.append(output.cpu().numpy())\n        \n        base_test_predictions = np.concatenate(test_preds)\n        \n        val_preds_df = pd.DataFrame(\n            data=val_predictions,\n            columns=TARGETS,\n        )\n        val_preds_df['geology_id'] = val_dataset.features[:, 0]\n        \n        val_solution_df = pd.DataFrame(\n            data=y_val,\n            columns=TARGETS,\n        )\n        val_solution_df['geology_id'] = val_dataset.features[:, 0]\n        \n        nll_score = compute_nll_score(val_solution_df, val_preds_df)\n        \n        if run and autofinish:\n            run.log({\"val_nll_score\": nll_score})\n            run.finish()\n        \n        return base_test_predictions, val_predictions, nll_score\n        \n    finally:\n        torch.cuda.empty_cache()\n        \n        from torch.utils.data import _utils\n        if hasattr(_utils.worker, \"_worker_pool\"):\n            _utils.worker._worker_pool.close()\n            _utils.worker._worker_pool.join()\n        elif hasattr(_utils.worker, \"_shutdown_all_workers\"):\n            _utils.worker._shutdown_all_workers()\n        \n        import gc\n        gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.976311Z","iopub.execute_input":"2025-04-20T17:32:39.976705Z","iopub.status.idle":"2025-04-20T17:32:39.994846Z","shell.execute_reply.started":"2025-04-20T17:32:39.976683Z","shell.execute_reply":"2025-04-20T17:32:39.994311Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def create_submission(base_predictions, config, val_nll_score):\n    submission = sub.copy()\n    \n    for i in range(300):\n        col_name = str(i+1)\n        submission[col_name] = base_predictions[:, i]\n    \n    realizations = generate_diverse_realizations(\n        base_predictions, \n        num_samples=10, \n        diversity_factor=0.15 + 0.05 * (config.get('diversity_factor', 1.0) - 1.0)\n    )\n    \n    for r_idx in range(1, 10): \n        for i in range(300):\n            col_name = f\"r_{r_idx}_pos_{i+1}\"\n            submission[col_name] = realizations[r_idx][:, i]\n    \n    submission_file = f\"submission_{config['model_type']}_{val_nll_score:.6f}.csv\"\n    submission.to_csv(submission_file, index=False)\n    print(f\"\\nSubmission file saved: {submission_file}\")\n    \n    expected_cols = sub.columns.tolist()\n    actual_cols = submission.columns.tolist()\n    \n    if set(expected_cols) != set(actual_cols):\n        print(\"WARNING: Submission columns don't match expected format!\")\n        missing = set(expected_cols) - set(actual_cols)\n        extra = set(actual_cols) - set(expected_cols)\n        if missing:\n            print(f\"Missing columns: {missing}\")\n        if extra:\n            print(f\"Extra columns: {extra}\")\n    else:\n        print(\"Submission format validated successfully!\")\n    \n    return submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:39.995543Z","iopub.execute_input":"2025-04-20T17:32:39.995769Z","iopub.status.idle":"2025-04-20T17:32:40.015127Z","shell.execute_reply.started":"2025-04-20T17:32:39.995754Z","shell.execute_reply":"2025-04-20T17:32:40.014593Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def visualize_model_predictions(submission, config, run=None):\n    try:\n        plt.figure(figsize=(15, 8))\n\n        sample_indices = [0, 10, 20]\n        \n        for sample_idx in sample_indices:\n            plt.figure(figsize=(15, 8))\n            \n            x_coords = np.arange(1, 301)\n            plt.plot(x_coords, submission.iloc[sample_idx, 1:301].values, \n                    color='blue', label='Baseline', linewidth=2)\n            \n            colors = ['red', 'green', 'purple']\n            for r in range(1, 4): \n                cols = [f\"r_{r}_pos_{i+1}\" for i in range(300)]\n                plt.plot(x_coords, submission.loc[submission.index[sample_idx], cols].values,\n                        color=colors[(r-1) % len(colors)], label=f'Realization {r}', alpha=0.7)\n            \n            plt.title(f\"{config['model_type']} - Sample {sample_idx}\")\n            plt.xlabel(\"Position\")\n            plt.ylabel(\"Layer Depth (Z coordinate)\")\n            plt.legend()\n            plt.grid(True, alpha=0.3)\n\n            if run:\n                run.log({f\"predictions_sample_{sample_idx}\": wandb.Image(plt)})\n            \n            plt.close()\n        \n    except Exception as e:\n        print(f\"Visualization error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.015750Z","iopub.execute_input":"2025-04-20T17:32:40.015989Z","iopub.status.idle":"2025-04-20T17:32:40.034691Z","shell.execute_reply.started":"2025-04-20T17:32:40.015973Z","shell.execute_reply":"2025-04-20T17:32:40.034044Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def split_train_val(X_features, y, val_size=0.2, random_state=42):\n    n_samples = len(X_features)\n    indices = np.arange(n_samples)\n    np.random.seed(random_state)\n    np.random.shuffle(indices)\n    \n    val_samples = int(val_size * n_samples)\n    val_indices = indices[:val_samples]\n    train_indices = indices[val_samples:]\n    \n    X_train = X_features[train_indices]\n    y_train = y[train_indices]\n    X_val = X_features[val_indices]\n    y_val = y[val_indices]\n    \n    return X_train, y_train, X_val, y_val, train_indices, val_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.035335Z","iopub.execute_input":"2025-04-20T17:32:40.035526Z","iopub.status.idle":"2025-04-20T17:32:40.054823Z","shell.execute_reply.started":"2025-04-20T17:32:40.035512Z","shell.execute_reply":"2025-04-20T17:32:40.054122Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def run_experiment(config, autofinish=False):\n    try:\n        seed_everything(config['seed'])\n        \n        print(f\"\\n{'='*50}\\nRunning experiment with {config['model_type']}\\n{'='*50}\")\n        print(f\"Config: {config}\")\n        \n        X_train, y_train, X_val, y_val, train_indices, val_indices = split_train_val(\n            X_features, y, val_size=0.2, random_state=config['seed']\n        )\n        \n        base_predictions, val_predictions, val_nll_score = train_and_predict_single_model(\n            X_train, y_train, X_val, y_val, X_features_test, config, autofinish\n        )\n        \n        train_sub.loc[val_indices, TARGETS] = val_predictions\n        \n        submission = create_submission(base_predictions, config, val_nll_score)\n    \n        visualize_model_predictions(submission, config)\n        \n        print(f\"Finished experiment with {config['model_type']}, validation NLL: {val_nll_score:.6f}\")\n        \n        return val_nll_score\n    \n    except RuntimeError as e:\n        if \"CUDA out of memory\" in str(e):\n            print(f\"CUDA OOM error with config: {config}\")\n            \n            if wandb.run is not None:\n                wandb.log({\"cuda_oom_error\": True, \"error_message\": str(e)})\n                \n            # Большое значение метрики, чтобы байесовский оптимизатор избегал таких конфигураций\n            return float('inf')\n        else:\n            raise e","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.058308Z","iopub.execute_input":"2025-04-20T17:32:40.058581Z","iopub.status.idle":"2025-04-20T17:32:40.070115Z","shell.execute_reply.started":"2025-04-20T17:32:40.058564Z","shell.execute_reply":"2025-04-20T17:32:40.069503Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def visualize_predictions(test_idx=0, num_realizations=3):\n    plt.figure(figsize=(15, 8))\n    \n    x_coords = np.arange(1, 301)\n    plt.plot(x_coords, submission.iloc[test_idx, 1:301].values, \n             color='blue', label='Realization 0', linewidth=2)\n    \n    colors = ['red', 'green', 'purple']\n    for r in range(1, min(num_realizations+1, 10)):\n        cols = [f\"r_{r}_pos_{i+1}\" for i in range(300)]\n        plt.plot(x_coords, submission.loc[submission.index[test_idx], cols].values,\n                color=colors[(r-1) % len(colors)], label=f'Realization {r}', alpha=0.7)\n    \n    plt.title(f\"Multiple Geological Sequence Realizations for Sample {test_idx}\")\n    plt.xlabel(\"Position\")\n    plt.ylabel(\"Layer Depth (Z coordinate)\")\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    try:\n        wandb.log({\"prediction_visualization\": wandb.Image(plt)})\n    except:\n        pass\n    \n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.070797Z","iopub.execute_input":"2025-04-20T17:32:40.070981Z","iopub.status.idle":"2025-04-20T17:32:40.088514Z","shell.execute_reply.started":"2025-04-20T17:32:40.070967Z","shell.execute_reply":"2025-04-20T17:32:40.087986Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def analyze_geological_patterns(submission_df, sample_indices=None, num_samples=5):\n    if sample_indices is None:\n        sample_indices = np.random.choice(len(submission_df), min(num_samples, len(submission_df)), replace=False)\n    \n    plt.figure(figsize=(18, 12))\n    \n    for idx, i in enumerate(sample_indices):\n        plt.subplot(len(sample_indices), 1, idx+1)\n        \n        base_pred = submission_df.iloc[i, 1:301].values\n        \n        slopes = np.diff(base_pred)\n        \n        threshold = np.std(slopes) * 2.5\n        fault_indicators = np.where(np.abs(slopes) > threshold)[0]\n        \n        plt.plot(range(1, 301), base_pred, 'b-', linewidth=2, label='Predicted Sequence')\n        \n        if len(fault_indicators) > 0:\n            plt.scatter([x+1 for x in fault_indicators], \n                       [base_pred[x] for x in fault_indicators],\n                       color='red', s=80, marker='x', label='Potential Fault/Change')\n        \n        segment_size = 50\n        for seg_start in range(0, 300, segment_size):\n            seg_end = min(seg_start + segment_size, 300)\n            if seg_end - seg_start > 10:  # Only fit if enough points\n                x_seg = np.arange(seg_start, seg_end)\n                y_seg = base_pred[seg_start:seg_end]\n                # Fit a line to this segment\n                z = np.polyfit(x_seg, y_seg, 1)\n                p = np.poly1d(z)\n                plt.plot(x_seg+1, p(x_seg), '--', linewidth=1.5, \n                         alpha=0.7, label=f'Trend (Seg {seg_start}-{seg_end})')\n        \n        plt.title(f\"Geological Analysis for Sample {i}\")\n        plt.xlabel(\"Position\")\n        plt.ylabel(\"Layer Depth (Z)\")\n        plt.grid(True, alpha=0.3)\n        if idx == 0:\n            plt.legend(loc='upper right')\n    \n    plt.tight_layout()\n\n    try:\n        wandb.log({\"geological_analysis\": wandb.Image(plt)})\n    except:\n        pass\n    \n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.089248Z","iopub.execute_input":"2025-04-20T17:32:40.089434Z","iopub.status.idle":"2025-04-20T17:32:40.104244Z","shell.execute_reply.started":"2025-04-20T17:32:40.089420Z","shell.execute_reply":"2025-04-20T17:32:40.103559Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def calculate_prediction_uncertainty(submission_df, num_samples=5):\n    sample_indices = np.random.choice(len(submission_df), min(num_samples, len(submission_df)), replace=False)\n    \n    plt.figure(figsize=(15, 10))\n    \n    for idx, i in enumerate(sample_indices):\n        plt.subplot(num_samples, 1, idx+1)\n        \n        realizations = []\n        \n        base_realization = submission_df.iloc[i, 1:301].values\n        realizations.append(base_realization)\n        \n        for r in range(1, 10):\n            cols = [f\"r_{r}_pos_{i+1}\" for i in range(300)]\n            realization = submission_df.loc[submission_df.index[i], cols].values\n            realizations.append(realization)\n        \n        realizations = np.array(realizations)\n        \n        mean_prediction = np.mean(realizations, axis=0)\n        std_prediction = np.std(realizations, axis=0)\n        \n        x_coords = np.arange(1, 301)\n        plt.plot(x_coords, mean_prediction, 'b-', label='Mean Prediction')\n        \n        plt.fill_between(x_coords, \n                         mean_prediction - 2*std_prediction,\n                         mean_prediction + 2*std_prediction,\n                         alpha=0.3, color='blue',\n                         label='95% Confidence Interval')\n        \n        high_uncertainty = np.where(std_prediction > np.mean(std_prediction) + np.std(std_prediction))[0]\n        if len(high_uncertainty) > 0:\n            plt.scatter(high_uncertainty+1, \n                       mean_prediction[high_uncertainty],\n                       color='red', s=50, alpha=0.7, \n                       label='High Uncertainty Regions')\n        \n        plt.title(f\"Prediction Uncertainty Analysis for Sample {i}\")\n        plt.xlabel(\"Position\")\n        plt.ylabel(\"Layer Depth (Z)\")\n        plt.grid(True, alpha=0.3)\n        if idx == 0:\n            plt.legend(loc='upper right')\n    \n    plt.tight_layout()\n    \n    try:\n        wandb.log({\"uncertainty_analysis\": wandb.Image(plt)})\n    except:\n        pass\n    \n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.104893Z","iopub.execute_input":"2025-04-20T17:32:40.105434Z","iopub.status.idle":"2025-04-20T17:32:40.124068Z","shell.execute_reply.started":"2025-04-20T17:32:40.105416Z","shell.execute_reply":"2025-04-20T17:32:40.123559Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def create_sweep_config():\n    sweep_config = {\n        'method': 'bayes', \n        'metric': {\n            'name': 'val_nll_score',\n            'goal': 'minimize'\n        },\n        'parameters': {\n            'model_type': {\n                'values': ['TCN', 'LSTM', 'HybridCNNLSTM']\n            },\n            'learning_rate': {\n                'distribution': 'log_uniform_values', \n                'min': 3e-4,\n                'max': 1e-2\n            },\n            'batch_size': {\n                'values': [64, 128]\n            },\n            'dropout': {\n                'distribution': 'uniform',\n                'min': 0.1,\n                'max': 0.3 \n            },\n            'hidden_size': {\n                'values': [128, 256]\n            },\n            'num_layers': {\n                'values': [2, 3, 4]\n            },\n            'weight_decay': {\n                'values': [1e-5, 1e-4]\n            },\n            'optimizer': {\n                'values': ['adamw', 'adamw', 'sgd']\n            },\n            'scheduler': {\n                'values': ['cosine', 'reduce', 'onecycle']\n            },\n            'diversity_factor': {\n                'distribution': 'uniform',\n                'min': 0.8,\n                'max': 1.5\n            }\n        }\n    }\n    \n    sweep_config['parameters']['d_model'] = {\n        'values': [128, 256]\n    }\n    sweep_config['parameters']['nhead'] = {\n        'values': [4, 8, 12]\n    }\n    sweep_config['parameters']['dim_feedforward'] = {\n        'values': [128, 256, 512]\n    }\n    \n    sweep_config['parameters']['kernel_size'] = {\n        'values': [3, 5]\n    }\n    \n    return sweep_config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.124847Z","iopub.execute_input":"2025-04-20T17:32:40.125060Z","iopub.status.idle":"2025-04-20T17:32:40.143572Z","shell.execute_reply.started":"2025-04-20T17:32:40.125040Z","shell.execute_reply":"2025-04-20T17:32:40.142894Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def sweep_agent():\n    global X_features, y, X_features_test\n    \n    wandb.init(reinit=True)\n    \n    config = wandb.config\n    model_type = config['model_type']\n    \n    default_config = get_default_config(model_type)\n    \n    experiment_config = dict(config)\n    \n    for key, value in default_config.items():\n        if key not in experiment_config:\n            experiment_config[key] = value\n    \n    transformer_params = ['d_model', 'nhead', 'dim_feedforward']\n    tcn_params = ['kernel_size']\n    \n    if model_type != 'Transformer':\n        for param in transformer_params:\n            if param in experiment_config: \n                del experiment_config[param]\n    \n    if model_type != 'TCN':\n        for param in tcn_params:\n            if param in experiment_config:\n                del experiment_config[param]\n    \n    print(f\"Running experiment with config: {experiment_config}\")\n    val_nll_score = run_experiment(experiment_config, autofinish=False)\n    \n    wandb.log({'val_nll_score': val_nll_score, 'final_val_nll_score': val_nll_score})\n    wandb.finish()\n    \n    return val_nll_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.144389Z","iopub.execute_input":"2025-04-20T17:32:40.144634Z","iopub.status.idle":"2025-04-20T17:32:40.162711Z","shell.execute_reply.started":"2025-04-20T17:32:40.144601Z","shell.execute_reply":"2025-04-20T17:32:40.162098Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def run_sweep(count=10):\n    init_wandb(project_name=\"geology-forecast-challenge-sweep-gpu-bayes-30\")\n    \n    sweep_config = create_sweep_config()\n    sweep_id = wandb.sweep(sweep_config, project=\"geology-forecast-challenge-sweep-gpu-bayes-30\")\n    \n    wandb.finish()\n    \n    wandb.agent(sweep_id, function=sweep_agent, count=count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.163421Z","iopub.execute_input":"2025-04-20T17:32:40.163576Z","iopub.status.idle":"2025-04-20T17:32:40.179234Z","shell.execute_reply.started":"2025-04-20T17:32:40.163563Z","shell.execute_reply":"2025-04-20T17:32:40.178630Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def run_single_model(model_type='HybridCNNLSTM', custom_params=None):\n    config = get_default_config(model_type)\n    \n    if custom_params:\n        config.update(custom_params)\n    \n    val_nll_score = run_experiment(config)\n    \n    return val_nll_score, config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.179809Z","iopub.execute_input":"2025-04-20T17:32:40.180133Z","iopub.status.idle":"2025-04-20T17:32:40.194561Z","shell.execute_reply.started":"2025-04-20T17:32:40.180118Z","shell.execute_reply":"2025-04-20T17:32:40.193887Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"\"\"\"\nscore, config = run_single_model('HybridCNNLSTM', {\n    'hidden_size': 512, \n    'num_layers': 2,\n    'dropout': 0.3,\n    'learning_rate': 3e-4,\n    'epochs': 60 \n})\n\nprint(f\"Final validation NLL score: {score:.6f}\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.195179Z","iopub.execute_input":"2025-04-20T17:32:40.195372Z","iopub.status.idle":"2025-04-20T17:32:40.210254Z","shell.execute_reply.started":"2025-04-20T17:32:40.195360Z","shell.execute_reply":"2025-04-20T17:32:40.209696Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'\\nscore, config = run_single_model(\\'HybridCNNLSTM\\', {\\n    \\'hidden_size\\': 512, \\n    \\'num_layers\\': 2,\\n    \\'dropout\\': 0.3,\\n    \\'learning_rate\\': 3e-4,\\n    \\'epochs\\': 60 \\n})\\n\\nprint(f\"Final validation NLL score: {score:.6f}\")\\n'"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"print(\"Engineering features for train data...\")\ntrain_features = engineer_features(train)\n\nprint(\"Engineering features for test data...\")\ntest_features = engineer_features(test)\n\nX_features = train_features.drop('geology_id', axis=1).values\ny = train[TARGETS].values\nX_features_test = test_features.drop('geology_id', axis=1).values\n\nprint(f\"Feature shape: {X_features.shape}, Target shape: {y.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:40.210907Z","iopub.execute_input":"2025-04-20T17:32:40.211143Z","iopub.status.idle":"2025-04-20T17:32:48.960675Z","shell.execute_reply.started":"2025-04-20T17:32:40.211124Z","shell.execute_reply":"2025-04-20T17:32:48.960077Z"}},"outputs":[{"name":"stdout","text":"Engineering features for train data...\nEngineering features for test data...\nFeature shape: (1510, 397), Target shape: (1510, 3000)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"run_sweep(count=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T17:32:48.961315Z","iopub.execute_input":"2025-04-20T17:32:48.961554Z","execution_failed":"2025-04-20T17:42:41.309Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meva-koroleva\u001b[0m (\u001b[33mml-samurai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250420_173255-6rc8pxsx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/runs/6rc8pxsx' target=\"_blank\">woven-waterfall-8</a></strong> to <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30' target=\"_blank\">https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/runs/6rc8pxsx' target=\"_blank\">https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/runs/6rc8pxsx</a>"},"metadata":{}},{"name":"stdout","text":"W&B successfully initialized\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. learning_rate uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: yea8hcrq\nSweep URL: https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/sweeps/yea8hcrq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">woven-waterfall-8</strong> at: <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/runs/6rc8pxsx' target=\"_blank\">https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/runs/6rc8pxsx</a><br> View project at: <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30' target=\"_blank\">https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250420_173255-6rc8pxsx/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0ojyhpxw with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 768\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdiversity_factor: 1.1350509391807937\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.11134274715865912\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: 7\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002214133550293376\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_type: TCN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: onecycle\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250420_173310-0ojyhpxw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/runs/0ojyhpxw' target=\"_blank\">vocal-sweep-1</a></strong> to <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/sweeps/yea8hcrq' target=\"_blank\">https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/sweeps/yea8hcrq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30' target=\"_blank\">https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/sweeps/yea8hcrq' target=\"_blank\">https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/sweeps/yea8hcrq</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/runs/0ojyhpxw' target=\"_blank\">https://wandb.ai/ml-samurai/geology-forecast-challenge-sweep-gpu-bayes-30/runs/0ojyhpxw</a>"},"metadata":{}},{"name":"stdout","text":"Running experiment with config: {'batch_size': 128, 'diversity_factor': 1.1350509391807937, 'dropout': 0.11134274715865912, 'hidden_size': 1024, 'kernel_size': 7, 'learning_rate': 0.0002214133550293376, 'model_type': 'TCN', 'num_layers': 2, 'optimizer': 'adamw', 'scheduler': 'onecycle', 'weight_decay': 0.0001, 'epochs': 50, 'seed': 42, 'feature_engineering': 'advanced'}\n\n==================================================\nRunning experiment with TCN\n==================================================\nConfig: {'batch_size': 128, 'diversity_factor': 1.1350509391807937, 'dropout': 0.11134274715865912, 'hidden_size': 1024, 'kernel_size': 7, 'learning_rate': 0.0002214133550293376, 'model_type': 'TCN', 'num_layers': 2, 'optimizer': 'adamw', 'scheduler': 'onecycle', 'weight_decay': 0.0001, 'epochs': 50, 'seed': 42, 'feature_engineering': 'advanced'}\nTraining model TCN...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae391626d0d74c8891959c8dfd02f572"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ee094bce6334eefa6537b9cbcdf4c2b"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/50 - Train Loss: 1.100777, Val Loss: 1.022578\nSaved new best model with validation loss: 1.022578\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2511e0e6d8d4495087e92bf935257d7e"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00><function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n        if w.is_alive():if w.is_alive():\n \n             ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: \nAssertionErrorcan only test a child process\n: can only test a child process\nException ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00><function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()    \nself._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nif w.is_alive():    \nif w.is_alive(): \n           ^ ^ ^^^^^^^^^^^^^^^^^^^\n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    \nassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n     assert self._parent_pid == os.getpid(), 'can only test a child process'\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAssertionErrorAssertionError: : can only test a child processcan only test a child process\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32728ac30b6e4801a4809b908e90ac23"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/50 - Train Loss: 1.062170, Val Loss: 1.003897\nSaved new best model with validation loss: 1.003897\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7e2394961224054a5e67d6c51859d4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb80b435b7714d2b838c95a2b8e14c25"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/50 - Train Loss: 1.028707, Val Loss: 0.992420\nSaved new best model with validation loss: 0.992420\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69e2e157d24d4728a2f5f45f2a951721"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcdc89c903694fa5b5594933957f7c8b"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/50 - Train Loss: 1.011968, Val Loss: 0.982677\nSaved new best model with validation loss: 0.982677\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aed876133004e8d86c76c0ce0f30efd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d1a284c0e514207b4824e06a9b5bccc"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/50 - Train Loss: 0.995704, Val Loss: 0.972729\nSaved new best model with validation loss: 0.972729\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"801b4e19a9a742b29dbc43f384855ae9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6abd01b5abc4672aae4a9d99ddd4954"}},"metadata":{}},{"name":"stdout","text":"Epoch 6/50 - Train Loss: 0.993640, Val Loss: 0.961279\nSaved new best model with validation loss: 0.961279\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f002f67338645559103467185197b1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e133f4a109584765be9c6e03bdbcf15b"}},"metadata":{}},{"name":"stdout","text":"Epoch 7/50 - Train Loss: 0.984907, Val Loss: 0.949359\nSaved new best model with validation loss: 0.949359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53a58f5e5811423f838132fbc57aebb0"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Exception ignored in: \nTraceback (most recent call last):\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n    self._shutdown_workers()Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nself._shutdown_workers()    \nif w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n     if w.is_alive(): \n          ^ ^ ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^\n    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n     assert self._parent_pid == os.getpid(), 'can only test a child process'  \n                ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError^: can only test a child process\nAssertionError\n: can only test a child processException ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nException ignored in: Traceback (most recent call last):\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nself._shutdown_workers()\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nself._shutdown_workers()\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nif w.is_alive():    if w.is_alive():\n \n            ^^ ^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n               ^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAssertionError: AssertionErrorcan only test a child process: \ncan only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Traceback (most recent call last):\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():    \nif w.is_alive():\n              ^^^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\nassert self._parent_pid == os.getpid(), 'can only test a child process'    \nassert self._parent_pid == os.getpid(), 'can only test a child process' \n                    ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nAssertionErrorAssertionError: : can only test a child process\ncan only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nself._shutdown_workers()    \nself._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n        if w.is_alive():if w.is_alive():\n\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    \nassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n                 ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nAssertionErrorTraceback (most recent call last):\n:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\ncan only test a child process    \nself._shutdown_workers()Exception ignored in: \n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n    Traceback (most recent call last):\nif w.is_alive():\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n     self._shutdown_workers() \n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n       if w.is_alive(): \n^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^ ^ ^ ^\n    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n      ^^ ^  ^^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^^\n^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>^\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nAssertionError:     can only test a child processself._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>    if w.is_alive():\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n       self._shutdown_workers()\n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n      if w.is_alive(): \n^  ^ ^ ^ ^ ^^ ^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process'  \n          ^^  ^^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>^\n\nTraceback (most recent call last):\nAssertionError  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n:     can only test a child processself._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nException ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>if w.is_alive():\n\nTraceback (most recent call last):\n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n      self._shutdown_workers() \n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n      if w.is_alive():^\n^ ^ ^ ^ ^ ^  ^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n          ^ ^^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^^Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nAssertionErrorTraceback (most recent call last):\n:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\ncan only test a child process    \nself._shutdown_workers()\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n    Traceback (most recent call last):\nif w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n    self._shutdown_workers()  \n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n      if w.is_alive(): \n  ^ ^ ^^ ^ ^ ^ ^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n        ^ ^  ^ ^^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\nTraceback (most recent call last):\nAssertionError:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\ncan only test a child process\n    self._shutdown_workers()\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n    Traceback (most recent call last):\nif w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n     self._shutdown_workers() \n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n      if w.is_alive(): \n   ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ \n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n            ^ ^ ^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^^can only test a child process\n^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\nAssertionErrorTraceback (most recent call last):\n: can only test a child process  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n    self._shutdown_workers()Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    if w.is_alive():    \nself._shutdown_workers() \n    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n     if w.is_alive(): \n   ^ ^ ^ ^ ^^  ^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ \n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process'  \n            ^ ^ ^ ^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError^: ^can only test a child process\n^^Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>AssertionError\n: Traceback (most recent call last):\ncan only test a child process  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n    self._shutdown_workers()Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n    Traceback (most recent call last):\nif w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n     self._shutdown_workers() \n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n        if w.is_alive(): \n^  ^^ ^ ^ ^ ^ ^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process'  \n          ^ ^ ^ ^  ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError^: can only test a child process^\n\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"088e2b5f068e4aa58425740177d36d62"}},"metadata":{}},{"name":"stdout","text":"Epoch 8/50 - Train Loss: 0.974020, Val Loss: 0.936409\nSaved new best model with validation loss: 0.936409\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4c7eceeeeab44aa847d21250d76a783"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01ecaf5eb766416bafab46f5551818ef"}},"metadata":{}},{"name":"stdout","text":"Epoch 9/50 - Train Loss: 0.955562, Val Loss: 0.920809\nSaved new best model with validation loss: 0.920809\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c12bdddde124935a63d4057ff4eede5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1312e615636c47fe8062a3a66db6a695"}},"metadata":{}},{"name":"stdout","text":"Epoch 10/50 - Train Loss: 0.939382, Val Loss: 0.904660\nSaved new best model with validation loss: 0.904660\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2c216d0a1034532b0ee6409bf4e31aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88343bf0c92245cba47bddb6950eb981"}},"metadata":{}},{"name":"stdout","text":"Epoch 11/50 - Train Loss: 0.926621, Val Loss: 0.886007\nSaved new best model with validation loss: 0.886007\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0eec6cf01bc34f8e962382d3df803299"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f06ec58172174f39b944e7a6da8cbde5"}},"metadata":{}},{"name":"stdout","text":"Epoch 12/50 - Train Loss: 0.914908, Val Loss: 0.865296\nSaved new best model with validation loss: 0.865296\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6671809b40174705adcd11bc0cad5910"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb717c0729f8476a8c8bb18fd5caf891"}},"metadata":{}},{"name":"stdout","text":"Epoch 13/50 - Train Loss: 0.897450, Val Loss: 0.842736\nSaved new best model with validation loss: 0.842736\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14/50:   0%|          | 0/10 [00:10<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0436a25daae14b439422ac0607010e78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dabbcbfefe864f1f87fb3038b423d991"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00><function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nself._shutdown_workers()    \nif w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n     if w.is_alive():\n           ^ ^ ^^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\nassert self._parent_pid == os.getpid(), 'can only test a child process'    \nassert self._parent_pid == os.getpid(), 'can only test a child process' \n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError\nAssertionError: : can only test a child processcan only test a child process\n\nException ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00><function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n        if w.is_alive():if w.is_alive():\n\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\nassert self._parent_pid == os.getpid(), 'can only test a child process'    \nassert self._parent_pid == os.getpid(), 'can only test a child process'\n                     ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: \ncan only test a child processAssertionError\n: can only test a child processException ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nException ignored in: Traceback (most recent call last):\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nself._shutdown_workers()    \nself._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():    \nif w.is_alive(): \n           ^ ^ ^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n              ^  ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>AssertionError\n: Traceback (most recent call last):\ncan only test a child process  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n    Exception ignored in: self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nif w.is_alive():\n     self._shutdown_workers() \n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n       if w.is_alive(): \n ^ ^ ^ ^ ^  ^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n            ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process\nAssertionError\n: Exception ignored in: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\nTraceback (most recent call last):\nException ignored in:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nTraceback (most recent call last):\n    self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    \n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nself._shutdown_workers()\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nif w.is_alive():\n    if w.is_alive():  \n          ^ ^ ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError\n: AssertionErrorcan only test a child process: \ncan only test a child process\nException ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00><function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n        if w.is_alive():\nif w.is_alive(): \n            ^^ ^^^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    \nassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n     assert self._parent_pid == os.getpid(), 'can only test a child process'\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError\n: AssertionErrorcan only test a child process: \ncan only test a child process\nException ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Traceback (most recent call last):\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n        self._shutdown_workers()self._shutdown_workers()\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n        if w.is_alive():if w.is_alive():\n\n              ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^    \nassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n                 ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^\n: AssertionErrorcan only test a child process: \ncan only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n    self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\nif w.is_alive():\n     if w.is_alive(): \n         ^ ^ ^ ^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n      assert self._parent_pid == os.getpid(), 'can only test a child process' \n                ^^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError^: \nAssertionErrorcan only test a child process\n: can only test a child processException ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nTraceback (most recent call last):\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nself._shutdown_workers()    \nself._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():    \nif w.is_alive(): \n            ^ ^^^^^^^^^^^^^^^^^^^^\n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    \n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\nassert self._parent_pid == os.getpid(), 'can only test a child process'    \n assert self._parent_pid == os.getpid(), 'can only test a child process' \n                  ^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process\n\nAssertionError: Exception ignored in: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n\nException ignored in: Traceback (most recent call last):\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n    self._shutdown_workers()Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    self._shutdown_workers()    if w.is_alive():\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n      if w.is_alive(): \n       ^ ^ ^ ^ ^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n\n    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n              ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process\n^\nAssertionErrorException ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\ncan only test a child process\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\nException ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>self._shutdown_workers()\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n        self._shutdown_workers()if w.is_alive():\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n       if w.is_alive(): \n       ^ ^ ^ ^^^^^^^^^^^^^^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n                  ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError^: ^can only test a child process\n\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/50 - Train Loss: 0.872877, Val Loss: 0.818798\nSaved new best model with validation loss: 0.818798\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"228fc98855eb47708b9946e2cf8bd144"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n  Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1550, in _shutdown_workers\n    self._pin_memory_thread.join()\n  File \"/usr/lib/python3.11/threading.py\", line 1116, in join\n    raise RuntimeError(\"cannot join current thread\")\nRuntimeError: cannot join current thread\n     ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>^\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n^^    ^self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n^    ^if w.is_alive():^^\n^ \n AssertionError :   can only test a child process\n  Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>^^\nTraceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n^    self._shutdown_workers()^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n^    if w.is_alive():\n^  ^ ^    ^^^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^^ ^ ^  \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     assert self._parent_pid == os.getpid(), 'can only test a child process' \n     ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>^\n\nTraceback (most recent call last):\nAssertionError  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n: can only test a child process    \nself._shutdown_workers()Exception ignored in: \n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\n    if w.is_alive():Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n\n    self._shutdown_workers() \n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n        if w.is_alive(): \n   ^ ^ ^ ^^  ^^^^^^^^^^^\n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^ \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n       assert self._parent_pid == os.getpid(), 'can only test a child process' \n      ^  ^^  ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^^\n^Exception ignored in: \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7b539c6b1d00>\nAssertionErrorTraceback (most recent call last):\n:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\ncan only test a child process    \nself._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e272c29bda34d0080e15d272ea3ce19"}},"metadata":{}},{"name":"stdout","text":"Epoch 15/50 - Train Loss: 0.848049, Val Loss: 0.792482\nSaved new best model with validation loss: 0.792482\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 16/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6fd624a9d8c46469d18d4891d30c972"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e970fcd60bb4b909d65e2a696ab9084"}},"metadata":{}},{"name":"stdout","text":"Epoch 16/50 - Train Loss: 0.841045, Val Loss: 0.763847\nSaved new best model with validation loss: 0.763847\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 17/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d58a104a22c643f0afd13f8f2977b52f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e4fe950f9a4fa58be40f59ac44ef8e"}},"metadata":{}},{"name":"stdout","text":"Epoch 17/50 - Train Loss: 0.802103, Val Loss: 0.733172\nSaved new best model with validation loss: 0.733172\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 18/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d71006fd7244af484b4718b09c09ad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0e728f6d4d042deaab7af4ed77ad681"}},"metadata":{}},{"name":"stdout","text":"Epoch 18/50 - Train Loss: 0.773748, Val Loss: 0.701610\nSaved new best model with validation loss: 0.701610\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 19/50:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e6e2f3960746acac07020de4457910"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"\"\"\"\n# Visualize predictions for a few samples\ntry:\n    for i in range(3):\n        visualize_predictions(test_idx=i)\nexcept Exception as e:\n    print(f\"Visualization error: {e}\")\n\n# Save submission file\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\nSubmission file saved!\")\n\n# Validate submission format\nexpected_cols = sub.columns.tolist()\nactual_cols = submission.columns.tolist()\n\nif set(expected_cols) != set(actual_cols):\n    print(\"WARNING: Submission columns don't match expected format!\")\n    missing = set(expected_cols) - set(actual_cols)\n    extra = set(actual_cols) - set(expected_cols)\n    if missing:\n        print(f\"Missing columns: {missing}\")\n    if extra:\n        print(f\"Extra columns: {extra}\")\nelse:\n    print(\"Submission format validated successfully!\")\n\n# Analyze prediction uncertainty\ntry:\n    calculate_prediction_uncertainty(submission, num_samples=3)\nexcept Exception as e:\n    print(f\"Uncertainty analysis error: {e}\")\n\n# Finalize wandb run\ntry:\n    wandb.finish()\nexcept:\n    pass\n\nprint(\"\\nTraining and prediction completed!\")\nprint(f\"Final mean validation NLL score: {mean_val_score:.6f}\")\nprint(\"Submission file saved as 'submission.csv'\")\n\"\"\"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-20T17:42:41.310Z"}},"outputs":[],"execution_count":null}]}