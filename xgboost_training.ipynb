{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.special import logsumexp\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wandb(project_name=\"geology-forecast-challenge-sweep-gpu-bayes-30-server-HybridCNNLSTM\", config=None):\n",
    "    # Если run уже существует, просто возвращаем его\n",
    "    if wandb.run is not None:\n",
    "        return wandb.run\n",
    "    \n",
    "    try:\n",
    "        wandb_api_key = os.environ['WANDB_API_KEY']\n",
    "        \n",
    "        wandb.login(key=wandb_api_key)\n",
    "        \n",
    "        run = wandb.init(\n",
    "            project=project_name,\n",
    "            config=config,\n",
    "            tags=[\"LSTM\", \"Geology Forecast Challenge\", \"Feature Engineering\"],\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        print(\"W&B successfully initialized\")\n",
    "        return run\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing W&B: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\").fillna(0)\n",
    "test = pd.read_csv(\"data/test.csv\").fillna(0)\n",
    "sub = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [c for c in test.columns if c != 'geology_id']\n",
    "TARGETS = [c for c in sub.columns if c != 'geology_id']\n",
    "solution = train[['geology_id'] + TARGETS].copy()\n",
    "train_sub = train[['geology_id'] + TARGETS].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(data, is_test=False):\n",
    "    feature_data = pd.DataFrame({'geology_id': data['geology_id']})\n",
    "    \n",
    "    historical_cols = [col for col in data.columns if col != 'geology_id' and col.startswith('-') or col == '0']\n",
    "    \n",
    "    historical_cols.sort(key=lambda x: int(x) if x.isdigit() else int(x))\n",
    "    \n",
    "    historical_data = data[historical_cols].values\n",
    "    \n",
    "    # 1. Calculate local slopes (first derivative)\n",
    "    slopes = np.zeros_like(historical_data)\n",
    "    for i in range(1, historical_data.shape[1]):\n",
    "        slopes[:, i] = historical_data[:, i] - historical_data[:, i-1]\n",
    "    \n",
    "    # 2. Calculate curvature (second derivative)\n",
    "    curvature = np.zeros_like(historical_data)\n",
    "    for i in range(1, slopes.shape[1]-1):\n",
    "        curvature[:, i] = slopes[:, i+1] - slopes[:, i]\n",
    "    \n",
    "    # 3. Create rolling statistics for last N points\n",
    "    window_sizes = [5, 10, 20]\n",
    "    for window in window_sizes:\n",
    "\n",
    "        if historical_data.shape[1] >= window:\n",
    "            \n",
    "            feature_data[f'mean_last_{window}'] = np.mean(historical_data[:, -window:], axis=1)\n",
    "            feature_data[f'std_last_{window}'] = np.std(historical_data[:, -window:], axis=1)\n",
    "\n",
    "            x = np.arange(window)\n",
    "            \n",
    "            for i in range(historical_data.shape[0]):\n",
    "                \n",
    "                y = historical_data[i, -window:]\n",
    "                \n",
    "                if np.all(y == 0):\n",
    "                    feature_data.loc[i, f'trend_last_{window}'] = 0\n",
    "                else:\n",
    "                    slope = np.polyfit(x, y, 1)[0]\n",
    "                    feature_data.loc[i, f'trend_last_{window}'] = slope\n",
    "    \n",
    "    # 4. Calculate smoothed versions of data (different levels of smoothing)\n",
    "    smooth_windows = [3, 5, 9]\n",
    "    for window in smooth_windows:\n",
    "        # Savitzky-Golay filter requires window_length > polyorder\n",
    "        if window <= 3: \n",
    "            continue\n",
    "        \n",
    "        if historical_data.shape[1] >= window:\n",
    "            sg_window = window if window % 2 == 1 else window + 1\n",
    "            \n",
    "            for i in range(historical_data.shape[0]):\n",
    "                data_slice = historical_data[i, -50:]\n",
    "                if len(data_slice) >= sg_window:\n",
    "                    try:\n",
    "                        polyorder = 2 if sg_window <= 5 else 3\n",
    "                        smoothed = savgol_filter(data_slice, sg_window, polyorder, mode='nearest')\n",
    "                        feature_data.loc[i, f'sg_smooth_{window}'] = smoothed[-1]\n",
    "                        \n",
    "                        if len(smoothed) >= 3:\n",
    "                            feature_data.loc[i, f'sg_smooth_slope_{window}'] = smoothed[-1] - smoothed[-2]\n",
    "                    except Exception as e:\n",
    "                        feature_data.loc[i, f'sg_smooth_{window}'] = data_slice[-1]\n",
    "                        if len(data_slice) >= 3:\n",
    "                            feature_data.loc[i, f'sg_smooth_slope_{window}'] = data_slice[-1] - data_slice[-2]\n",
    "                else:\n",
    "                    feature_data.loc[i, f'sg_smooth_{window}'] = historical_data[i, -1] if historical_data.shape[1] > 0 else 0\n",
    "                    feature_data.loc[i, f'sg_smooth_slope_{window}'] = 0\n",
    "    \n",
    "    # 5. Calculate frequency-domain features (FFT-based)\n",
    "    if historical_data.shape[1] >= 32: \n",
    "        for i in range(historical_data.shape[0]):\n",
    "            fft_vals = np.abs(np.fft.rfft(historical_data[i, -32:]))\n",
    "            feature_data.loc[i, 'dominant_freq'] = np.argmax(fft_vals[1:]) + 1 if len(fft_vals) > 1 else 0\n",
    "            feature_data.loc[i, 'dominant_power'] = np.max(fft_vals[1:]) if len(fft_vals) > 1 else 0\n",
    "            feature_data.loc[i, 'total_power'] = np.sum(fft_vals[1:]) if len(fft_vals) > 1 else 0\n",
    "    \n",
    "    # 6. Detect potential fault indicators\n",
    "    if historical_data.shape[1] >= 5:\n",
    "        max_changes = []\n",
    "        for i in range(historical_data.shape[0]):\n",
    "            max_change = 0\n",
    "            for j in range(historical_data.shape[1] - 5):\n",
    "                change = np.max(historical_data[i, j:j+5]) - np.min(historical_data[i, j:j+5])\n",
    "                max_change = max(max_change, change)\n",
    "            max_changes.append(max_change)\n",
    "        feature_data['max_change_5pt'] = max_changes\n",
    "    \n",
    "    # 7. Calculate geological dip angle features\n",
    "    if historical_data.shape[1] >= 10:\n",
    "        dips = []\n",
    "        for i in range(historical_data.shape[0]):\n",
    "            # Use linear regression to find dip angle\n",
    "            x = np.arange(10)\n",
    "            y = historical_data[i, -10:]\n",
    "            slope = np.polyfit(x, y, 1)[0]\n",
    "            # Convert to degrees (slope is rise/run, arctangent gives angle)\n",
    "            dip_angle = np.degrees(np.arctan(slope))\n",
    "            dips.append(dip_angle)\n",
    "        feature_data['dip_angle'] = dips\n",
    "    \n",
    "    # 8. Add the raw historical data (last 50 points)\n",
    "    for i in range(min(50, historical_data.shape[1])):\n",
    "        feature_data[f'raw_{i}'] = historical_data[:, -(i+1)]\n",
    "    \n",
    "    # 9. Create interaction features from important raw features\n",
    "    if 'mean_last_5' in feature_data.columns and 'trend_last_10' in feature_data.columns:\n",
    "        feature_data['mean_trend_interaction'] = feature_data['mean_last_5'] * feature_data['trend_last_10']\n",
    "    \n",
    "    if 'dip_angle' in feature_data.columns and 'max_change_5pt' in feature_data.columns:\n",
    "        feature_data['dip_change_interaction'] = feature_data['dip_angle'] * feature_data['max_change_5pt']\n",
    "\n",
    "    # 10. Non-linear transformations of important features\n",
    "    for col in feature_data.columns:\n",
    "        if col != 'geology_id' and not col.startswith('raw_'):\n",
    "            feature_data[f'{col}_squared'] = feature_data[col] ** 2\n",
    "            # Log transform for any potentially positive-only features\n",
    "            if np.all(feature_data[col] > 0):\n",
    "                feature_data[f'{col}_log'] = np.log1p(feature_data[col])\n",
    "    \n",
    "    # Add the original features as well\n",
    "    for col in historical_cols:\n",
    "        feature_data[col] = data[col]\n",
    "    \n",
    "    return feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMForecastModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        num_layers,\n",
    "        output_size,\n",
    "        dropout=0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "        )\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        lstm_out = self.layer_norm(lstm_out)\n",
    "        \n",
    "        x = self.fc1(lstm_out)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerForecastModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_layers=4,\n",
    "        dim_feedforward=2048,\n",
    "        dropout=0.1,\n",
    "        output_size=300\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_projection = nn.Linear(input_size, d_model)\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        transformer_output = self.transformer_encoder(x)\n",
    "\n",
    "        output = self.output_layer(transformer_output[:, -1, :])\n",
    "        \n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Padding для сохранения размерности\n",
    "        padding = (kernel_size - 1) * dilation\n",
    "        \n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size, \n",
    "            padding=padding, \n",
    "            dilation=dilation\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.residual = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        \n",
    "        out = self.conv(x)\n",
    "        \n",
    "        out = out[:, :, :-self.conv.padding[0]]\n",
    "        \n",
    "        out = out + residual\n",
    "        \n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = out.permute(0, 2, 1)\n",
    "        out = self.layer_norm(out)\n",
    "        out = out.permute(0, 2, 1) \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCNForecastModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size=128,\n",
    "        kernel_size=3,\n",
    "        num_layers=8,\n",
    "        dropout=0.2,\n",
    "        output_size=300\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_projection = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.tcn_blocks = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            dilation = 2 ** i  # 1, 2, 4, 8, ...\n",
    "            self.tcn_blocks.append(\n",
    "                TCNBlock(hidden_size, hidden_size, kernel_size, dilation, dropout)\n",
    "            )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        for block in self.tcn_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        x = x[:, :, -1]\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridCNNLSTMModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        cnn_filters=[64, 128, 128, 256],\n",
    "        kernel_size=3,\n",
    "        lstm_hidden=512,\n",
    "        lstm_layers=2,\n",
    "        dropout=0.2,\n",
    "        output_size=300\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.ModuleList()\n",
    "        \n",
    "        self.cnn_layers.append(nn.Conv1d(input_size, cnn_filters[0], kernel_size, padding=kernel_size//2))\n",
    "        \n",
    "        for i in range(1, len(cnn_filters)):\n",
    "            self.cnn_layers.append(\n",
    "                nn.Conv1d(cnn_filters[i-1], cnn_filters[i], kernel_size, padding=kernel_size//2)\n",
    "            )\n",
    "        \n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(filters) for filters in cnn_filters\n",
    "        ])\n",
    "        \n",
    "        self.act = nn.GELU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_filters[-1],\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0,\n",
    "            bidirectional=True \n",
    "        )\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(lstm_hidden * 2) \n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden * 2, lstm_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(lstm_hidden, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        for i, (conv, bn) in enumerate(zip(self.cnn_layers, self.batch_norms)):\n",
    "            x = conv(x)\n",
    "            x = bn(x)\n",
    "            x = self.act(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        \n",
    "        lstm_out = lstm_out[:, -1, :]\n",
    "        \n",
    "        lstm_out = self.layer_norm(lstm_out)\n",
    "\n",
    "        x = self.output_layer(lstm_out)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeologyDataset(Dataset):\n",
    "    def __init__(self, features, targets=None, is_test=False, scale_features=True):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        if scale_features:\n",
    "            self.feature_scaler = StandardScaler()\n",
    "            self.features = self.feature_scaler.fit_transform(self.features)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        \n",
    "        x = x.reshape(-1, 1)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return x\n",
    "        else:\n",
    "            y = self.targets[idx]\n",
    "            return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, engineered_features=None, target_cols=None, is_test=False):\n",
    "    if engineered_features is None:\n",
    "        # If no engineered features provided, use raw data\n",
    "        feature_cols = [c for c in df.columns if c != 'geology_id' and (c.startswith('-') or c == '0')]\n",
    "        X = df[feature_cols].values\n",
    "    else:\n",
    "        # Use the engineered features, dropping the ID column\n",
    "        X = engineered_features.drop('geology_id', axis=1).values\n",
    "    \n",
    "    if not is_test:\n",
    "        y = df[target_cols].values\n",
    "        return X, y\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nll_score(solution, submission, row_id_column_name='geology_id'):\n",
    "    solution_copy = solution.copy()\n",
    "    submission_copy = submission.copy()\n",
    "    \n",
    "    del solution_copy[row_id_column_name]\n",
    "    del submission_copy[row_id_column_name]\n",
    "\n",
    "    NEGATIVE_PART = -299\n",
    "    LARGEST_CHUNK = 600\n",
    "    SMALLEST_CHUNK = 350\n",
    "    TOTAL_REALIZATIONS = 10\n",
    "    INFLATION_SIGMA = 600\n",
    "    \n",
    "    sigma_2 = np.ones((LARGEST_CHUNK+NEGATIVE_PART-1))\n",
    "    from_ranges = [1, 61, 245]\n",
    "    to_ranges_excl = [61, 245, 301]\n",
    "    log_slopes = [1.0406028049510443, 0.0, 7.835345062351012]\n",
    "    log_offsets = [-6.430669850650689, -2.1617411566043896, -45.24876794412965]\n",
    "\n",
    "    for growth_mode in range(len(from_ranges)):\n",
    "        for i in range(from_ranges[growth_mode], to_ranges_excl[growth_mode]):\n",
    "            sigma_2[i-1] = np.exp(np.log(i)*log_slopes[growth_mode]+log_offsets[growth_mode])\n",
    "\n",
    "    sigma_2 *= INFLATION_SIGMA\n",
    "  \n",
    "    cov_matrix_inv_diag = 1. / sigma_2\n",
    "    \n",
    "    num_rows = solution_copy.shape[0]\n",
    "    num_columns = LARGEST_CHUNK + NEGATIVE_PART - 1\n",
    "    \n",
    "    p = 1./TOTAL_REALIZATIONS\n",
    "    log_p = np.log(p)\n",
    "    \n",
    "    solution_arr = np.zeros((num_rows, TOTAL_REALIZATIONS, num_columns))\n",
    "    submission_arr = np.zeros((num_rows, TOTAL_REALIZATIONS, num_columns))\n",
    "    \n",
    "    for k in range(TOTAL_REALIZATIONS):\n",
    "        for i in range(num_columns):\n",
    "            if k == 0:\n",
    "                column_name = str(i+1)\n",
    "            else:\n",
    "                column_name = f\"r_{k}_pos_{i+1}\"\n",
    "            solution_arr[:, k, i] = solution_copy[column_name].values\n",
    "            submission_arr[:, k, i] = submission_copy[column_name].values\n",
    "\n",
    "    misfit = solution_arr - submission_arr\n",
    "    inner_product_matrix = np.sum(cov_matrix_inv_diag * misfit * misfit, axis=2)\n",
    "    \n",
    "    nll = -logsumexp(log_p - inner_product_matrix, axis=1)\n",
    "    \n",
    "    return nll.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_nll_loss(model, train_loader, optimizer, device, epoch=0, total_epochs=30):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{total_epochs}\")\n",
    "    \n",
    "    for data, target in pbar:\n",
    "        data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        target_mean = target.mean(dim=0)\n",
    "        target_std = target.std(dim=0) + 1e-6\n",
    "        \n",
    "        normalized_output = (output - target_mean) / target_std\n",
    "        normalized_target = (target - target_mean) / target_std\n",
    "        \n",
    "        loss = F.mse_loss(normalized_output, normalized_target)\n",
    "        \n",
    "        if output.shape[1] > 1:\n",
    "            smoothness_penalty = torch.mean(torch.abs(output[:, 1:] - output[:, :-1]))\n",
    "            loss += 0.01 * smoothness_penalty\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.6f}\"})\n",
    "    \n",
    "    return np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    val_preds = []\n",
    "    val_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(val_loader, desc=\"Validating\"):\n",
    "            data, target = data.to(device, dtype=torch.float32), target.to(device, dtype=torch.float32)\n",
    "            output = model(data)\n",
    "            \n",
    "            target_mean = target.mean(dim=0)\n",
    "            target_std = target.std(dim=0) + 1e-6\n",
    "            \n",
    "            normalized_output = (output - target_mean) / target_std\n",
    "            normalized_target = (target - target_mean) / target_std\n",
    "            \n",
    "            loss = F.mse_loss(normalized_output, normalized_target)\n",
    "            \n",
    "            val_losses.append(loss.item())\n",
    "            val_preds.append(output.cpu().numpy())\n",
    "            val_targets.append(target.cpu().numpy())\n",
    "    \n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_targets = np.concatenate(val_targets)\n",
    "    \n",
    "    return np.mean(val_losses), val_preds, val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diverse_realizations(base_predictions, num_samples=10, diversity_factor=0.2):\n",
    "    num_rows, num_cols = base_predictions.shape\n",
    "    realizations = np.zeros((num_samples, num_rows, num_cols))\n",
    "\n",
    "    realizations[0] = base_predictions\n",
    "\n",
    "    for i in range(1, num_samples):\n",
    "        realization = base_predictions.copy()\n",
    "        \n",
    "        for j in range(num_rows):\n",
    "            noise = np.random.normal(0, diversity_factor, num_cols)\n",
    "            \n",
    "            smoothed_noise = gaussian_filter1d(noise, sigma=5.0)\n",
    "            \n",
    "            position_factor = np.linspace(0.1, 1.0, num_cols)\n",
    "            scaled_noise = smoothed_noise * position_factor\n",
    "            \n",
    "            realization[j] += scaled_noise\n",
    "\n",
    "            for k in range(1, num_cols):\n",
    "\n",
    "                max_change = 2.0 * (k/num_cols + 0.1)  # Allow larger changes further away\n",
    "                diff = realization[j, k] - realization[j, k-1]\n",
    "                if abs(diff) > max_change:\n",
    "                    realization[j, k] = realization[j, k-1] + np.sign(diff) * max_change\n",
    "        \n",
    "        realizations[i] = realization\n",
    "    \n",
    "    return realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fold_realizations(base_predictions, num_realizations=10):\n",
    "    realizations = generate_diverse_realizations(\n",
    "        base_predictions, \n",
    "        num_samples=num_realizations,\n",
    "        diversity_factor=0.15  # Control the diversity level\n",
    "    )\n",
    "    return realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(train_features, y):\n",
    "    feature_cols = [col for col in train_features.columns if col != 'geology_id']\n",
    "    \n",
    "    target_cols = [str(i) for i in range(1, 11)]\n",
    "    target_cols = [col for col in target_cols if col in train.columns]\n",
    "    \n",
    "    correlations = []\n",
    "    for tcol in target_cols:\n",
    "        if tcol in train.columns:\n",
    "            for fcol in feature_cols:\n",
    "                corr = np.corrcoef(train_features[fcol], train[tcol])[0, 1]\n",
    "                correlations.append((fcol, tcol, abs(corr)))\n",
    "    \n",
    "    top_correlations = sorted(correlations, key=lambda x: x[2], reverse=True)[:15]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plot_data = pd.DataFrame(top_correlations, columns=['Feature', 'Target', 'Correlation'])\n",
    "    sns.barplot(data=plot_data, x='Correlation', y='Feature', hue='Target')\n",
    "    plt.title('Top Feature Correlations with Targets')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    try:\n",
    "        wandb.log({\"feature_correlations\": wandb.Image(plt)})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_config(model_type):    \n",
    "    if model_type == 'LSTM':\n",
    "        return {\n",
    "            'model_type': 'LSTM',\n",
    "            'hidden_size': 512,\n",
    "            'num_layers': 2,\n",
    "            'dropout': 0.2,\n",
    "            'learning_rate': 5e-4,\n",
    "            'weight_decay': 1e-5,\n",
    "            'batch_size': 128,\n",
    "            'epochs': 50,\n",
    "            'seed': SEED,\n",
    "            'feature_engineering': 'advanced',\n",
    "            'optimizer': 'adamw',\n",
    "            'scheduler': 'onecycle'\n",
    "        }\n",
    "    elif model_type == 'Transformer':\n",
    "        return {\n",
    "            'model_type': 'Transformer',\n",
    "            'd_model': 512,\n",
    "            'nhead': 8,\n",
    "            'num_layers': 4,\n",
    "            'dim_feedforward': 1024,\n",
    "            'dropout': 0.2,\n",
    "            'learning_rate': 4e-4,\n",
    "            'weight_decay': 1e-5,\n",
    "            'batch_size': 128,\n",
    "            'epochs': 50,\n",
    "            'seed': SEED,\n",
    "            'feature_engineering': 'advanced',\n",
    "            'optimizer': 'adamw',\n",
    "            'scheduler': 'cosine'\n",
    "        }\n",
    "    elif model_type == 'TCN':\n",
    "        return {\n",
    "            'model_type': 'TCN',\n",
    "            'hidden_size': 256,\n",
    "            'kernel_size': 3,\n",
    "            'num_layers': 8,\n",
    "            'dropout': 0.2,\n",
    "            'learning_rate': 5e-4,\n",
    "            'weight_decay': 1e-5,\n",
    "            'batch_size': 128,\n",
    "            'epochs': 50,\n",
    "            'seed': SEED,\n",
    "            'feature_engineering': 'advanced',\n",
    "            'optimizer': 'adam',\n",
    "            'scheduler': 'onecycle'\n",
    "        }\n",
    "    elif model_type == 'HybridCNNLSTM':\n",
    "        return {\n",
    "            'model_type': 'HybridCNNLSTM',\n",
    "            'cnn_filters': [64, 128, 128, 256],\n",
    "            'kernel_size': 3,\n",
    "            'hidden_size': 512,\n",
    "            'num_layers': 2,\n",
    "            'dropout': 0.3,\n",
    "            'learning_rate': 3e-4,\n",
    "            'weight_decay': 1e-5,\n",
    "            'batch_size': 128,\n",
    "            'epochs': 60,\n",
    "            'seed': SEED,\n",
    "            'feature_engineering': 'advanced',\n",
    "            'optimizer': 'adamw',\n",
    "            'scheduler': 'cosine'\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный тип модели: {model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(config, device):\n",
    "    model_type = config['model_type']\n",
    "    input_features_size = 1 \n",
    "    output_size = 3000\n",
    "    \n",
    "    if model_type == 'LSTM':\n",
    "        model = LSTMForecastModel(\n",
    "            input_size=input_features_size,\n",
    "            hidden_size=config['hidden_size'],\n",
    "            num_layers=config['num_layers'],\n",
    "            output_size=output_size,\n",
    "            dropout=config['dropout']\n",
    "        )\n",
    "    elif model_type == 'Transformer':\n",
    "        model = TransformerForecastModel(\n",
    "            input_size=input_features_size,\n",
    "            d_model=config.get('d_model', 512),\n",
    "            nhead=config.get('nhead', 8),\n",
    "            num_layers=config['num_layers'],\n",
    "            dim_feedforward=config.get('dim_feedforward', 2048),\n",
    "            dropout=config['dropout'],\n",
    "            output_size=output_size\n",
    "        )\n",
    "    elif model_type == 'TCN':\n",
    "        model = TCNForecastModel(\n",
    "            input_size=input_features_size,\n",
    "            hidden_size=config['hidden_size'],\n",
    "            kernel_size=config.get('kernel_size', 3),\n",
    "            num_layers=config['num_layers'],\n",
    "            dropout=config['dropout'],\n",
    "            output_size=output_size\n",
    "        )\n",
    "    elif model_type == 'HybridCNNLSTM':\n",
    "        model = HybridCNNLSTMModel(\n",
    "            input_size=input_features_size,\n",
    "            cnn_filters=config.get('cnn_filters', [64, 128, 128, 256]),\n",
    "            kernel_size=config.get('kernel_size', 3),\n",
    "            lstm_hidden=config['hidden_size'],\n",
    "            lstm_layers=config['num_layers'],\n",
    "            dropout=config['dropout'],\n",
    "            output_size=output_size\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Неизвестный тип модели: {model_type}\")\n",
    "    \n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_single_model(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    "    config,\n",
    "    run_name=None,\n",
    "    autofinish=True,\n",
    "    wandb_run=None\n",
    "):\n",
    "    try:\n",
    "        # Используем переданный wandb_run или инициализируем новый\n",
    "        run = wandb_run if wandb_run is not None else init_wandb(project_name=run_name, config=config)\n",
    "        \n",
    "        train_dataset = GeologyDataset(X_train, y_train)\n",
    "        val_dataset = GeologyDataset(X_val, y_val)\n",
    "        test_dataset = GeologyDataset(X_test, is_test=True)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=config['batch_size'], \n",
    "            shuffle=True,\n",
    "            pin_memory=True, \n",
    "            num_workers=2  \n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=config['batch_size'], \n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=2\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=config['batch_size'], \n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=2\n",
    "        )\n",
    "        \n",
    "        model = create_model(config, device)\n",
    "        \n",
    "        if config.get('optimizer', 'adamw').lower() == 'adamw':\n",
    "            optimizer = optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay'],\n",
    "                eps=1e-8\n",
    "            )\n",
    "        elif config.get('optimizer', 'adamw').lower() == 'adam':\n",
    "            optimizer = optim.Adam(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay'],\n",
    "                eps=1e-8\n",
    "            )\n",
    "        elif config.get('optimizer', 'adamw').lower() == 'sgd':\n",
    "            optimizer = optim.SGD(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                momentum=config.get('momentum', 0.9),\n",
    "                weight_decay=config['weight_decay']\n",
    "            )\n",
    "        \n",
    "        if config.get('scheduler', 'onecycle').lower() == 'onecycle':\n",
    "            steps_per_epoch = len(train_loader)\n",
    "            scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=config['learning_rate'],\n",
    "                epochs=config['epochs'],\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                pct_start=0.3,\n",
    "                div_factor=25,\n",
    "                final_div_factor=1000,\n",
    "            )\n",
    "        elif config.get('scheduler', 'onecycle').lower() == 'cosine':\n",
    "            scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, \n",
    "                T_max=config['epochs'] // 2,\n",
    "                eta_min=config['learning_rate'] / 1000\n",
    "            )\n",
    "        elif config.get('scheduler', 'onecycle').lower() == 'reduce':\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode='min',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=config['learning_rate'] / 100\n",
    "            )\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        val_predictions = None\n",
    "        \n",
    "        # early stopping\n",
    "        patience = 10\n",
    "        counter = 0\n",
    "        min_delta = 1e-4\n",
    "        \n",
    "        print(f\"Training model {config['model_type']}...\")\n",
    "        for epoch in range(config['epochs']):\n",
    "            train_loss = train_model_with_nll_loss(\n",
    "                model, train_loader, optimizer, device, epoch, config['epochs']\n",
    "            )\n",
    "            \n",
    "            val_loss, val_preds, val_targets = validate_model(model, val_loader, device)\n",
    "            \n",
    "            val_predictions = val_preds\n",
    "            \n",
    "            if config.get('scheduler', 'onecycle').lower() in ['onecycle', 'cosine']:\n",
    "                scheduler.step()\n",
    "            elif config.get('scheduler', 'onecycle').lower() == 'reduce':\n",
    "                scheduler.step(val_loss)\n",
    "    \n",
    "            if run:\n",
    "                run.log({\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "                })\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{config['epochs']} - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n",
    "            \n",
    "            # loss check\n",
    "            if epoch + 1 == 12 and val_loss > 1.0:\n",
    "                print(f\"Validation loss > 1.0 at epoch 10 ({val_loss:.6f}). Stopping training.\")\n",
    "                if run:\n",
    "                    run.log({\"early_stop_reason\": \"high_loss_at_epoch_10\", \"best_val_loss\": best_val_loss})\n",
    "                break\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                model_path = f\"model_{config['model_type']}.pt\"\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                if run:\n",
    "                    run.save(model_path)\n",
    "                print(f\"Saved new best model with validation loss: {val_loss:.6f}\")\n",
    "                counter = 0 \n",
    "            else:\n",
    "                if val_loss > best_val_loss - min_delta:\n",
    "                    counter += 1\n",
    "                    if counter >= patience:\n",
    "                        print(f\"Early stopping triggered at epoch {epoch+1}. Best val_loss: {best_val_loss:.6f}\")\n",
    "                        if run:\n",
    "                            run.log({\"early_stop_reason\": \"no_improvement\", \"best_val_loss\": best_val_loss})\n",
    "                        break\n",
    "        \n",
    "        model.load_state_dict(torch.load(f\"model_{config['model_type']}.pt\"))\n",
    "        model.eval()\n",
    "        test_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(test_loader, desc=\"Predicting test data\"):\n",
    "                if isinstance(data, list):\n",
    "                    data = data[0]\n",
    "                data = data.to(device, dtype=torch.float32)\n",
    "                output = model(data)\n",
    "                test_preds.append(output.cpu().numpy())\n",
    "        \n",
    "        base_test_predictions = np.concatenate(test_preds)\n",
    "        \n",
    "        val_preds_df = pd.DataFrame(\n",
    "            data=val_predictions,\n",
    "            columns=TARGETS,\n",
    "        )\n",
    "        val_preds_df['geology_id'] = val_dataset.features[:, 0]\n",
    "        \n",
    "        val_solution_df = pd.DataFrame(\n",
    "            data=y_val,\n",
    "            columns=TARGETS,\n",
    "        )\n",
    "        val_solution_df['geology_id'] = val_dataset.features[:, 0]\n",
    "        \n",
    "        nll_score = compute_nll_score(val_solution_df, val_preds_df)\n",
    "        \n",
    "        # Завершаем run только если мы его создали и autofinish=True\n",
    "        if run and autofinish and wandb_run is None:\n",
    "            run.log({\"val_nll_score\": nll_score})\n",
    "            run.finish()\n",
    "        \n",
    "        return base_test_predictions, val_predictions, nll_score\n",
    "        \n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        from torch.utils.data import _utils\n",
    "        if hasattr(_utils.worker, \"_worker_pool\"):\n",
    "            _utils.worker._worker_pool.close()\n",
    "            _utils.worker._worker_pool.join()\n",
    "        elif hasattr(_utils.worker, \"_shutdown_all_workers\"):\n",
    "            _utils.worker._shutdown_all_workers()\n",
    "        \n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(base_predictions, config, val_nll_score):\n",
    "    submission = sub.copy()\n",
    "    \n",
    "    for i in range(300):\n",
    "        col_name = str(i+1)\n",
    "        submission[col_name] = base_predictions[:, i]\n",
    "    \n",
    "    realizations = generate_diverse_realizations(\n",
    "        base_predictions, \n",
    "        num_samples=10, \n",
    "        diversity_factor=0.15 + 0.05 * (config.get('diversity_factor', 1.0) - 1.0)\n",
    "    )\n",
    "    \n",
    "    for r_idx in range(1, 10): \n",
    "        for i in range(300):\n",
    "            col_name = f\"r_{r_idx}_pos_{i+1}\"\n",
    "            submission[col_name] = realizations[r_idx][:, i]\n",
    "    \n",
    "    submission_file = f\"submission_{config['model_type']}_{val_nll_score:.6f}.csv\"\n",
    "    submission.to_csv(submission_file, index=False)\n",
    "    print(f\"\\nSubmission file saved: {submission_file}\")\n",
    "    \n",
    "    expected_cols = sub.columns.tolist()\n",
    "    actual_cols = submission.columns.tolist()\n",
    "    \n",
    "    if set(expected_cols) != set(actual_cols):\n",
    "        print(\"WARNING: Submission columns don't match expected format!\")\n",
    "        missing = set(expected_cols) - set(actual_cols)\n",
    "        extra = set(actual_cols) - set(expected_cols)\n",
    "        if missing:\n",
    "            print(f\"Missing columns: {missing}\")\n",
    "        if extra:\n",
    "            print(f\"Extra columns: {extra}\")\n",
    "    else:\n",
    "        print(\"Submission format validated successfully!\")\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_predictions(submission, config, run=None):\n",
    "    try:\n",
    "        plt.figure(figsize=(15, 8))\n",
    "\n",
    "        sample_indices = [0, 10, 20]\n",
    "        \n",
    "        for sample_idx in sample_indices:\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            \n",
    "            x_coords = np.arange(1, 301)\n",
    "            plt.plot(x_coords, submission.iloc[sample_idx, 1:301].values, \n",
    "                    color='blue', label='Baseline', linewidth=2)\n",
    "            \n",
    "            colors = ['red', 'green', 'purple']\n",
    "            for r in range(1, 4): \n",
    "                cols = [f\"r_{r}_pos_{i+1}\" for i in range(300)]\n",
    "                plt.plot(x_coords, submission.loc[submission.index[sample_idx], cols].values,\n",
    "                        color=colors[(r-1) % len(colors)], label=f'Realization {r}', alpha=0.7)\n",
    "            \n",
    "            plt.title(f\"{config['model_type']} - Sample {sample_idx}\")\n",
    "            plt.xlabel(\"Position\")\n",
    "            plt.ylabel(\"Layer Depth (Z coordinate)\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            if run:\n",
    "                run.log({f\"predictions_sample_{sample_idx}\": wandb.Image(plt)})\n",
    "            \n",
    "            plt.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Visualization error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(X_features, y, val_size=0.2, random_state=42):\n",
    "    n_samples = len(X_features)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    val_samples = int(val_size * n_samples)\n",
    "    val_indices = indices[:val_samples]\n",
    "    train_indices = indices[val_samples:]\n",
    "    \n",
    "    X_train = X_features[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    X_val = X_features[val_indices]\n",
    "    y_val = y[val_indices]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config, autofinish=True, wandb_run=None):\n",
    "    try:\n",
    "        seed_everything(config['seed'])\n",
    "        \n",
    "        print(f\"\\n{'='*50}\\nRunning experiment with {config['model_type']}\\n{'='*50}\")\n",
    "        print(f\"Config: {config}\")\n",
    "        \n",
    "        X_train, y_train, X_val, y_val, train_indices, val_indices = split_train_val(\n",
    "            X_features, y, val_size=0.2, random_state=config['seed']\n",
    "        )\n",
    "\n",
    "        base_predictions, val_predictions, val_nll_score = train_and_predict_single_model(\n",
    "        X_train, y_train, X_val, y_val, X_features_test, config, \n",
    "        run_name=\"geology-forecast-challenge\", \n",
    "        autofinish=autofinish, wandb_run=wandb_run)\n",
    "        \n",
    "        train_sub.loc[val_indices, TARGETS] = val_predictions\n",
    "        \n",
    "        submission = create_submission(base_predictions, config, val_nll_score)\n",
    "    \n",
    "        visualize_model_predictions(submission, config)\n",
    "        \n",
    "        print(f\"Finished experiment with {config['model_type']}, validation NLL: {val_nll_score:.6f}\")\n",
    "        \n",
    "        return val_nll_score\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(f\"CUDA OOM error with config: {config}\")\n",
    "            \n",
    "            if wandb.run is not None:\n",
    "                wandb.log({\"cuda_oom_error\": True, \"error_message\": str(e)})\n",
    "                \n",
    "            # Большое значение метрики, чтобы байесовский оптимизатор избегал таких конфигураций\n",
    "            return float('inf')\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(test_idx=0, num_realizations=3):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    x_coords = np.arange(1, 301)\n",
    "    plt.plot(x_coords, submission.iloc[test_idx, 1:301].values, \n",
    "             color='blue', label='Realization 0', linewidth=2)\n",
    "    \n",
    "    colors = ['red', 'green', 'purple']\n",
    "    for r in range(1, min(num_realizations+1, 10)):\n",
    "        cols = [f\"r_{r}_pos_{i+1}\" for i in range(300)]\n",
    "        plt.plot(x_coords, submission.loc[submission.index[test_idx], cols].values,\n",
    "                color=colors[(r-1) % len(colors)], label=f'Realization {r}', alpha=0.7)\n",
    "    \n",
    "    plt.title(f\"Multiple Geological Sequence Realizations for Sample {test_idx}\")\n",
    "    plt.xlabel(\"Position\")\n",
    "    plt.ylabel(\"Layer Depth (Z coordinate)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    try:\n",
    "        wandb.log({\"prediction_visualization\": wandb.Image(plt)})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_geological_patterns(submission_df, sample_indices=None, num_samples=5):\n",
    "    if sample_indices is None:\n",
    "        sample_indices = np.random.choice(len(submission_df), min(num_samples, len(submission_df)), replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    for idx, i in enumerate(sample_indices):\n",
    "        plt.subplot(len(sample_indices), 1, idx+1)\n",
    "        \n",
    "        base_pred = submission_df.iloc[i, 1:301].values\n",
    "        \n",
    "        slopes = np.diff(base_pred)\n",
    "        \n",
    "        threshold = np.std(slopes) * 2.5\n",
    "        fault_indicators = np.where(np.abs(slopes) > threshold)[0]\n",
    "        \n",
    "        plt.plot(range(1, 301), base_pred, 'b-', linewidth=2, label='Predicted Sequence')\n",
    "        \n",
    "        if len(fault_indicators) > 0:\n",
    "            plt.scatter([x+1 for x in fault_indicators], \n",
    "                       [base_pred[x] for x in fault_indicators],\n",
    "                       color='red', s=80, marker='x', label='Potential Fault/Change')\n",
    "        \n",
    "        segment_size = 50\n",
    "        for seg_start in range(0, 300, segment_size):\n",
    "            seg_end = min(seg_start + segment_size, 300)\n",
    "            if seg_end - seg_start > 10:  # Only fit if enough points\n",
    "                x_seg = np.arange(seg_start, seg_end)\n",
    "                y_seg = base_pred[seg_start:seg_end]\n",
    "                # Fit a line to this segment\n",
    "                z = np.polyfit(x_seg, y_seg, 1)\n",
    "                p = np.poly1d(z)\n",
    "                plt.plot(x_seg+1, p(x_seg), '--', linewidth=1.5, \n",
    "                         alpha=0.7, label=f'Trend (Seg {seg_start}-{seg_end})')\n",
    "        \n",
    "        plt.title(f\"Geological Analysis for Sample {i}\")\n",
    "        plt.xlabel(\"Position\")\n",
    "        plt.ylabel(\"Layer Depth (Z)\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        if idx == 0:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    try:\n",
    "        wandb.log({\"geological_analysis\": wandb.Image(plt)})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_uncertainty(submission_df, num_samples=5):\n",
    "    sample_indices = np.random.choice(len(submission_df), min(num_samples, len(submission_df)), replace=False)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for idx, i in enumerate(sample_indices):\n",
    "        plt.subplot(num_samples, 1, idx+1)\n",
    "        \n",
    "        realizations = []\n",
    "        \n",
    "        base_realization = submission_df.iloc[i, 1:301].values\n",
    "        realizations.append(base_realization)\n",
    "        \n",
    "        for r in range(1, 10):\n",
    "            cols = [f\"r_{r}_pos_{i+1}\" for i in range(300)]\n",
    "            realization = submission_df.loc[submission_df.index[i], cols].values\n",
    "            realizations.append(realization)\n",
    "        \n",
    "        realizations = np.array(realizations)\n",
    "        \n",
    "        mean_prediction = np.mean(realizations, axis=0)\n",
    "        std_prediction = np.std(realizations, axis=0)\n",
    "        \n",
    "        x_coords = np.arange(1, 301)\n",
    "        plt.plot(x_coords, mean_prediction, 'b-', label='Mean Prediction')\n",
    "        \n",
    "        plt.fill_between(x_coords, \n",
    "                         mean_prediction - 2*std_prediction,\n",
    "                         mean_prediction + 2*std_prediction,\n",
    "                         alpha=0.3, color='blue',\n",
    "                         label='95% Confidence Interval')\n",
    "        \n",
    "        high_uncertainty = np.where(std_prediction > np.mean(std_prediction) + np.std(std_prediction))[0]\n",
    "        if len(high_uncertainty) > 0:\n",
    "            plt.scatter(high_uncertainty+1, \n",
    "                       mean_prediction[high_uncertainty],\n",
    "                       color='red', s=50, alpha=0.7, \n",
    "                       label='High Uncertainty Regions')\n",
    "        \n",
    "        plt.title(f\"Prediction Uncertainty Analysis for Sample {i}\")\n",
    "        plt.xlabel(\"Position\")\n",
    "        plt.ylabel(\"Layer Depth (Z)\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        if idx == 0:\n",
    "            plt.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    try:\n",
    "        wandb.log({\"uncertainty_analysis\": wandb.Image(plt)})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sweep_config():\n",
    "    sweep_config = {\n",
    "        'method': 'bayes', \n",
    "        'metric': {\n",
    "            'name': 'val_nll_score',\n",
    "            'goal': 'minimize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'model_type': {\n",
    "                'values': ['HybridCNNLSTM']\n",
    "            },\n",
    "            'learning_rate': {\n",
    "                'distribution': 'log_uniform_values', \n",
    "                'min': 3e-4,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "            'batch_size': {\n",
    "                'values': [128]\n",
    "            },\n",
    "            'dropout': {\n",
    "                'distribution': 'uniform',\n",
    "                'min': 0.1,\n",
    "                'max': 0.3 \n",
    "            },\n",
    "            'hidden_size': {\n",
    "                'values': [128]\n",
    "            },\n",
    "            'num_layers': {\n",
    "                'values': [2, 3, 4]\n",
    "            },\n",
    "            'weight_decay': {\n",
    "                'values': [1e-5, 1e-4]\n",
    "            },\n",
    "            'optimizer': {\n",
    "                'values': ['adamw', 'adamw', 'sgd']\n",
    "            },\n",
    "            'scheduler': {\n",
    "                'values': ['cosine', 'reduce', 'onecycle']\n",
    "            },\n",
    "            'diversity_factor': {\n",
    "                'distribution': 'uniform',\n",
    "                'min': 0.8,\n",
    "                'max': 1.5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    sweep_config['parameters']['d_model'] = {\n",
    "        'values': [128]\n",
    "    }\n",
    "    sweep_config['parameters']['nhead'] = {\n",
    "        'values': [4, 8, 12]\n",
    "    }\n",
    "    sweep_config['parameters']['dim_feedforward'] = {\n",
    "        'values': [128, 256]\n",
    "    }\n",
    "    \n",
    "    sweep_config['parameters']['kernel_size'] = {\n",
    "        'values': [3, 5]\n",
    "    }\n",
    "    \n",
    "    return sweep_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_agent():\n",
    "    global X_features, y, X_features_test\n",
    "    \n",
    "    # Инициализируем wandb run и сохраняем объект run\n",
    "    run = wandb.init(reinit=True)\n",
    "    \n",
    "    config = wandb.config\n",
    "    model_type = config['model_type']\n",
    "    \n",
    "    default_config = get_default_config(model_type)\n",
    "    \n",
    "    experiment_config = dict(config)\n",
    "    \n",
    "    for key, value in default_config.items():\n",
    "        if key not in experiment_config:\n",
    "            experiment_config[key] = value\n",
    "    \n",
    "    transformer_params = ['d_model', 'nhead', 'dim_feedforward']\n",
    "    tcn_params = ['kernel_size']\n",
    "    \n",
    "    if model_type != 'Transformer':\n",
    "        for param in transformer_params:\n",
    "            if param in experiment_config: \n",
    "                del experiment_config[param]\n",
    "    \n",
    "    if model_type != 'TCN':\n",
    "        for param in tcn_params:\n",
    "            if param in experiment_config:\n",
    "                del experiment_config[param]\n",
    "    \n",
    "    print(f\"Running experiment with config: {experiment_config}\")\n",
    "    \n",
    "    # Передаем объект run в run_experiment\n",
    "    val_nll_score = run_experiment(experiment_config, autofinish=False, wandb_run=run)\n",
    "    \n",
    "    # Логируем с использованием того же объекта run\n",
    "    run.log({'val_nll_score': val_nll_score, 'final_val_nll_score': val_nll_score})\n",
    "    \n",
    "    # wandb.finish() не нужен, так как агент сам позаботится о завершении\n",
    "    \n",
    "    return val_nll_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sweep(count=10):\n",
    "    # Инициализируем начальный run для создания sweep\n",
    "    init_wandb(project_name=\"geology-forecast-challenge-sweep-gpu-bayes-30-server-HybridCNNLSTM\")\n",
    "    \n",
    "    sweep_config = create_sweep_config()\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"geology-forecast-challenge-sweep-gpu-bayes-30-server-HybridCNNLSTM\")\n",
    "    \n",
    "    # Завершаем начальный run перед запуском агента\n",
    "    wandb.finish()\n",
    "    \n",
    "    # Запускаем агента\n",
    "    wandb.agent(sweep_id, function=sweep_agent, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_model(model_type='HybridCNNLSTM', custom_params=None):\n",
    "    config = get_default_config(model_type)\n",
    "    \n",
    "    if custom_params:\n",
    "        config.update(custom_params)\n",
    "    \n",
    "    val_nll_score = run_experiment(config)\n",
    "    \n",
    "    return val_nll_score, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscore, config = run_single_model(\\'HybridCNNLSTM\\', {\\n    \\'hidden_size\\': 512, \\n    \\'num_layers\\': 2,\\n    \\'dropout\\': 0.3,\\n    \\'learning_rate\\': 3e-4,\\n    \\'epochs\\': 60 \\n})\\n\\nprint(f\"Final validation NLL score: {score:.6f}\")\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "score, config = run_single_model('HybridCNNLSTM', {\n",
    "    'hidden_size': 512, \n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.3,\n",
    "    'learning_rate': 3e-4,\n",
    "    'epochs': 60 \n",
    "})\n",
    "\n",
    "print(f\"Final validation NLL score: {score:.6f}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features for train data...\n",
      "Engineering features for test data...\n",
      "Feature shape: (1510, 397), Target shape: (1510, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Engineering features for train data...\")\n",
    "train_features = engineer_features(train)\n",
    "\n",
    "print(\"Engineering features for test data...\")\n",
    "test_features = engineer_features(test)\n",
    "\n",
    "X_features = train_features.drop('geology_id', axis=1).values\n",
    "y = train[TARGETS].values\n",
    "X_features_test = test_features.drop('geology_id', axis=1).values\n",
    "\n",
    "print(f\"Feature shape: {X_features.shape}, Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/venv/lib/python3.10/site-packages (3.0.0)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.10/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /opt/venv/lib/python3.10/site-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: scipy in /opt/venv/lib/python3.10/site-packages (from xgboost) (1.13.0)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.10/site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: tqdm in /opt/venv/lib/python3.10/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/venv/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /opt/venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.2.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (580 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.6/580.6 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.15.2 colorlog-6.9.0 greenlet-3.2.1 optuna-4.3.0 sqlalchemy-2.0.40\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "from optuna.integration.wandb import WeightsAndBiasesCallback\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def train_xgboost_model(X_train, y_train, X_val=None, y_val=None, params=None, num_boost_round=1000, early_stopping_rounds=50):\n",
    "    \"\"\"\n",
    "    Train XGBoost model with early stopping\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = get_default_xgb_params()\n",
    "    \n",
    "    # Create DMatrix objects for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    \n",
    "    # Create validation set if provided\n",
    "    eval_list = [(dtrain, 'train')]\n",
    "    if X_val is not None and y_val is not None:\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        eval_list.append((dval, 'valid'))\n",
    "    \n",
    "    # Train model with early stopping\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=eval_list,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_default_xgb_params():\n",
    "    \"\"\"\n",
    "    Default XGBoost parameters\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.01,\n",
    "        'reg_lambda': 1,\n",
    "        'gamma': 0,\n",
    "        'tree_method': 'gpu_hist' if torch.cuda.is_available() else 'hist',\n",
    "        'predictor': 'gpu_predictor' if torch.cuda.is_available() else 'cpu_predictor',\n",
    "        'seed': SEED\n",
    "    }\n",
    "\n",
    "def predict_output_sequence(model, X):\n",
    "    \"\"\"\n",
    "    Generate predictions for each target position using a single XGBoost model\n",
    "    \"\"\"\n",
    "    dtest = xgb.DMatrix(X)\n",
    "    return model.predict(dtest)\n",
    "\n",
    "def cross_validate_xgb(X, y, params, n_splits=5, target_cols=None):\n",
    "    \"\"\"\n",
    "    Cross-validate XGBoost model\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    cv_scores = []\n",
    "    oof_preds = np.zeros_like(y)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        model = train_xgboost_model(X_train, y_train, X_val, y_val, params)\n",
    "        \n",
    "        # Make predictions\n",
    "        val_preds = predict_output_sequence(model, X_val)\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        \n",
    "        # Calculate fold score\n",
    "        mse = mean_squared_error(y_val, val_preds)\n",
    "        print(f\"Fold {fold+1} MSE: {mse:.6f}\")\n",
    "        cv_scores.append(mse)\n",
    "    \n",
    "    # Calculate overall CV score\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    print(f\"\\nCV MSE: {cv_score:.6f}\")\n",
    "    \n",
    "    return cv_score, oof_preds\n",
    "\n",
    "def xgb_multioutput_training(X, y, X_test, params=None, n_splits=5):\n",
    "    \"\"\"\n",
    "    Train a set of XGBoost models, one for each geological position\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = get_default_xgb_params()\n",
    "    \n",
    "    # Select positions to model (we'll train models for each position)\n",
    "    # For computational efficiency, we'll train models for positions at intervals\n",
    "    # and interpolate the rest\n",
    "    interval = 5  # Model every 5th position\n",
    "    positions_to_model = list(range(0, 300, interval))\n",
    "    if 299 not in positions_to_model:  # Make sure we model the last position\n",
    "        positions_to_model.append(299)\n",
    "    \n",
    "    models = {}\n",
    "    oof_preds = np.zeros((X.shape[0], 300))\n",
    "    test_preds = np.zeros((X_test.shape[0], 300))\n",
    "    \n",
    "    # Initialize W&B run\n",
    "    run = init_wandb(project_name=\"geology-forecast-challenge-xgb\", config=params)\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    for pos in tqdm(positions_to_model, desc=\"Training position models\"):\n",
    "        pos_models = []\n",
    "        pos_oof_preds = np.zeros(X.shape[0])\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            # Extract target for current position\n",
    "            y_train = y[train_idx, pos]\n",
    "            y_val = y[val_idx, pos]\n",
    "            \n",
    "            # Train model\n",
    "            pos_model = train_xgboost_model(\n",
    "                X_train, y_train, X_val, y_val, params, \n",
    "                num_boost_round=2000, early_stopping_rounds=50\n",
    "            )\n",
    "            \n",
    "            # Save model\n",
    "            pos_models.append(pos_model)\n",
    "            \n",
    "            # Generate OOF predictions\n",
    "            val_preds = predict_output_sequence(pos_model, X_val)\n",
    "            pos_oof_preds[val_idx] = val_preds\n",
    "            \n",
    "        # Store model for this position\n",
    "        models[pos] = pos_models\n",
    "        \n",
    "        # Store OOF predictions for this position\n",
    "        oof_preds[:, pos] = pos_oof_preds\n",
    "        \n",
    "        # Generate test predictions (average of fold models)\n",
    "        pos_test_preds = np.zeros(X_test.shape[0])\n",
    "        for model in pos_models:\n",
    "            pos_test_preds += predict_output_sequence(model, X_test) / len(pos_models)\n",
    "        test_preds[:, pos] = pos_test_preds\n",
    "        \n",
    "        if run:\n",
    "            mse = mean_squared_error(y[:, pos], pos_oof_preds)\n",
    "            run.log({f\"position_{pos}_mse\": mse})\n",
    "    \n",
    "    # Interpolate predictions for positions not explicitly modeled\n",
    "    for i in range(300):\n",
    "        if i in positions_to_model:\n",
    "            continue\n",
    "        \n",
    "        # Find the closest modeled positions\n",
    "        left_pos = max([p for p in positions_to_model if p < i])\n",
    "        right_pos = min([p for p in positions_to_model if p > i])\n",
    "        \n",
    "        # Calculate interpolation weights\n",
    "        total_dist = right_pos - left_pos\n",
    "        left_weight = (right_pos - i) / total_dist\n",
    "        right_weight = (i - left_pos) / total_dist\n",
    "        \n",
    "        # Interpolate OOF predictions\n",
    "        oof_preds[:, i] = left_weight * oof_preds[:, left_pos] + right_weight * oof_preds[:, right_pos]\n",
    "        \n",
    "        # Interpolate test predictions\n",
    "        test_preds[:, i] = left_weight * test_preds[:, left_pos] + right_weight * test_preds[:, right_pos]\n",
    "    \n",
    "    if run:\n",
    "        mse = mean_squared_error(y, oof_preds)\n",
    "        run.log({\"overall_mse\": mse})\n",
    "    \n",
    "    return models, oof_preds, test_preds\n",
    "\n",
    "def nll_cv_score(oof_preds, y, geology_ids):\n",
    "    \"\"\"\n",
    "    Calculate NLL score for cross-validation\n",
    "    \"\"\"\n",
    "    # Create DataFrames with the required format for NLL score\n",
    "    oof_df = pd.DataFrame({\"geology_id\": geology_ids})\n",
    "    solution_df = pd.DataFrame({\"geology_id\": geology_ids})\n",
    "    \n",
    "    # Add base predictions\n",
    "    for i in range(300):\n",
    "        col_name = str(i+1)\n",
    "        oof_df[col_name] = oof_preds[:, i]\n",
    "        solution_df[col_name] = y[:, i]\n",
    "    \n",
    "    # Generate diverse realizations\n",
    "    realizations = generate_diverse_realizations(oof_preds, num_samples=10, diversity_factor=0.15)\n",
    "    \n",
    "    # Add realizations to oof_df\n",
    "    for r_idx in range(1, 10):\n",
    "        for i in range(300):\n",
    "            col_name = f\"r_{r_idx}_pos_{i+1}\"\n",
    "            oof_df[col_name] = realizations[r_idx][:, i]\n",
    "            solution_df[col_name] = y[:, i]\n",
    "    \n",
    "    # Calculate NLL score\n",
    "    nll = compute_nll_score(solution_df, oof_df)\n",
    "    return nll\n",
    "\n",
    "def generate_geological_features(X):\n",
    "    \"\"\"\n",
    "    Generate additional geological-domain specific features\n",
    "    \"\"\"\n",
    "    # Extract the last 50 points for each sample\n",
    "    historical_features = []\n",
    "    \n",
    "    # Find columns that start with 'raw_'\n",
    "    raw_cols = [col for col in range(X.shape[1]) if col >= X.shape[1] - 50]\n",
    "    \n",
    "    if len(raw_cols) >= 10:\n",
    "        # Get the raw values\n",
    "        raw_data = X[:, raw_cols]\n",
    "        \n",
    "        # Calculate local slopes (first derivative)\n",
    "        slopes = np.diff(raw_data, axis=1)\n",
    "        mean_slope = np.mean(slopes, axis=1).reshape(-1, 1)\n",
    "        std_slope = np.std(slopes, axis=1).reshape(-1, 1)\n",
    "        max_slope = np.max(np.abs(slopes), axis=1).reshape(-1, 1)\n",
    "        \n",
    "        # Calculate curvature (second derivative)\n",
    "        curvature = np.diff(slopes, axis=1)\n",
    "        mean_curv = np.mean(curvature, axis=1).reshape(-1, 1)\n",
    "        std_curv = np.std(curvature, axis=1).reshape(-1, 1)\n",
    "        max_curv = np.max(np.abs(curvature), axis=1).reshape(-1, 1)\n",
    "        \n",
    "        # Create features from wavelets\n",
    "        from scipy import signal\n",
    "        wavelet_features = []\n",
    "        for wl in ['haar', 'db1', 'sym2']:\n",
    "            try:\n",
    "                coeffs = np.array([signal.cwt(row, signal.ricker, [2, 4, 8, 16]) for row in raw_data])\n",
    "                wavelet_stats = np.hstack([\n",
    "                    np.mean(coeffs, axis=(1, 2)).reshape(-1, 1),\n",
    "                    np.std(coeffs, axis=(1, 2)).reshape(-1, 1),\n",
    "                    np.max(coeffs, axis=(1, 2)).reshape(-1, 1),\n",
    "                    np.min(coeffs, axis=(1, 2)).reshape(-1, 1)\n",
    "                ])\n",
    "                wavelet_features.append(wavelet_stats)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if wavelet_features:\n",
    "            wavelet_features = np.hstack(wavelet_features)\n",
    "            \n",
    "            # Combine all features\n",
    "            geo_features = np.hstack([\n",
    "                mean_slope, std_slope, max_slope,\n",
    "                mean_curv, std_curv, max_curv,\n",
    "                wavelet_features\n",
    "            ])\n",
    "            \n",
    "            # Concatenate original features with new ones\n",
    "            X_enhanced = np.hstack([X, geo_features])\n",
    "            return X_enhanced\n",
    "    \n",
    "    return X\n",
    "\n",
    "class OptimizeXGBoost:\n",
    "    \"\"\"\n",
    "    Optuna optimization for XGBoost hyperparameters\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, n_trials=50):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_trials = n_trials\n",
    "        self.best_params = None\n",
    "        self.best_score = float('inf')\n",
    "        \n",
    "    def objective(self, trial):\n",
    "        # Define hyperparameters to optimize\n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 1.0, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "            'tree_method': 'gpu_hist' if torch.cuda.is_available() else 'hist',\n",
    "            'predictor': 'gpu_predictor' if torch.cuda.is_available() else 'cpu_predictor',\n",
    "            'seed': SEED\n",
    "        }\n",
    "        \n",
    "        # Perform k-fold cross validation with current parameters\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        # We'll sample a subset of target positions for efficiency\n",
    "        sampled_positions = np.random.choice(range(300), size=10, replace=False)\n",
    "        \n",
    "        scores = []\n",
    "        for pos in sampled_positions:\n",
    "            pos_scores = []\n",
    "            \n",
    "            for train_idx, val_idx in kf.split(self.X):\n",
    "                X_train, X_val = self.X[train_idx], self.X[val_idx]\n",
    "                y_train, y_val = self.y[train_idx, pos], self.y[val_idx, pos]\n",
    "                \n",
    "                model = train_xgboost_model(X_train, y_train, X_val, y_val, params, \n",
    "                                           num_boost_round=1000, early_stopping_rounds=50)\n",
    "                \n",
    "                val_preds = predict_output_sequence(model, X_val)\n",
    "                \n",
    "                mse = mean_squared_error(y_val, val_preds)\n",
    "                pos_scores.append(mse)\n",
    "            \n",
    "            scores.append(np.mean(pos_scores))\n",
    "        \n",
    "        mean_score = np.mean(scores)\n",
    "        \n",
    "        if mean_score < self.best_score:\n",
    "            self.best_score = mean_score\n",
    "            self.best_params = params\n",
    "        \n",
    "        return mean_score\n",
    "    \n",
    "    def optimize(self):\n",
    "        wandb_kwargs = {\"project\": \"geology-forecast-xgb-optuna\"}\n",
    "        wandb_callback = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs)\n",
    "        \n",
    "        sampler = TPESampler(seed=SEED)\n",
    "        study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "        study.optimize(self.objective, n_trials=self.n_trials, callbacks=[wandb_callback])\n",
    "        \n",
    "        print(f\"Best trial: {study.best_trial.number}\")\n",
    "        print(f\"Best MSE: {study.best_value:.6f}\")\n",
    "        print(f\"Best hyperparameters: {study.best_params}\")\n",
    "        \n",
    "        return study.best_params\n",
    "\n",
    "def xgb_pipeline(X_features, y, X_features_test, optimize=True, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Complete XGBoost training pipeline with feature engineering and model tuning\n",
    "    \"\"\"\n",
    "    print(\"Starting XGBoost pipeline...\")\n",
    "    \n",
    "    # Original feature shape\n",
    "    print(f\"Original feature shape: {X_features.shape}\")\n",
    "    \n",
    "    # Generate additional geological features\n",
    "    X_features = generate_geological_features(X_features)\n",
    "    X_features_test = generate_geological_features(X_features_test)\n",
    "    \n",
    "    print(f\"Enhanced feature shape: {X_features.shape}\")\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_features_scaled = scaler.fit_transform(X_features)\n",
    "    X_features_test_scaled = scaler.transform(X_features_test)\n",
    "    \n",
    "    # Optimize hyperparameters\n",
    "    if optimize:\n",
    "        print(\"Optimizing XGBoost hyperparameters...\")\n",
    "        optimizer = OptimizeXGBoost(X_features_scaled, y, n_trials=1)\n",
    "        best_params = optimizer.optimize()\n",
    "    else:\n",
    "        best_params = get_default_xgb_params()\n",
    "    \n",
    "    print(f\"Training with parameters: {best_params}\")\n",
    "    \n",
    "    # Train models for multiple positions\n",
    "    models, oof_preds, test_preds = xgb_multioutput_training(\n",
    "        X_features_scaled, y, X_features_test_scaled, \n",
    "        params=best_params, n_splits=5\n",
    "    )\n",
    "    \n",
    "    # Calculate NLL score on OOF predictions\n",
    "    geology_ids = train['geology_id'].values\n",
    "    nll = nll_cv_score(oof_preds, y, geology_ids)\n",
    "    print(f\"OOF NLL Score: {nll:.6f}\")\n",
    "    \n",
    "    # Create and save submission\n",
    "    submission = create_submission_xgb(test_preds, best_params, nll)\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_model_predictions(submission, {\"model_type\": \"XGBoost\"})\n",
    "    \n",
    "    return models, oof_preds, test_preds, nll, submission\n",
    "\n",
    "def create_submission_xgb(base_predictions, config, val_nll_score):\n",
    "    \"\"\"\n",
    "    Create submission file from XGBoost predictions\n",
    "    \"\"\"\n",
    "    submission = sub.copy()\n",
    "    \n",
    "    for i in range(300):\n",
    "        col_name = str(i+1)\n",
    "        submission[col_name] = base_predictions[:, i]\n",
    "    \n",
    "    # Generate diverse realizations for different scenarios\n",
    "    realizations = generate_diverse_realizations(\n",
    "        base_predictions, \n",
    "        num_samples=10, \n",
    "        diversity_factor=0.15\n",
    "    )\n",
    "    \n",
    "    for r_idx in range(1, 10): \n",
    "        for i in range(300):\n",
    "            col_name = f\"r_{r_idx}_pos_{i+1}\"\n",
    "            submission[col_name] = realizations[r_idx][:, i]\n",
    "    \n",
    "    submission_file = f\"submission_XGBoost_{val_nll_score:.6f}.csv\"\n",
    "    submission.to_csv(submission_file, index=False)\n",
    "    print(f\"\\nSubmission file saved: {submission_file}\")\n",
    "    \n",
    "    expected_cols = sub.columns.tolist()\n",
    "    actual_cols = submission.columns.tolist()\n",
    "    \n",
    "    if set(expected_cols) != set(actual_cols):\n",
    "        print(\"WARNING: Submission columns don't match expected format!\")\n",
    "        missing = set(expected_cols) - set(actual_cols)\n",
    "        extra = set(actual_cols) - set(expected_cols)\n",
    "        if missing:\n",
    "            print(f\"Missing columns: {missing}\")\n",
    "        if extra:\n",
    "            print(f\"Extra columns: {extra}\")\n",
    "    else:\n",
    "        print(\"Submission format validated successfully!\")\n",
    "    \n",
    "    return submission\n",
    "\n",
    "def visualize_feature_importance(models, feature_names):\n",
    "    \"\"\"\n",
    "    Visualize feature importance across models\n",
    "    \"\"\"\n",
    "    importance_df = pd.DataFrame()\n",
    "    \n",
    "    # Sample a few positions to analyze\n",
    "    positions = list(models.keys())\n",
    "    sample_positions = np.random.choice(positions, min(5, len(positions)), replace=False)\n",
    "    \n",
    "    for pos in sample_positions:\n",
    "        # Get the first fold model for this position\n",
    "        model = models[pos][0]\n",
    "        \n",
    "        # Get feature importance\n",
    "        importance = model.get_score(importance_type='gain')\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        pos_df = pd.DataFrame({\n",
    "            'Feature': list(importance.keys()),\n",
    "            'Importance': list(importance.values()),\n",
    "            'Position': f'Pos {pos}'\n",
    "        })\n",
    "        \n",
    "        importance_df = pd.concat([importance_df, pos_df])\n",
    "    \n",
    "    # Visualize top features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Get top 20 features by average importance\n",
    "    top_features = importance_df.groupby('Feature')['Importance'].mean().nlargest(20).index\n",
    "    \n",
    "    # Filter to only these features\n",
    "    plot_df = importance_df[importance_df['Feature'].isin(top_features)]\n",
    "    \n",
    "    sns.barplot(data=plot_df, x='Importance', y='Feature', hue='Position')\n",
    "    plt.title('Feature Importance by Position')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    try:\n",
    "        wandb.log({\"feature_importance\": wandb.Image(plt)})\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna-integration[wandb]\n",
      "  Downloading optuna_integration-4.3.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: optuna in /opt/venv/lib/python3.10/site-packages (from optuna-integration[wandb]) (4.3.0)\n",
      "Requirement already satisfied: wandb in /opt/venv/lib/python3.10/site-packages (from optuna-integration[wandb]) (0.19.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/venv/lib/python3.10/site-packages (from optuna->optuna-integration[wandb]) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /opt/venv/lib/python3.10/site-packages (from optuna->optuna-integration[wandb]) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.10/site-packages (from optuna->optuna-integration[wandb]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.10/site-packages (from optuna->optuna-integration[wandb]) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/venv/lib/python3.10/site-packages (from optuna->optuna-integration[wandb]) (2.0.40)\n",
      "Requirement already satisfied: tqdm in /opt/venv/lib/python3.10/site-packages (from optuna->optuna-integration[wandb]) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /opt/venv/lib/python3.10/site-packages (from optuna->optuna-integration[wandb]) (6.0.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (2.11.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (2.26.1)\n",
      "Requirement already satisfied: setproctitle in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (79.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/venv/lib/python3.10/site-packages (from wandb->optuna-integration[wandb]) (4.12.2)\n",
      "Requirement already satisfied: Mako in /opt/venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->optuna-integration[wandb]) (1.3.10)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/venv/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->optuna-integration[wandb]) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/venv/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->optuna-integration[wandb]) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/venv/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb->optuna-integration[wandb]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/venv/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb->optuna-integration[wandb]) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/venv/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb->optuna-integration[wandb]) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->optuna-integration[wandb]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->optuna-integration[wandb]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->optuna-integration[wandb]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/venv/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->optuna-integration[wandb]) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/venv/lib/python3.10/site-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[wandb]) (3.2.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/venv/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->optuna-integration[wandb]) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration[wandb]) (2.1.5)\n",
      "Downloading optuna_integration-4.3.0-py3-none-any.whl (98 kB)\n",
      "Installing collected packages: optuna-integration\n",
      "Successfully installed optuna-integration-4.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna-integration[wandb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting XGBoost pipeline...\n",
      "Original feature shape: (1510, 397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-26 15:21:37,744] A new study created in memory with name: no-name-af1f0f8d-88fc-4087-b05a-da0077c315e6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced feature shape: (1510, 415)\n",
      "Optimizing XGBoost hyperparameters...\n",
      "[0]\ttrain-rmse:1.30884\tvalid-rmse:1.26892\n",
      "[100]\ttrain-rmse:0.80687\tvalid-rmse:0.78102\n",
      "[200]\ttrain-rmse:0.54287\tvalid-rmse:0.53492\n",
      "[300]\ttrain-rmse:0.41149\tvalid-rmse:0.42541\n",
      "[400]\ttrain-rmse:0.34765\tvalid-rmse:0.38591\n",
      "[500]\ttrain-rmse:0.31371\tvalid-rmse:0.37271\n",
      "[600]\ttrain-rmse:0.29039\tvalid-rmse:0.36742\n",
      "[700]\ttrain-rmse:0.27174\tvalid-rmse:0.36434\n",
      "[800]\ttrain-rmse:0.25709\tvalid-rmse:0.36347\n",
      "[900]\ttrain-rmse:0.24356\tvalid-rmse:0.36220\n",
      "[999]\ttrain-rmse:0.23168\tvalid-rmse:0.36175\n",
      "[0]\ttrain-rmse:1.32453\tvalid-rmse:1.20348\n",
      "[100]\ttrain-rmse:0.81748\tvalid-rmse:0.72238\n",
      "[200]\ttrain-rmse:0.55046\tvalid-rmse:0.48219\n",
      "[300]\ttrain-rmse:0.41795\tvalid-rmse:0.37905\n",
      "[400]\ttrain-rmse:0.35454\tvalid-rmse:0.34500\n",
      "[500]\ttrain-rmse:0.32090\tvalid-rmse:0.33687\n",
      "[544]\ttrain-rmse:0.30910\tvalid-rmse:0.33805\n",
      "[0]\ttrain-rmse:1.30813\tvalid-rmse:1.27200\n",
      "[100]\ttrain-rmse:0.80246\tvalid-rmse:0.80231\n",
      "[200]\ttrain-rmse:0.53629\tvalid-rmse:0.57054\n",
      "[300]\ttrain-rmse:0.40273\tvalid-rmse:0.46649\n",
      "[400]\ttrain-rmse:0.33735\tvalid-rmse:0.42688\n",
      "[500]\ttrain-rmse:0.30216\tvalid-rmse:0.41303\n",
      "[600]\ttrain-rmse:0.28060\tvalid-rmse:0.40861\n",
      "[700]\ttrain-rmse:0.26240\tvalid-rmse:0.40711\n",
      "[754]\ttrain-rmse:0.25418\tvalid-rmse:0.40721\n",
      "[0]\ttrain-rmse:1.29689\tvalid-rmse:1.31781\n",
      "[100]\ttrain-rmse:0.79275\tvalid-rmse:0.81942\n",
      "[200]\ttrain-rmse:0.52591\tvalid-rmse:0.58944\n",
      "[300]\ttrain-rmse:0.39157\tvalid-rmse:0.50478\n",
      "[400]\ttrain-rmse:0.32659\tvalid-rmse:0.48064\n",
      "[500]\ttrain-rmse:0.29225\tvalid-rmse:0.47556\n",
      "[600]\ttrain-rmse:0.27028\tvalid-rmse:0.47464\n",
      "[621]\ttrain-rmse:0.26638\tvalid-rmse:0.47476\n",
      "[0]\ttrain-rmse:1.26489\tvalid-rmse:1.43633\n",
      "[100]\ttrain-rmse:0.76834\tvalid-rmse:0.95313\n",
      "[200]\ttrain-rmse:0.50316\tvalid-rmse:0.72067\n",
      "[300]\ttrain-rmse:0.37085\tvalid-rmse:0.62308\n",
      "[400]\ttrain-rmse:0.30836\tvalid-rmse:0.58511\n",
      "[500]\ttrain-rmse:0.27724\tvalid-rmse:0.56964\n",
      "[600]\ttrain-rmse:0.25715\tvalid-rmse:0.56263\n",
      "[700]\ttrain-rmse:0.24135\tvalid-rmse:0.55842\n",
      "[800]\ttrain-rmse:0.22888\tvalid-rmse:0.55634\n",
      "[900]\ttrain-rmse:0.21799\tvalid-rmse:0.55581\n",
      "[943]\ttrain-rmse:0.21388\tvalid-rmse:0.55590\n",
      "[0]\ttrain-rmse:1.51511\tvalid-rmse:1.47529\n",
      "[100]\ttrain-rmse:0.93278\tvalid-rmse:0.91354\n",
      "[200]\ttrain-rmse:0.62510\tvalid-rmse:0.63043\n",
      "[300]\ttrain-rmse:0.47198\tvalid-rmse:0.50503\n",
      "[400]\ttrain-rmse:0.39870\tvalid-rmse:0.45802\n",
      "[500]\ttrain-rmse:0.35829\tvalid-rmse:0.44171\n",
      "[600]\ttrain-rmse:0.33080\tvalid-rmse:0.43573\n",
      "[700]\ttrain-rmse:0.30916\tvalid-rmse:0.43146\n",
      "[800]\ttrain-rmse:0.29205\tvalid-rmse:0.42932\n",
      "[900]\ttrain-rmse:0.27560\tvalid-rmse:0.42792\n",
      "[999]\ttrain-rmse:0.26164\tvalid-rmse:0.42704\n",
      "[0]\ttrain-rmse:1.53392\tvalid-rmse:1.39697\n",
      "[100]\ttrain-rmse:0.94504\tvalid-rmse:0.84318\n",
      "[200]\ttrain-rmse:0.63379\tvalid-rmse:0.56496\n",
      "[300]\ttrain-rmse:0.47886\tvalid-rmse:0.44591\n",
      "[400]\ttrain-rmse:0.40398\tvalid-rmse:0.40669\n",
      "[500]\ttrain-rmse:0.36509\tvalid-rmse:0.39933\n",
      "[554]\ttrain-rmse:0.34848\tvalid-rmse:0.40081\n",
      "[0]\ttrain-rmse:1.51263\tvalid-rmse:1.48556\n",
      "[100]\ttrain-rmse:0.92572\tvalid-rmse:0.94403\n",
      "[200]\ttrain-rmse:0.61550\tvalid-rmse:0.67708\n",
      "[300]\ttrain-rmse:0.45880\tvalid-rmse:0.55769\n",
      "[400]\ttrain-rmse:0.38151\tvalid-rmse:0.51089\n",
      "[500]\ttrain-rmse:0.34037\tvalid-rmse:0.49415\n",
      "[600]\ttrain-rmse:0.31484\tvalid-rmse:0.48854\n",
      "[700]\ttrain-rmse:0.29330\tvalid-rmse:0.48671\n",
      "[779]\ttrain-rmse:0.27940\tvalid-rmse:0.48737\n",
      "[0]\ttrain-rmse:1.50103\tvalid-rmse:1.53265\n",
      "[100]\ttrain-rmse:0.91497\tvalid-rmse:0.95988\n",
      "[200]\ttrain-rmse:0.60363\tvalid-rmse:0.69804\n",
      "[300]\ttrain-rmse:0.44550\tvalid-rmse:0.60318\n",
      "[400]\ttrain-rmse:0.36850\tvalid-rmse:0.57809\n",
      "[500]\ttrain-rmse:0.32788\tvalid-rmse:0.57239\n",
      "[600]\ttrain-rmse:0.30206\tvalid-rmse:0.57177\n",
      "[622]\ttrain-rmse:0.29730\tvalid-rmse:0.57172\n",
      "[0]\ttrain-rmse:1.47179\tvalid-rmse:1.64134\n",
      "[100]\ttrain-rmse:0.89653\tvalid-rmse:1.07356\n",
      "[200]\ttrain-rmse:0.58949\tvalid-rmse:0.79853\n",
      "[300]\ttrain-rmse:0.43576\tvalid-rmse:0.68209\n",
      "[400]\ttrain-rmse:0.36279\tvalid-rmse:0.63712\n",
      "[500]\ttrain-rmse:0.32614\tvalid-rmse:0.61954\n",
      "[600]\ttrain-rmse:0.30191\tvalid-rmse:0.61262\n",
      "[700]\ttrain-rmse:0.28283\tvalid-rmse:0.60803\n",
      "[800]\ttrain-rmse:0.26755\tvalid-rmse:0.60551\n",
      "[900]\ttrain-rmse:0.25443\tvalid-rmse:0.60458\n",
      "[999]\ttrain-rmse:0.24214\tvalid-rmse:0.60443\n",
      "[0]\ttrain-rmse:9.93248\tvalid-rmse:9.86610\n",
      "[100]\ttrain-rmse:6.41428\tvalid-rmse:6.78777\n",
      "[200]\ttrain-rmse:4.55162\tvalid-rmse:5.34630\n",
      "[300]\ttrain-rmse:3.59537\tvalid-rmse:4.77073\n",
      "[400]\ttrain-rmse:3.08828\tvalid-rmse:4.55478\n",
      "[500]\ttrain-rmse:2.79127\tvalid-rmse:4.48046\n",
      "[600]\ttrain-rmse:2.57477\tvalid-rmse:4.44861\n",
      "[700]\ttrain-rmse:2.42163\tvalid-rmse:4.42639\n",
      "[800]\ttrain-rmse:2.30931\tvalid-rmse:4.41548\n",
      "[860]\ttrain-rmse:2.24985\tvalid-rmse:4.41510\n",
      "[0]\ttrain-rmse:10.00998\tvalid-rmse:9.55125\n",
      "[100]\ttrain-rmse:6.39541\tvalid-rmse:6.61525\n",
      "[200]\ttrain-rmse:4.47805\tvalid-rmse:5.46815\n",
      "[300]\ttrain-rmse:3.48789\tvalid-rmse:5.14117\n",
      "[400]\ttrain-rmse:2.95618\tvalid-rmse:5.09546\n",
      "[435]\ttrain-rmse:2.82981\tvalid-rmse:5.10353\n",
      "[0]\ttrain-rmse:9.89048\tvalid-rmse:10.02780\n",
      "[100]\ttrain-rmse:6.34103\tvalid-rmse:7.02505\n",
      "[200]\ttrain-rmse:4.48337\tvalid-rmse:5.68339\n",
      "[300]\ttrain-rmse:3.51898\tvalid-rmse:5.16447\n",
      "[400]\ttrain-rmse:3.00555\tvalid-rmse:4.96390\n",
      "[500]\ttrain-rmse:2.69985\tvalid-rmse:4.89810\n",
      "[600]\ttrain-rmse:2.49911\tvalid-rmse:4.86584\n",
      "[700]\ttrain-rmse:2.35199\tvalid-rmse:4.85774\n",
      "[734]\ttrain-rmse:2.31077\tvalid-rmse:4.85975\n",
      "[0]\ttrain-rmse:9.87333\tvalid-rmse:10.10404\n",
      "[100]\ttrain-rmse:6.32340\tvalid-rmse:6.84099\n",
      "[200]\ttrain-rmse:4.43975\tvalid-rmse:5.52879\n",
      "[300]\ttrain-rmse:3.47141\tvalid-rmse:5.11868\n",
      "[400]\ttrain-rmse:2.94878\tvalid-rmse:5.03379\n",
      "[441]\ttrain-rmse:2.80536\tvalid-rmse:5.03698\n",
      "[0]\ttrain-rmse:9.87336\tvalid-rmse:10.09682\n",
      "[100]\ttrain-rmse:6.36596\tvalid-rmse:6.80776\n",
      "[200]\ttrain-rmse:4.51530\tvalid-rmse:5.38132\n",
      "[300]\ttrain-rmse:3.54961\tvalid-rmse:4.89150\n",
      "[400]\ttrain-rmse:3.04002\tvalid-rmse:4.77005\n",
      "[500]\ttrain-rmse:2.73614\tvalid-rmse:4.76164\n",
      "[511]\ttrain-rmse:2.70858\tvalid-rmse:4.76079\n",
      "[0]\ttrain-rmse:4.55738\tvalid-rmse:4.43334\n",
      "[100]\ttrain-rmse:2.95360\tvalid-rmse:2.95532\n",
      "[200]\ttrain-rmse:2.12340\tvalid-rmse:2.26796\n",
      "[300]\ttrain-rmse:1.71231\tvalid-rmse:1.98157\n",
      "[400]\ttrain-rmse:1.49521\tvalid-rmse:1.87204\n",
      "[500]\ttrain-rmse:1.36514\tvalid-rmse:1.82777\n",
      "[600]\ttrain-rmse:1.26450\tvalid-rmse:1.80740\n",
      "[700]\ttrain-rmse:1.18580\tvalid-rmse:1.79011\n",
      "[800]\ttrain-rmse:1.12259\tvalid-rmse:1.78171\n",
      "[900]\ttrain-rmse:1.06544\tvalid-rmse:1.77869\n",
      "[931]\ttrain-rmse:1.04606\tvalid-rmse:1.77817\n",
      "[0]\ttrain-rmse:4.53745\tvalid-rmse:4.51926\n",
      "[100]\ttrain-rmse:2.86322\tvalid-rmse:3.23653\n",
      "[200]\ttrain-rmse:1.98927\tvalid-rmse:2.72329\n",
      "[300]\ttrain-rmse:1.54956\tvalid-rmse:2.56249\n",
      "[400]\ttrain-rmse:1.32575\tvalid-rmse:2.53082\n",
      "[457]\ttrain-rmse:1.24330\tvalid-rmse:2.53300\n",
      "[0]\ttrain-rmse:4.50027\tvalid-rmse:4.66141\n",
      "[100]\ttrain-rmse:2.88302\tvalid-rmse:3.26730\n",
      "[200]\ttrain-rmse:2.04636\tvalid-rmse:2.62705\n",
      "[300]\ttrain-rmse:1.62368\tvalid-rmse:2.36261\n",
      "[400]\ttrain-rmse:1.40638\tvalid-rmse:2.25679\n",
      "[500]\ttrain-rmse:1.27206\tvalid-rmse:2.21705\n",
      "[600]\ttrain-rmse:1.17735\tvalid-rmse:2.20622\n",
      "[700]\ttrain-rmse:1.10342\tvalid-rmse:2.20353\n",
      "[797]\ttrain-rmse:1.04540\tvalid-rmse:2.20270\n",
      "[0]\ttrain-rmse:4.54409\tvalid-rmse:4.49245\n",
      "[100]\ttrain-rmse:2.93608\tvalid-rmse:2.94210\n",
      "[200]\ttrain-rmse:2.10490\tvalid-rmse:2.28862\n",
      "[300]\ttrain-rmse:1.68572\tvalid-rmse:2.08899\n",
      "[400]\ttrain-rmse:1.46930\tvalid-rmse:2.05020\n",
      "[469]\ttrain-rmse:1.37802\tvalid-rmse:2.05668\n",
      "[0]\ttrain-rmse:4.51957\tvalid-rmse:4.58340\n",
      "[100]\ttrain-rmse:2.94014\tvalid-rmse:2.96047\n",
      "[200]\ttrain-rmse:2.12838\tvalid-rmse:2.19712\n",
      "[300]\ttrain-rmse:1.72427\tvalid-rmse:1.89186\n",
      "[400]\ttrain-rmse:1.51475\tvalid-rmse:1.78333\n",
      "[500]\ttrain-rmse:1.38569\tvalid-rmse:1.75156\n",
      "[600]\ttrain-rmse:1.28770\tvalid-rmse:1.74597\n",
      "[640]\ttrain-rmse:1.25431\tvalid-rmse:1.74808\n",
      "[0]\ttrain-rmse:4.07600\tvalid-rmse:3.96561\n",
      "[100]\ttrain-rmse:2.66253\tvalid-rmse:2.65774\n",
      "[200]\ttrain-rmse:1.93584\tvalid-rmse:2.05391\n",
      "[300]\ttrain-rmse:1.57946\tvalid-rmse:1.80208\n",
      "[400]\ttrain-rmse:1.39028\tvalid-rmse:1.70392\n",
      "[500]\ttrain-rmse:1.27585\tvalid-rmse:1.66893\n",
      "[600]\ttrain-rmse:1.18466\tvalid-rmse:1.65344\n",
      "[700]\ttrain-rmse:1.11385\tvalid-rmse:1.63892\n",
      "[800]\ttrain-rmse:1.05621\tvalid-rmse:1.63101\n",
      "[900]\ttrain-rmse:1.00202\tvalid-rmse:1.62930\n",
      "[929]\ttrain-rmse:0.98619\tvalid-rmse:1.62892\n",
      "[0]\ttrain-rmse:4.04942\tvalid-rmse:4.07739\n",
      "[100]\ttrain-rmse:2.56864\tvalid-rmse:2.96666\n",
      "[200]\ttrain-rmse:1.80117\tvalid-rmse:2.52962\n",
      "[300]\ttrain-rmse:1.41829\tvalid-rmse:2.39711\n",
      "[400]\ttrain-rmse:1.22421\tvalid-rmse:2.37618\n",
      "[459]\ttrain-rmse:1.15054\tvalid-rmse:2.37814\n",
      "[0]\ttrain-rmse:4.01734\tvalid-rmse:4.19804\n",
      "[100]\ttrain-rmse:2.58835\tvalid-rmse:2.98135\n",
      "[200]\ttrain-rmse:1.85521\tvalid-rmse:2.42337\n",
      "[300]\ttrain-rmse:1.48862\tvalid-rmse:2.19690\n",
      "[400]\ttrain-rmse:1.30029\tvalid-rmse:2.11050\n",
      "[500]\ttrain-rmse:1.18443\tvalid-rmse:2.07986\n",
      "[600]\ttrain-rmse:1.09924\tvalid-rmse:2.07079\n",
      "[700]\ttrain-rmse:1.03125\tvalid-rmse:2.06727\n",
      "[772]\ttrain-rmse:0.98975\tvalid-rmse:2.06633\n",
      "[0]\ttrain-rmse:4.07121\tvalid-rmse:3.98950\n",
      "[100]\ttrain-rmse:2.65726\tvalid-rmse:2.61562\n",
      "[200]\ttrain-rmse:1.93312\tvalid-rmse:2.03583\n",
      "[300]\ttrain-rmse:1.57305\tvalid-rmse:1.85905\n",
      "[400]\ttrain-rmse:1.38591\tvalid-rmse:1.83008\n",
      "[437]\ttrain-rmse:1.33997\tvalid-rmse:1.83038\n",
      "[0]\ttrain-rmse:4.05169\tvalid-rmse:4.06155\n",
      "[100]\ttrain-rmse:2.66528\tvalid-rmse:2.60206\n",
      "[200]\ttrain-rmse:1.95993\tvalid-rmse:1.90238\n",
      "[300]\ttrain-rmse:1.61179\tvalid-rmse:1.62037\n",
      "[400]\ttrain-rmse:1.43125\tvalid-rmse:1.51718\n",
      "[500]\ttrain-rmse:1.31772\tvalid-rmse:1.48631\n",
      "[597]\ttrain-rmse:1.23043\tvalid-rmse:1.48048\n",
      "[0]\ttrain-rmse:1.54971\tvalid-rmse:1.50962\n",
      "[100]\ttrain-rmse:0.95396\tvalid-rmse:0.93567\n",
      "[200]\ttrain-rmse:0.63914\tvalid-rmse:0.64630\n",
      "[300]\ttrain-rmse:0.48251\tvalid-rmse:0.51799\n",
      "[400]\ttrain-rmse:0.40739\tvalid-rmse:0.47067\n",
      "[500]\ttrain-rmse:0.36626\tvalid-rmse:0.45387\n",
      "[600]\ttrain-rmse:0.33815\tvalid-rmse:0.44721\n",
      "[700]\ttrain-rmse:0.31615\tvalid-rmse:0.44264\n",
      "[800]\ttrain-rmse:0.29865\tvalid-rmse:0.44074\n",
      "[900]\ttrain-rmse:0.28212\tvalid-rmse:0.43952\n",
      "[999]\ttrain-rmse:0.26777\tvalid-rmse:0.43853\n",
      "[0]\ttrain-rmse:1.56897\tvalid-rmse:1.42950\n",
      "[100]\ttrain-rmse:0.96648\tvalid-rmse:0.86364\n",
      "[200]\ttrain-rmse:0.64780\tvalid-rmse:0.57879\n",
      "[300]\ttrain-rmse:0.48913\tvalid-rmse:0.45799\n",
      "[400]\ttrain-rmse:0.41250\tvalid-rmse:0.41826\n",
      "[500]\ttrain-rmse:0.37241\tvalid-rmse:0.41075\n",
      "[553]\ttrain-rmse:0.35552\tvalid-rmse:0.41237\n",
      "[0]\ttrain-rmse:1.54689\tvalid-rmse:1.52128\n",
      "[100]\ttrain-rmse:0.94653\tvalid-rmse:0.96720\n",
      "[200]\ttrain-rmse:0.62891\tvalid-rmse:0.69416\n",
      "[300]\ttrain-rmse:0.46841\tvalid-rmse:0.57250\n",
      "[400]\ttrain-rmse:0.38926\tvalid-rmse:0.52458\n",
      "[500]\ttrain-rmse:0.34705\tvalid-rmse:0.50731\n",
      "[600]\ttrain-rmse:0.32091\tvalid-rmse:0.50162\n",
      "[700]\ttrain-rmse:0.29883\tvalid-rmse:0.49980\n",
      "[753]\ttrain-rmse:0.28875\tvalid-rmse:0.50034\n",
      "[0]\ttrain-rmse:1.53520\tvalid-rmse:1.56872\n",
      "[100]\ttrain-rmse:0.93543\tvalid-rmse:0.98376\n",
      "[200]\ttrain-rmse:0.61654\tvalid-rmse:0.71633\n",
      "[300]\ttrain-rmse:0.45430\tvalid-rmse:0.61944\n",
      "[400]\ttrain-rmse:0.37518\tvalid-rmse:0.59408\n",
      "[500]\ttrain-rmse:0.33335\tvalid-rmse:0.58823\n",
      "[600]\ttrain-rmse:0.30718\tvalid-rmse:0.58753\n",
      "[640]\ttrain-rmse:0.29820\tvalid-rmse:0.58760\n",
      "[0]\ttrain-rmse:1.50642\tvalid-rmse:1.67571\n",
      "[100]\ttrain-rmse:0.91794\tvalid-rmse:1.09443\n",
      "[200]\ttrain-rmse:0.60385\tvalid-rmse:0.81286\n",
      "[300]\ttrain-rmse:0.44632\tvalid-rmse:0.69342\n",
      "[400]\ttrain-rmse:0.37159\tvalid-rmse:0.64720\n",
      "[500]\ttrain-rmse:0.33390\tvalid-rmse:0.62967\n",
      "[600]\ttrain-rmse:0.30865\tvalid-rmse:0.62236\n",
      "[700]\ttrain-rmse:0.28908\tvalid-rmse:0.61757\n",
      "[800]\ttrain-rmse:0.27347\tvalid-rmse:0.61501\n",
      "[900]\ttrain-rmse:0.25984\tvalid-rmse:0.61406\n",
      "[999]\ttrain-rmse:0.24752\tvalid-rmse:0.61383\n",
      "[0]\ttrain-rmse:5.37309\tvalid-rmse:5.22561\n",
      "[100]\ttrain-rmse:3.46159\tvalid-rmse:3.48213\n",
      "[200]\ttrain-rmse:2.46240\tvalid-rmse:2.65912\n",
      "[300]\ttrain-rmse:1.96137\tvalid-rmse:2.31838\n",
      "[400]\ttrain-rmse:1.69824\tvalid-rmse:2.19143\n",
      "[500]\ttrain-rmse:1.53942\tvalid-rmse:2.13920\n",
      "[600]\ttrain-rmse:1.42130\tvalid-rmse:2.11121\n",
      "[700]\ttrain-rmse:1.33077\tvalid-rmse:2.09198\n",
      "[800]\ttrain-rmse:1.25975\tvalid-rmse:2.08104\n",
      "[900]\ttrain-rmse:1.19902\tvalid-rmse:2.07997\n",
      "[931]\ttrain-rmse:1.18065\tvalid-rmse:2.08029\n",
      "[0]\ttrain-rmse:5.36107\tvalid-rmse:5.28059\n",
      "[100]\ttrain-rmse:3.37331\tvalid-rmse:3.73118\n",
      "[200]\ttrain-rmse:2.32798\tvalid-rmse:3.09172\n",
      "[300]\ttrain-rmse:1.79715\tvalid-rmse:2.89179\n",
      "[400]\ttrain-rmse:1.52416\tvalid-rmse:2.85554\n",
      "[457]\ttrain-rmse:1.42586\tvalid-rmse:2.85913\n",
      "[0]\ttrain-rmse:5.32000\tvalid-rmse:5.43923\n",
      "[100]\ttrain-rmse:3.39312\tvalid-rmse:3.76906\n",
      "[200]\ttrain-rmse:2.38892\tvalid-rmse:2.99365\n",
      "[300]\ttrain-rmse:1.87658\tvalid-rmse:2.66497\n",
      "[400]\ttrain-rmse:1.61168\tvalid-rmse:2.53625\n",
      "[500]\ttrain-rmse:1.45112\tvalid-rmse:2.48581\n",
      "[600]\ttrain-rmse:1.34011\tvalid-rmse:2.46759\n",
      "[700]\ttrain-rmse:1.25485\tvalid-rmse:2.46288\n",
      "[800]\ttrain-rmse:1.18797\tvalid-rmse:2.46114\n",
      "[818]\ttrain-rmse:1.17625\tvalid-rmse:2.46157\n",
      "[0]\ttrain-rmse:5.34563\tvalid-rmse:5.34242\n",
      "[100]\ttrain-rmse:3.42107\tvalid-rmse:3.50544\n",
      "[200]\ttrain-rmse:2.41490\tvalid-rmse:2.74352\n",
      "[300]\ttrain-rmse:1.90436\tvalid-rmse:2.50770\n",
      "[400]\ttrain-rmse:1.63868\tvalid-rmse:2.45795\n",
      "[460]\ttrain-rmse:1.54153\tvalid-rmse:2.46230\n",
      "[0]\ttrain-rmse:5.31330\tvalid-rmse:5.46302\n",
      "[100]\ttrain-rmse:3.42138\tvalid-rmse:3.57149\n",
      "[200]\ttrain-rmse:2.43593\tvalid-rmse:2.70044\n",
      "[300]\ttrain-rmse:1.94185\tvalid-rmse:2.36927\n",
      "[400]\ttrain-rmse:1.68543\tvalid-rmse:2.26257\n",
      "[500]\ttrain-rmse:1.53187\tvalid-rmse:2.23053\n",
      "[591]\ttrain-rmse:1.42779\tvalid-rmse:2.22503\n",
      "[0]\ttrain-rmse:9.06469\tvalid-rmse:9.00688\n",
      "[100]\ttrain-rmse:5.83001\tvalid-rmse:6.21599\n",
      "[200]\ttrain-rmse:4.11567\tvalid-rmse:4.90979\n",
      "[300]\ttrain-rmse:3.23522\tvalid-rmse:4.38007\n",
      "[400]\ttrain-rmse:2.76756\tvalid-rmse:4.18279\n",
      "[500]\ttrain-rmse:2.49628\tvalid-rmse:4.10558\n",
      "[600]\ttrain-rmse:2.30397\tvalid-rmse:4.07556\n",
      "[700]\ttrain-rmse:2.16260\tvalid-rmse:4.06101\n",
      "[800]\ttrain-rmse:2.05844\tvalid-rmse:4.05348\n",
      "[900]\ttrain-rmse:1.96990\tvalid-rmse:4.04748\n",
      "[965]\ttrain-rmse:1.91664\tvalid-rmse:4.04933\n",
      "[0]\ttrain-rmse:9.13257\tvalid-rmse:8.73547\n",
      "[100]\ttrain-rmse:5.80672\tvalid-rmse:6.04562\n",
      "[200]\ttrain-rmse:4.04375\tvalid-rmse:4.97798\n",
      "[300]\ttrain-rmse:3.13089\tvalid-rmse:4.66929\n",
      "[400]\ttrain-rmse:2.64803\tvalid-rmse:4.62693\n",
      "[449]\ttrain-rmse:2.49026\tvalid-rmse:4.63978\n",
      "[0]\ttrain-rmse:9.04003\tvalid-rmse:9.10076\n",
      "[100]\ttrain-rmse:5.79768\tvalid-rmse:6.27804\n",
      "[200]\ttrain-rmse:4.10461\tvalid-rmse:4.98664\n",
      "[300]\ttrain-rmse:3.22408\tvalid-rmse:4.45438\n",
      "[400]\ttrain-rmse:2.75742\tvalid-rmse:4.24748\n",
      "[500]\ttrain-rmse:2.47918\tvalid-rmse:4.17329\n",
      "[600]\ttrain-rmse:2.29369\tvalid-rmse:4.14276\n",
      "[700]\ttrain-rmse:2.15522\tvalid-rmse:4.13249\n",
      "[796]\ttrain-rmse:2.05620\tvalid-rmse:4.13235\n",
      "[0]\ttrain-rmse:9.01223\tvalid-rmse:9.22026\n",
      "[100]\ttrain-rmse:5.74803\tvalid-rmse:6.22002\n",
      "[200]\ttrain-rmse:4.01280\tvalid-rmse:5.01190\n",
      "[300]\ttrain-rmse:3.12004\tvalid-rmse:4.64359\n",
      "[400]\ttrain-rmse:2.64358\tvalid-rmse:4.56783\n",
      "[480]\ttrain-rmse:2.41331\tvalid-rmse:4.58385\n",
      "[0]\ttrain-rmse:9.00294\tvalid-rmse:9.25203\n",
      "[100]\ttrain-rmse:5.77546\tvalid-rmse:6.24990\n",
      "[200]\ttrain-rmse:4.06614\tvalid-rmse:4.95730\n",
      "[300]\ttrain-rmse:3.18004\tvalid-rmse:4.50916\n",
      "[400]\ttrain-rmse:2.71269\tvalid-rmse:4.39560\n",
      "[496]\ttrain-rmse:2.44741\tvalid-rmse:4.39630\n",
      "[0]\ttrain-rmse:3.64719\tvalid-rmse:3.54103\n",
      "[100]\ttrain-rmse:2.30725\tvalid-rmse:2.30491\n",
      "[200]\ttrain-rmse:1.60324\tvalid-rmse:1.72296\n",
      "[300]\ttrain-rmse:1.25529\tvalid-rmse:1.48908\n",
      "[400]\ttrain-rmse:1.07894\tvalid-rmse:1.40167\n",
      "[500]\ttrain-rmse:0.97892\tvalid-rmse:1.37065\n",
      "[600]\ttrain-rmse:0.90238\tvalid-rmse:1.36087\n",
      "[700]\ttrain-rmse:0.84260\tvalid-rmse:1.35426\n",
      "[800]\ttrain-rmse:0.79618\tvalid-rmse:1.35065\n",
      "[862]\ttrain-rmse:0.77011\tvalid-rmse:1.35183\n",
      "[0]\ttrain-rmse:3.68812\tvalid-rmse:3.36957\n",
      "[100]\ttrain-rmse:2.33567\tvalid-rmse:2.13091\n",
      "[200]\ttrain-rmse:1.63476\tvalid-rmse:1.54836\n",
      "[300]\ttrain-rmse:1.28576\tvalid-rmse:1.33116\n",
      "[400]\ttrain-rmse:1.11037\tvalid-rmse:1.27699\n",
      "[498]\ttrain-rmse:1.00888\tvalid-rmse:1.27633\n",
      "[0]\ttrain-rmse:3.56778\tvalid-rmse:3.85136\n",
      "[100]\ttrain-rmse:2.20530\tvalid-rmse:2.74133\n",
      "[200]\ttrain-rmse:1.48076\tvalid-rmse:2.23941\n",
      "[300]\ttrain-rmse:1.10835\tvalid-rmse:2.03561\n",
      "[400]\ttrain-rmse:0.91853\tvalid-rmse:1.95674\n",
      "[500]\ttrain-rmse:0.80926\tvalid-rmse:1.92641\n",
      "[600]\ttrain-rmse:0.74166\tvalid-rmse:1.91400\n",
      "[700]\ttrain-rmse:0.68892\tvalid-rmse:1.91066\n",
      "[800]\ttrain-rmse:0.64890\tvalid-rmse:1.90992\n",
      "[835]\ttrain-rmse:0.63836\tvalid-rmse:1.90988\n",
      "[0]\ttrain-rmse:3.62011\tvalid-rmse:3.65307\n",
      "[100]\ttrain-rmse:2.27658\tvalid-rmse:2.38330\n",
      "[200]\ttrain-rmse:1.57281\tvalid-rmse:1.84748\n",
      "[300]\ttrain-rmse:1.21788\tvalid-rmse:1.68056\n",
      "[400]\ttrain-rmse:1.03684\tvalid-rmse:1.64590\n",
      "[480]\ttrain-rmse:0.95106\tvalid-rmse:1.64686\n",
      "[0]\ttrain-rmse:3.60310\tvalid-rmse:3.71515\n",
      "[100]\ttrain-rmse:2.28950\tvalid-rmse:2.36387\n",
      "[200]\ttrain-rmse:1.60759\tvalid-rmse:1.70967\n",
      "[300]\ttrain-rmse:1.26753\tvalid-rmse:1.44039\n",
      "[400]\ttrain-rmse:1.09803\tvalid-rmse:1.34746\n",
      "[500]\ttrain-rmse:0.99725\tvalid-rmse:1.31719\n",
      "[600]\ttrain-rmse:0.92616\tvalid-rmse:1.31402\n",
      "[610]\ttrain-rmse:0.92041\tvalid-rmse:1.31433\n",
      "[0]\ttrain-rmse:9.58592\tvalid-rmse:9.51802\n",
      "[100]\ttrain-rmse:6.19629\tvalid-rmse:6.55377\n",
      "[200]\ttrain-rmse:4.40444\tvalid-rmse:5.17126\n",
      "[300]\ttrain-rmse:3.48445\tvalid-rmse:4.60745\n",
      "[400]\ttrain-rmse:2.99452\tvalid-rmse:4.39463\n",
      "[500]\ttrain-rmse:2.70709\tvalid-rmse:4.32146\n",
      "[600]\ttrain-rmse:2.49705\tvalid-rmse:4.28731\n",
      "[700]\ttrain-rmse:2.35049\tvalid-rmse:4.26355\n",
      "[800]\ttrain-rmse:2.24076\tvalid-rmse:4.25706\n",
      "[823]\ttrain-rmse:2.21662\tvalid-rmse:4.25656\n",
      "[0]\ttrain-rmse:9.66011\tvalid-rmse:9.21639\n",
      "[100]\ttrain-rmse:6.17573\tvalid-rmse:6.39002\n",
      "[200]\ttrain-rmse:4.33026\tvalid-rmse:5.28743\n",
      "[300]\ttrain-rmse:3.37609\tvalid-rmse:4.97008\n",
      "[400]\ttrain-rmse:2.86920\tvalid-rmse:4.92394\n",
      "[432]\ttrain-rmse:2.75712\tvalid-rmse:4.92906\n",
      "[0]\ttrain-rmse:9.54153\tvalid-rmse:9.68856\n",
      "[100]\ttrain-rmse:6.11841\tvalid-rmse:6.80315\n",
      "[200]\ttrain-rmse:4.32851\tvalid-rmse:5.51333\n",
      "[300]\ttrain-rmse:3.39766\tvalid-rmse:5.01093\n",
      "[400]\ttrain-rmse:2.90419\tvalid-rmse:4.82357\n",
      "[500]\ttrain-rmse:2.61024\tvalid-rmse:4.76270\n",
      "[600]\ttrain-rmse:2.41688\tvalid-rmse:4.73163\n",
      "[700]\ttrain-rmse:2.27416\tvalid-rmse:4.72141\n",
      "[722]\ttrain-rmse:2.24820\tvalid-rmse:4.72094\n",
      "[0]\ttrain-rmse:9.53119\tvalid-rmse:9.73791\n",
      "[100]\ttrain-rmse:6.11110\tvalid-rmse:6.58708\n",
      "[200]\ttrain-rmse:4.29820\tvalid-rmse:5.31302\n",
      "[300]\ttrain-rmse:3.36689\tvalid-rmse:4.91410\n",
      "[400]\ttrain-rmse:2.86448\tvalid-rmse:4.84101\n",
      "[440]\ttrain-rmse:2.73124\tvalid-rmse:4.84569\n",
      "[0]\ttrain-rmse:9.52643\tvalid-rmse:9.74954\n",
      "[100]\ttrain-rmse:6.14868\tvalid-rmse:6.58137\n",
      "[200]\ttrain-rmse:4.36687\tvalid-rmse:5.20699\n",
      "[300]\ttrain-rmse:3.43567\tvalid-rmse:4.73247\n",
      "[400]\ttrain-rmse:2.94377\tvalid-rmse:4.61773\n",
      "[495]\ttrain-rmse:2.66241\tvalid-rmse:4.61437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-26 15:25:36,808] Trial 0 finished with value: 8.130498995293056 and parameters: {'learning_rate': 0.005611516415334507, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'reg_alpha': 1.7699302940633311e-07, 'reg_lambda': 2.9152036385288193e-08, 'gamma': 0.08499808989182997}. Best is trial 0 with value: 8.130498995293056.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0\n",
      "Best MSE: 8.130499\n",
      "Best hyperparameters: {'learning_rate': 0.005611516415334507, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'reg_alpha': 1.7699302940633311e-07, 'reg_lambda': 2.9152036385288193e-08, 'gamma': 0.08499808989182997}\n",
      "Training with parameters: {'learning_rate': 0.005611516415334507, 'max_depth': 10, 'min_child_weight': 8, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'reg_alpha': 1.7699302940633311e-07, 'reg_lambda': 2.9152036385288193e-08, 'gamma': 0.08499808989182997}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea5d71767fa498d97825ea1deb6235b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training position models:   0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.03573\tvalid-rmse:0.03661\n",
      "[100]\ttrain-rmse:0.02309\tvalid-rmse:0.02459\n",
      "[200]\ttrain-rmse:0.01734\tvalid-rmse:0.01924\n",
      "[300]\ttrain-rmse:0.01459\tvalid-rmse:0.01673\n",
      "[400]\ttrain-rmse:0.01438\tvalid-rmse:0.01654\n",
      "[500]\ttrain-rmse:0.01438\tvalid-rmse:0.01654\n",
      "[534]\ttrain-rmse:0.01438\tvalid-rmse:0.01654\n",
      "[0]\ttrain-rmse:0.03655\tvalid-rmse:0.03324\n",
      "[100]\ttrain-rmse:0.02374\tvalid-rmse:0.02019\n",
      "[200]\ttrain-rmse:0.01793\tvalid-rmse:0.01403\n",
      "[300]\ttrain-rmse:0.01508\tvalid-rmse:0.01098\n",
      "[400]\ttrain-rmse:0.01493\tvalid-rmse:0.01082\n",
      "[485]\ttrain-rmse:0.01487\tvalid-rmse:0.01077\n",
      "[0]\ttrain-rmse:0.03625\tvalid-rmse:0.03450\n",
      "[100]\ttrain-rmse:0.02361\tvalid-rmse:0.02168\n",
      "[200]\ttrain-rmse:0.01783\tvalid-rmse:0.01559\n",
      "[300]\ttrain-rmse:0.01512\tvalid-rmse:0.01271\n",
      "[400]\ttrain-rmse:0.01488\tvalid-rmse:0.01246\n",
      "[410]\ttrain-rmse:0.01488\tvalid-rmse:0.01246\n",
      "[0]\ttrain-rmse:0.03554\tvalid-rmse:0.03738\n",
      "[100]\ttrain-rmse:0.02309\tvalid-rmse:0.02473\n",
      "[200]\ttrain-rmse:0.01745\tvalid-rmse:0.01913\n",
      "[300]\ttrain-rmse:0.01484\tvalid-rmse:0.01651\n",
      "[400]\ttrain-rmse:0.01466\tvalid-rmse:0.01631\n",
      "[430]\ttrain-rmse:0.01466\tvalid-rmse:0.01631\n",
      "[0]\ttrain-rmse:0.03544\tvalid-rmse:0.03774\n",
      "[100]\ttrain-rmse:0.02306\tvalid-rmse:0.02538\n",
      "[200]\ttrain-rmse:0.01738\tvalid-rmse:0.01975\n",
      "[300]\ttrain-rmse:0.01476\tvalid-rmse:0.01717\n",
      "[400]\ttrain-rmse:0.01452\tvalid-rmse:0.01694\n",
      "[500]\ttrain-rmse:0.01449\tvalid-rmse:0.01691\n",
      "[569]\ttrain-rmse:0.01446\tvalid-rmse:0.01688\n",
      "[0]\ttrain-rmse:0.21503\tvalid-rmse:0.21901\n",
      "[100]\ttrain-rmse:0.12727\tvalid-rmse:0.13197\n",
      "[200]\ttrain-rmse:0.07924\tvalid-rmse:0.08421\n",
      "[300]\ttrain-rmse:0.05512\tvalid-rmse:0.05965\n",
      "[400]\ttrain-rmse:0.04408\tvalid-rmse:0.04789\n",
      "[500]\ttrain-rmse:0.03992\tvalid-rmse:0.04314\n",
      "[600]\ttrain-rmse:0.03814\tvalid-rmse:0.04085\n",
      "[700]\ttrain-rmse:0.03766\tvalid-rmse:0.03998\n",
      "[800]\ttrain-rmse:0.03753\tvalid-rmse:0.03963\n",
      "[900]\ttrain-rmse:0.03741\tvalid-rmse:0.03932\n",
      "[1000]\ttrain-rmse:0.03732\tvalid-rmse:0.03914\n",
      "[1100]\ttrain-rmse:0.03726\tvalid-rmse:0.03898\n",
      "[1200]\ttrain-rmse:0.03719\tvalid-rmse:0.03885\n",
      "[1300]\ttrain-rmse:0.03716\tvalid-rmse:0.03881\n",
      "[1400]\ttrain-rmse:0.03713\tvalid-rmse:0.03875\n",
      "[1500]\ttrain-rmse:0.03707\tvalid-rmse:0.03866\n",
      "[1600]\ttrain-rmse:0.03703\tvalid-rmse:0.03857\n",
      "[1700]\ttrain-rmse:0.03703\tvalid-rmse:0.03856\n",
      "[1768]\ttrain-rmse:0.03702\tvalid-rmse:0.03856\n",
      "[0]\ttrain-rmse:0.21928\tvalid-rmse:0.20170\n",
      "[100]\ttrain-rmse:0.12958\tvalid-rmse:0.11757\n",
      "[200]\ttrain-rmse:0.08075\tvalid-rmse:0.07134\n",
      "[300]\ttrain-rmse:0.05631\tvalid-rmse:0.04758\n",
      "[400]\ttrain-rmse:0.04516\tvalid-rmse:0.03654\n",
      "[500]\ttrain-rmse:0.04073\tvalid-rmse:0.03212\n",
      "[600]\ttrain-rmse:0.03888\tvalid-rmse:0.03054\n",
      "[700]\ttrain-rmse:0.03851\tvalid-rmse:0.03034\n",
      "[800]\ttrain-rmse:0.03833\tvalid-rmse:0.03028\n",
      "[900]\ttrain-rmse:0.03820\tvalid-rmse:0.03022\n",
      "[1000]\ttrain-rmse:0.03814\tvalid-rmse:0.03019\n",
      "[1100]\ttrain-rmse:0.03808\tvalid-rmse:0.03016\n",
      "[1155]\ttrain-rmse:0.03807\tvalid-rmse:0.03016\n",
      "[0]\ttrain-rmse:0.21760\tvalid-rmse:0.20860\n",
      "[100]\ttrain-rmse:0.12812\tvalid-rmse:0.12321\n",
      "[200]\ttrain-rmse:0.07900\tvalid-rmse:0.07705\n",
      "[300]\ttrain-rmse:0.05395\tvalid-rmse:0.05457\n",
      "[400]\ttrain-rmse:0.04211\tvalid-rmse:0.04465\n",
      "[500]\ttrain-rmse:0.03738\tvalid-rmse:0.04107\n",
      "[600]\ttrain-rmse:0.03552\tvalid-rmse:0.03975\n",
      "[700]\ttrain-rmse:0.03509\tvalid-rmse:0.03951\n",
      "[800]\ttrain-rmse:0.03482\tvalid-rmse:0.03942\n",
      "[900]\ttrain-rmse:0.03473\tvalid-rmse:0.03941\n",
      "[1000]\ttrain-rmse:0.03465\tvalid-rmse:0.03937\n",
      "[1100]\ttrain-rmse:0.03461\tvalid-rmse:0.03936\n",
      "[1200]\ttrain-rmse:0.03455\tvalid-rmse:0.03936\n",
      "[1299]\ttrain-rmse:0.03451\tvalid-rmse:0.03936\n",
      "[0]\ttrain-rmse:0.21412\tvalid-rmse:0.22271\n",
      "[100]\ttrain-rmse:0.12570\tvalid-rmse:0.13237\n",
      "[200]\ttrain-rmse:0.07692\tvalid-rmse:0.08491\n",
      "[300]\ttrain-rmse:0.05182\tvalid-rmse:0.06324\n",
      "[400]\ttrain-rmse:0.03993\tvalid-rmse:0.05436\n",
      "[500]\ttrain-rmse:0.03519\tvalid-rmse:0.05132\n",
      "[600]\ttrain-rmse:0.03321\tvalid-rmse:0.05025\n",
      "[700]\ttrain-rmse:0.03281\tvalid-rmse:0.05008\n",
      "[800]\ttrain-rmse:0.03269\tvalid-rmse:0.05004\n",
      "[892]\ttrain-rmse:0.03265\tvalid-rmse:0.05004\n",
      "[0]\ttrain-rmse:0.21296\tvalid-rmse:0.22695\n",
      "[100]\ttrain-rmse:0.12566\tvalid-rmse:0.13524\n",
      "[200]\ttrain-rmse:0.07803\tvalid-rmse:0.08588\n",
      "[300]\ttrain-rmse:0.05395\tvalid-rmse:0.06158\n",
      "[400]\ttrain-rmse:0.04292\tvalid-rmse:0.05044\n",
      "[500]\ttrain-rmse:0.03855\tvalid-rmse:0.04588\n",
      "[600]\ttrain-rmse:0.03681\tvalid-rmse:0.04407\n",
      "[700]\ttrain-rmse:0.03630\tvalid-rmse:0.04346\n",
      "[800]\ttrain-rmse:0.03612\tvalid-rmse:0.04325\n",
      "[900]\ttrain-rmse:0.03600\tvalid-rmse:0.04310\n",
      "[1000]\ttrain-rmse:0.03592\tvalid-rmse:0.04302\n",
      "[1100]\ttrain-rmse:0.03584\tvalid-rmse:0.04290\n",
      "[1200]\ttrain-rmse:0.03578\tvalid-rmse:0.04283\n",
      "[1246]\ttrain-rmse:0.03578\tvalid-rmse:0.04283\n",
      "[0]\ttrain-rmse:0.39529\tvalid-rmse:0.40157\n",
      "[100]\ttrain-rmse:0.23458\tvalid-rmse:0.24087\n",
      "[200]\ttrain-rmse:0.14757\tvalid-rmse:0.15292\n",
      "[300]\ttrain-rmse:0.10269\tvalid-rmse:0.10703\n",
      "[400]\ttrain-rmse:0.08203\tvalid-rmse:0.08558\n",
      "[500]\ttrain-rmse:0.07341\tvalid-rmse:0.07633\n",
      "[600]\ttrain-rmse:0.06988\tvalid-rmse:0.07257\n",
      "[700]\ttrain-rmse:0.06820\tvalid-rmse:0.07080\n",
      "[800]\ttrain-rmse:0.06766\tvalid-rmse:0.07006\n",
      "[900]\ttrain-rmse:0.06745\tvalid-rmse:0.06970\n",
      "[1000]\ttrain-rmse:0.06729\tvalid-rmse:0.06941\n",
      "[1100]\ttrain-rmse:0.06720\tvalid-rmse:0.06908\n",
      "[1200]\ttrain-rmse:0.06711\tvalid-rmse:0.06887\n",
      "[1300]\ttrain-rmse:0.06704\tvalid-rmse:0.06876\n",
      "[1400]\ttrain-rmse:0.06701\tvalid-rmse:0.06855\n",
      "[1500]\ttrain-rmse:0.06696\tvalid-rmse:0.06841\n",
      "[1600]\ttrain-rmse:0.06692\tvalid-rmse:0.06828\n",
      "[1700]\ttrain-rmse:0.06690\tvalid-rmse:0.06826\n",
      "[1719]\ttrain-rmse:0.06689\tvalid-rmse:0.06828\n",
      "[0]\ttrain-rmse:0.40307\tvalid-rmse:0.36977\n",
      "[100]\ttrain-rmse:0.23918\tvalid-rmse:0.21562\n",
      "[200]\ttrain-rmse:0.15036\tvalid-rmse:0.13239\n",
      "[300]\ttrain-rmse:0.10460\tvalid-rmse:0.08965\n",
      "[400]\ttrain-rmse:0.08361\tvalid-rmse:0.07124\n",
      "[500]\ttrain-rmse:0.07499\tvalid-rmse:0.06487\n",
      "[600]\ttrain-rmse:0.07111\tvalid-rmse:0.06314\n",
      "[655]\ttrain-rmse:0.06993\tvalid-rmse:0.06327\n",
      "[0]\ttrain-rmse:0.39922\tvalid-rmse:0.38574\n",
      "[100]\ttrain-rmse:0.23528\tvalid-rmse:0.23294\n",
      "[200]\ttrain-rmse:0.14589\tvalid-rmse:0.15348\n",
      "[300]\ttrain-rmse:0.09917\tvalid-rmse:0.11641\n",
      "[400]\ttrain-rmse:0.07706\tvalid-rmse:0.10178\n",
      "[500]\ttrain-rmse:0.06771\tvalid-rmse:0.09687\n",
      "[600]\ttrain-rmse:0.06416\tvalid-rmse:0.09537\n",
      "[700]\ttrain-rmse:0.06246\tvalid-rmse:0.09492\n",
      "[800]\ttrain-rmse:0.06182\tvalid-rmse:0.09488\n",
      "[900]\ttrain-rmse:0.06151\tvalid-rmse:0.09487\n",
      "[903]\ttrain-rmse:0.06150\tvalid-rmse:0.09486\n",
      "[0]\ttrain-rmse:0.39363\tvalid-rmse:0.40830\n",
      "[100]\ttrain-rmse:0.23129\tvalid-rmse:0.24521\n",
      "[200]\ttrain-rmse:0.14223\tvalid-rmse:0.16292\n",
      "[300]\ttrain-rmse:0.09517\tvalid-rmse:0.12781\n",
      "[400]\ttrain-rmse:0.07326\tvalid-rmse:0.11563\n",
      "[500]\ttrain-rmse:0.06412\tvalid-rmse:0.11219\n",
      "[600]\ttrain-rmse:0.06019\tvalid-rmse:0.11147\n",
      "[697]\ttrain-rmse:0.05849\tvalid-rmse:0.11139\n",
      "[0]\ttrain-rmse:0.39123\tvalid-rmse:0.41715\n",
      "[100]\ttrain-rmse:0.23178\tvalid-rmse:0.24971\n",
      "[200]\ttrain-rmse:0.14502\tvalid-rmse:0.16038\n",
      "[300]\ttrain-rmse:0.10020\tvalid-rmse:0.11655\n",
      "[400]\ttrain-rmse:0.07934\tvalid-rmse:0.09782\n",
      "[500]\ttrain-rmse:0.07025\tvalid-rmse:0.09026\n",
      "[600]\ttrain-rmse:0.06628\tvalid-rmse:0.08695\n",
      "[700]\ttrain-rmse:0.06432\tvalid-rmse:0.08555\n",
      "[800]\ttrain-rmse:0.06359\tvalid-rmse:0.08508\n",
      "[900]\ttrain-rmse:0.06330\tvalid-rmse:0.08485\n",
      "[1000]\ttrain-rmse:0.06309\tvalid-rmse:0.08463\n",
      "[1100]\ttrain-rmse:0.06291\tvalid-rmse:0.08446\n",
      "[1200]\ttrain-rmse:0.06274\tvalid-rmse:0.08432\n",
      "[1300]\ttrain-rmse:0.06266\tvalid-rmse:0.08427\n",
      "[1400]\ttrain-rmse:0.06259\tvalid-rmse:0.08419\n",
      "[1500]\ttrain-rmse:0.06250\tvalid-rmse:0.08416\n",
      "[1512]\ttrain-rmse:0.06250\tvalid-rmse:0.08416\n",
      "[0]\ttrain-rmse:0.57772\tvalid-rmse:0.57986\n",
      "[100]\ttrain-rmse:0.34663\tvalid-rmse:0.34786\n",
      "[200]\ttrain-rmse:0.22273\tvalid-rmse:0.22051\n",
      "[300]\ttrain-rmse:0.16028\tvalid-rmse:0.15470\n",
      "[400]\ttrain-rmse:0.13120\tvalid-rmse:0.12348\n",
      "[500]\ttrain-rmse:0.11837\tvalid-rmse:0.11074\n",
      "[600]\ttrain-rmse:0.11113\tvalid-rmse:0.10518\n",
      "[700]\ttrain-rmse:0.10577\tvalid-rmse:0.10288\n",
      "[800]\ttrain-rmse:0.10315\tvalid-rmse:0.10154\n",
      "[900]\ttrain-rmse:0.10221\tvalid-rmse:0.10085\n",
      "[1000]\ttrain-rmse:0.10179\tvalid-rmse:0.10052\n",
      "[1100]\ttrain-rmse:0.10150\tvalid-rmse:0.10026\n",
      "[1200]\ttrain-rmse:0.10126\tvalid-rmse:0.10009\n",
      "[1300]\ttrain-rmse:0.10100\tvalid-rmse:0.09998\n",
      "[1400]\ttrain-rmse:0.10086\tvalid-rmse:0.09965\n",
      "[1500]\ttrain-rmse:0.10071\tvalid-rmse:0.09950\n",
      "[1524]\ttrain-rmse:0.10070\tvalid-rmse:0.09950\n",
      "[0]\ttrain-rmse:0.58479\tvalid-rmse:0.55153\n",
      "[100]\ttrain-rmse:0.34856\tvalid-rmse:0.33694\n",
      "[200]\ttrain-rmse:0.22066\tvalid-rmse:0.22707\n",
      "[300]\ttrain-rmse:0.15561\tvalid-rmse:0.17724\n",
      "[400]\ttrain-rmse:0.12536\tvalid-rmse:0.15832\n",
      "[500]\ttrain-rmse:0.11230\tvalid-rmse:0.15212\n",
      "[600]\ttrain-rmse:0.10505\tvalid-rmse:0.15049\n",
      "[688]\ttrain-rmse:0.10080\tvalid-rmse:0.15054\n",
      "[0]\ttrain-rmse:0.58181\tvalid-rmse:0.56328\n",
      "[100]\ttrain-rmse:0.34647\tvalid-rmse:0.34341\n",
      "[200]\ttrain-rmse:0.21919\tvalid-rmse:0.23123\n",
      "[300]\ttrain-rmse:0.15427\tvalid-rmse:0.18048\n",
      "[400]\ttrain-rmse:0.12413\tvalid-rmse:0.16100\n",
      "[500]\ttrain-rmse:0.11082\tvalid-rmse:0.15458\n",
      "[600]\ttrain-rmse:0.10471\tvalid-rmse:0.15278\n",
      "[700]\ttrain-rmse:0.10068\tvalid-rmse:0.15230\n",
      "[800]\ttrain-rmse:0.09838\tvalid-rmse:0.15217\n",
      "[900]\ttrain-rmse:0.09753\tvalid-rmse:0.15212\n",
      "[922]\ttrain-rmse:0.09749\tvalid-rmse:0.15211\n",
      "[0]\ttrain-rmse:0.57512\tvalid-rmse:0.59043\n",
      "[100]\ttrain-rmse:0.34115\tvalid-rmse:0.35684\n",
      "[200]\ttrain-rmse:0.21363\tvalid-rmse:0.24238\n",
      "[300]\ttrain-rmse:0.14806\tvalid-rmse:0.19683\n",
      "[400]\ttrain-rmse:0.11836\tvalid-rmse:0.18247\n",
      "[500]\ttrain-rmse:0.10595\tvalid-rmse:0.17896\n",
      "[600]\ttrain-rmse:0.10020\tvalid-rmse:0.17858\n",
      "[624]\ttrain-rmse:0.09918\tvalid-rmse:0.17860\n",
      "[0]\ttrain-rmse:0.57081\tvalid-rmse:0.60652\n",
      "[100]\ttrain-rmse:0.34184\tvalid-rmse:0.36463\n",
      "[200]\ttrain-rmse:0.21844\tvalid-rmse:0.23725\n",
      "[300]\ttrain-rmse:0.15636\tvalid-rmse:0.17609\n",
      "[400]\ttrain-rmse:0.12773\tvalid-rmse:0.15019\n",
      "[500]\ttrain-rmse:0.11450\tvalid-rmse:0.14064\n",
      "[600]\ttrain-rmse:0.10695\tvalid-rmse:0.13657\n",
      "[700]\ttrain-rmse:0.10194\tvalid-rmse:0.13489\n",
      "[800]\ttrain-rmse:0.09895\tvalid-rmse:0.13411\n",
      "[900]\ttrain-rmse:0.09771\tvalid-rmse:0.13384\n",
      "[1000]\ttrain-rmse:0.09716\tvalid-rmse:0.13372\n",
      "[1100]\ttrain-rmse:0.09672\tvalid-rmse:0.13357\n",
      "[1103]\ttrain-rmse:0.09671\tvalid-rmse:0.13357\n",
      "[0]\ttrain-rmse:0.75564\tvalid-rmse:0.75627\n",
      "[100]\ttrain-rmse:0.45420\tvalid-rmse:0.45510\n",
      "[200]\ttrain-rmse:0.29267\tvalid-rmse:0.29110\n",
      "[300]\ttrain-rmse:0.21087\tvalid-rmse:0.20787\n",
      "[400]\ttrain-rmse:0.17245\tvalid-rmse:0.17028\n",
      "[500]\ttrain-rmse:0.15456\tvalid-rmse:0.15528\n",
      "[600]\ttrain-rmse:0.14311\tvalid-rmse:0.14832\n",
      "[700]\ttrain-rmse:0.13485\tvalid-rmse:0.14546\n",
      "[800]\ttrain-rmse:0.12953\tvalid-rmse:0.14392\n",
      "[900]\ttrain-rmse:0.12655\tvalid-rmse:0.14288\n",
      "[1000]\ttrain-rmse:0.12494\tvalid-rmse:0.14244\n",
      "[1100]\ttrain-rmse:0.12412\tvalid-rmse:0.14215\n",
      "[1200]\ttrain-rmse:0.12359\tvalid-rmse:0.14193\n",
      "[1300]\ttrain-rmse:0.12308\tvalid-rmse:0.14163\n",
      "[1400]\ttrain-rmse:0.12277\tvalid-rmse:0.14129\n",
      "[1468]\ttrain-rmse:0.12252\tvalid-rmse:0.14122\n",
      "[0]\ttrain-rmse:0.76606\tvalid-rmse:0.71383\n",
      "[100]\ttrain-rmse:0.45816\tvalid-rmse:0.43191\n",
      "[200]\ttrain-rmse:0.29214\tvalid-rmse:0.28724\n",
      "[300]\ttrain-rmse:0.20842\tvalid-rmse:0.22163\n",
      "[400]\ttrain-rmse:0.16950\tvalid-rmse:0.19716\n",
      "[500]\ttrain-rmse:0.15096\tvalid-rmse:0.19024\n",
      "[600]\ttrain-rmse:0.14043\tvalid-rmse:0.18883\n",
      "[652]\ttrain-rmse:0.13611\tvalid-rmse:0.18902\n",
      "[0]\ttrain-rmse:0.75942\tvalid-rmse:0.74083\n",
      "[100]\ttrain-rmse:0.45281\tvalid-rmse:0.45634\n",
      "[200]\ttrain-rmse:0.28705\tvalid-rmse:0.31269\n",
      "[300]\ttrain-rmse:0.20238\tvalid-rmse:0.24847\n",
      "[400]\ttrain-rmse:0.16301\tvalid-rmse:0.22389\n",
      "[500]\ttrain-rmse:0.14487\tvalid-rmse:0.21549\n",
      "[600]\ttrain-rmse:0.13584\tvalid-rmse:0.21277\n",
      "[700]\ttrain-rmse:0.12918\tvalid-rmse:0.21176\n",
      "[800]\ttrain-rmse:0.12483\tvalid-rmse:0.21143\n",
      "[900]\ttrain-rmse:0.12262\tvalid-rmse:0.21124\n",
      "[983]\ttrain-rmse:0.12158\tvalid-rmse:0.21118\n",
      "[0]\ttrain-rmse:0.75120\tvalid-rmse:0.77405\n",
      "[100]\ttrain-rmse:0.44586\tvalid-rmse:0.47215\n",
      "[200]\ttrain-rmse:0.27952\tvalid-rmse:0.32639\n",
      "[300]\ttrain-rmse:0.19397\tvalid-rmse:0.26978\n",
      "[400]\ttrain-rmse:0.15463\tvalid-rmse:0.25208\n",
      "[500]\ttrain-rmse:0.13716\tvalid-rmse:0.24799\n",
      "[600]\ttrain-rmse:0.12853\tvalid-rmse:0.24760\n",
      "[605]\ttrain-rmse:0.12821\tvalid-rmse:0.24758\n",
      "[0]\ttrain-rmse:0.74573\tvalid-rmse:0.79440\n",
      "[100]\ttrain-rmse:0.44741\tvalid-rmse:0.48087\n",
      "[200]\ttrain-rmse:0.28653\tvalid-rmse:0.31602\n",
      "[300]\ttrain-rmse:0.20573\tvalid-rmse:0.23833\n",
      "[400]\ttrain-rmse:0.16811\tvalid-rmse:0.20628\n",
      "[500]\ttrain-rmse:0.15040\tvalid-rmse:0.19385\n",
      "[600]\ttrain-rmse:0.14018\tvalid-rmse:0.18835\n",
      "[700]\ttrain-rmse:0.13260\tvalid-rmse:0.18556\n",
      "[800]\ttrain-rmse:0.12708\tvalid-rmse:0.18438\n",
      "[900]\ttrain-rmse:0.12366\tvalid-rmse:0.18418\n",
      "[916]\ttrain-rmse:0.12323\tvalid-rmse:0.18423\n",
      "[0]\ttrain-rmse:0.93320\tvalid-rmse:0.92818\n",
      "[100]\ttrain-rmse:0.56246\tvalid-rmse:0.55944\n",
      "[200]\ttrain-rmse:0.36385\tvalid-rmse:0.36114\n",
      "[300]\ttrain-rmse:0.26376\tvalid-rmse:0.26249\n",
      "[400]\ttrain-rmse:0.21650\tvalid-rmse:0.21945\n",
      "[500]\ttrain-rmse:0.19352\tvalid-rmse:0.20219\n",
      "[600]\ttrain-rmse:0.17785\tvalid-rmse:0.19425\n",
      "[700]\ttrain-rmse:0.16679\tvalid-rmse:0.19109\n",
      "[800]\ttrain-rmse:0.15848\tvalid-rmse:0.18924\n",
      "[900]\ttrain-rmse:0.15266\tvalid-rmse:0.18811\n",
      "[1000]\ttrain-rmse:0.14818\tvalid-rmse:0.18777\n",
      "[1100]\ttrain-rmse:0.14576\tvalid-rmse:0.18753\n",
      "[1200]\ttrain-rmse:0.14375\tvalid-rmse:0.18730\n",
      "[1300]\ttrain-rmse:0.14273\tvalid-rmse:0.18718\n",
      "[1306]\ttrain-rmse:0.14263\tvalid-rmse:0.18717\n",
      "[0]\ttrain-rmse:0.94539\tvalid-rmse:0.87828\n",
      "[100]\ttrain-rmse:0.56731\tvalid-rmse:0.53137\n",
      "[200]\ttrain-rmse:0.36371\tvalid-rmse:0.35514\n",
      "[300]\ttrain-rmse:0.26125\tvalid-rmse:0.27626\n",
      "[400]\ttrain-rmse:0.21311\tvalid-rmse:0.24657\n",
      "[500]\ttrain-rmse:0.19002\tvalid-rmse:0.23874\n",
      "[600]\ttrain-rmse:0.17527\tvalid-rmse:0.23838\n",
      "[605]\ttrain-rmse:0.17471\tvalid-rmse:0.23843\n",
      "[0]\ttrain-rmse:0.93566\tvalid-rmse:0.91822\n",
      "[100]\ttrain-rmse:0.55940\tvalid-rmse:0.57139\n",
      "[200]\ttrain-rmse:0.35585\tvalid-rmse:0.39605\n",
      "[300]\ttrain-rmse:0.25184\tvalid-rmse:0.31865\n",
      "[400]\ttrain-rmse:0.20213\tvalid-rmse:0.28890\n",
      "[500]\ttrain-rmse:0.17874\tvalid-rmse:0.27840\n",
      "[600]\ttrain-rmse:0.16685\tvalid-rmse:0.27503\n",
      "[700]\ttrain-rmse:0.15805\tvalid-rmse:0.27400\n",
      "[800]\ttrain-rmse:0.15061\tvalid-rmse:0.27324\n",
      "[892]\ttrain-rmse:0.14648\tvalid-rmse:0.27308\n",
      "[0]\ttrain-rmse:0.92618\tvalid-rmse:0.95636\n",
      "[100]\ttrain-rmse:0.55138\tvalid-rmse:0.58822\n",
      "[200]\ttrain-rmse:0.34755\tvalid-rmse:0.41252\n",
      "[300]\ttrain-rmse:0.24246\tvalid-rmse:0.34479\n",
      "[400]\ttrain-rmse:0.19301\tvalid-rmse:0.32430\n",
      "[500]\ttrain-rmse:0.16996\tvalid-rmse:0.31998\n",
      "[600]\ttrain-rmse:0.15767\tvalid-rmse:0.31983\n",
      "[619]\ttrain-rmse:0.15599\tvalid-rmse:0.31985\n",
      "[0]\ttrain-rmse:0.91969\tvalid-rmse:0.98054\n",
      "[100]\ttrain-rmse:0.55323\tvalid-rmse:0.59841\n",
      "[200]\ttrain-rmse:0.35545\tvalid-rmse:0.39929\n",
      "[300]\ttrain-rmse:0.25576\tvalid-rmse:0.30655\n",
      "[400]\ttrain-rmse:0.20896\tvalid-rmse:0.26862\n",
      "[500]\ttrain-rmse:0.18688\tvalid-rmse:0.25461\n",
      "[600]\ttrain-rmse:0.17402\tvalid-rmse:0.24808\n",
      "[700]\ttrain-rmse:0.16385\tvalid-rmse:0.24390\n",
      "[800]\ttrain-rmse:0.15626\tvalid-rmse:0.24215\n",
      "[900]\ttrain-rmse:0.15027\tvalid-rmse:0.24177\n",
      "[948]\ttrain-rmse:0.14794\tvalid-rmse:0.24200\n",
      "[0]\ttrain-rmse:1.10900\tvalid-rmse:1.10104\n",
      "[100]\ttrain-rmse:0.67039\tvalid-rmse:0.66707\n",
      "[200]\ttrain-rmse:0.43541\tvalid-rmse:0.43649\n",
      "[300]\ttrain-rmse:0.31684\tvalid-rmse:0.32376\n",
      "[400]\ttrain-rmse:0.26010\tvalid-rmse:0.27547\n",
      "[500]\ttrain-rmse:0.23227\tvalid-rmse:0.25687\n",
      "[600]\ttrain-rmse:0.21329\tvalid-rmse:0.24839\n",
      "[700]\ttrain-rmse:0.19934\tvalid-rmse:0.24417\n",
      "[800]\ttrain-rmse:0.18851\tvalid-rmse:0.24246\n",
      "[900]\ttrain-rmse:0.18005\tvalid-rmse:0.24150\n",
      "[1000]\ttrain-rmse:0.17340\tvalid-rmse:0.24107\n",
      "[1100]\ttrain-rmse:0.16784\tvalid-rmse:0.24103\n",
      "[1121]\ttrain-rmse:0.16642\tvalid-rmse:0.24097\n",
      "[0]\ttrain-rmse:1.12333\tvalid-rmse:1.04221\n",
      "[100]\ttrain-rmse:0.67660\tvalid-rmse:0.63123\n",
      "[200]\ttrain-rmse:0.43634\tvalid-rmse:0.42222\n",
      "[300]\ttrain-rmse:0.31570\tvalid-rmse:0.32853\n",
      "[400]\ttrain-rmse:0.25869\tvalid-rmse:0.29378\n",
      "[500]\ttrain-rmse:0.23122\tvalid-rmse:0.28480\n",
      "[599]\ttrain-rmse:0.21268\tvalid-rmse:0.28432\n",
      "[0]\ttrain-rmse:1.11065\tvalid-rmse:1.09443\n",
      "[100]\ttrain-rmse:0.66598\tvalid-rmse:0.68690\n",
      "[200]\ttrain-rmse:0.42557\tvalid-rmse:0.48209\n",
      "[300]\ttrain-rmse:0.30239\tvalid-rmse:0.39173\n",
      "[400]\ttrain-rmse:0.24284\tvalid-rmse:0.35672\n",
      "[500]\ttrain-rmse:0.21378\tvalid-rmse:0.34400\n",
      "[600]\ttrain-rmse:0.19832\tvalid-rmse:0.33954\n",
      "[700]\ttrain-rmse:0.18638\tvalid-rmse:0.33870\n",
      "[800]\ttrain-rmse:0.17625\tvalid-rmse:0.33749\n",
      "[891]\ttrain-rmse:0.16953\tvalid-rmse:0.33746\n",
      "[0]\ttrain-rmse:1.10012\tvalid-rmse:1.13674\n",
      "[100]\ttrain-rmse:0.65668\tvalid-rmse:0.70324\n",
      "[200]\ttrain-rmse:0.41560\tvalid-rmse:0.49868\n",
      "[300]\ttrain-rmse:0.29121\tvalid-rmse:0.42142\n",
      "[400]\ttrain-rmse:0.23200\tvalid-rmse:0.39977\n",
      "[500]\ttrain-rmse:0.20332\tvalid-rmse:0.39551\n",
      "[600]\ttrain-rmse:0.18707\tvalid-rmse:0.39566\n",
      "[607]\ttrain-rmse:0.18620\tvalid-rmse:0.39550\n",
      "[0]\ttrain-rmse:1.09293\tvalid-rmse:1.16335\n",
      "[100]\ttrain-rmse:0.65938\tvalid-rmse:0.71383\n",
      "[200]\ttrain-rmse:0.42532\tvalid-rmse:0.48185\n",
      "[300]\ttrain-rmse:0.30742\tvalid-rmse:0.37538\n",
      "[400]\ttrain-rmse:0.25157\tvalid-rmse:0.33255\n",
      "[500]\ttrain-rmse:0.22476\tvalid-rmse:0.31639\n",
      "[600]\ttrain-rmse:0.20865\tvalid-rmse:0.30946\n",
      "[700]\ttrain-rmse:0.19651\tvalid-rmse:0.30490\n",
      "[800]\ttrain-rmse:0.18622\tvalid-rmse:0.30253\n",
      "[876]\ttrain-rmse:0.17941\tvalid-rmse:0.30247\n",
      "[0]\ttrain-rmse:1.30888\tvalid-rmse:1.26913\n",
      "[100]\ttrain-rmse:0.80634\tvalid-rmse:0.78154\n",
      "[200]\ttrain-rmse:0.54157\tvalid-rmse:0.53764\n",
      "[300]\ttrain-rmse:0.41038\tvalid-rmse:0.42967\n",
      "[400]\ttrain-rmse:0.34629\tvalid-rmse:0.38794\n",
      "[500]\ttrain-rmse:0.31139\tvalid-rmse:0.37345\n",
      "[600]\ttrain-rmse:0.28691\tvalid-rmse:0.36791\n",
      "[700]\ttrain-rmse:0.26839\tvalid-rmse:0.36471\n",
      "[800]\ttrain-rmse:0.25278\tvalid-rmse:0.36371\n",
      "[900]\ttrain-rmse:0.23996\tvalid-rmse:0.36286\n",
      "[1000]\ttrain-rmse:0.22907\tvalid-rmse:0.36226\n",
      "[1066]\ttrain-rmse:0.22226\tvalid-rmse:0.36229\n",
      "[0]\ttrain-rmse:1.32453\tvalid-rmse:1.20341\n",
      "[100]\ttrain-rmse:0.81688\tvalid-rmse:0.72106\n",
      "[200]\ttrain-rmse:0.54875\tvalid-rmse:0.48036\n",
      "[300]\ttrain-rmse:0.41640\tvalid-rmse:0.37698\n",
      "[400]\ttrain-rmse:0.35218\tvalid-rmse:0.34197\n",
      "[500]\ttrain-rmse:0.31813\tvalid-rmse:0.33478\n",
      "[563]\ttrain-rmse:0.30196\tvalid-rmse:0.33612\n",
      "[0]\ttrain-rmse:1.30813\tvalid-rmse:1.27218\n",
      "[100]\ttrain-rmse:0.80341\tvalid-rmse:0.80512\n",
      "[200]\ttrain-rmse:0.53612\tvalid-rmse:0.57136\n",
      "[300]\ttrain-rmse:0.40147\tvalid-rmse:0.46740\n",
      "[400]\ttrain-rmse:0.33530\tvalid-rmse:0.42749\n",
      "[500]\ttrain-rmse:0.29984\tvalid-rmse:0.41423\n",
      "[600]\ttrain-rmse:0.27807\tvalid-rmse:0.41034\n",
      "[700]\ttrain-rmse:0.25979\tvalid-rmse:0.40953\n",
      "[782]\ttrain-rmse:0.24750\tvalid-rmse:0.40923\n",
      "[0]\ttrain-rmse:1.29697\tvalid-rmse:1.31794\n",
      "[100]\ttrain-rmse:0.79212\tvalid-rmse:0.81919\n",
      "[200]\ttrain-rmse:0.52469\tvalid-rmse:0.58843\n",
      "[300]\ttrain-rmse:0.38883\tvalid-rmse:0.50278\n",
      "[400]\ttrain-rmse:0.32293\tvalid-rmse:0.48004\n",
      "[500]\ttrain-rmse:0.28879\tvalid-rmse:0.47617\n",
      "[564]\ttrain-rmse:0.27415\tvalid-rmse:0.47614\n",
      "[0]\ttrain-rmse:1.26495\tvalid-rmse:1.43638\n",
      "[100]\ttrain-rmse:0.76825\tvalid-rmse:0.95418\n",
      "[200]\ttrain-rmse:0.50179\tvalid-rmse:0.72217\n",
      "[300]\ttrain-rmse:0.36814\tvalid-rmse:0.62541\n",
      "[400]\ttrain-rmse:0.30444\tvalid-rmse:0.58761\n",
      "[500]\ttrain-rmse:0.27264\tvalid-rmse:0.57324\n",
      "[600]\ttrain-rmse:0.25243\tvalid-rmse:0.56653\n",
      "[700]\ttrain-rmse:0.23697\tvalid-rmse:0.56203\n",
      "[800]\ttrain-rmse:0.22394\tvalid-rmse:0.55999\n",
      "[877]\ttrain-rmse:0.21501\tvalid-rmse:0.56028\n",
      "[0]\ttrain-rmse:1.48058\tvalid-rmse:1.44109\n",
      "[100]\ttrain-rmse:0.91069\tvalid-rmse:0.89194\n",
      "[200]\ttrain-rmse:0.60994\tvalid-rmse:0.61826\n",
      "[300]\ttrain-rmse:0.46094\tvalid-rmse:0.49652\n",
      "[400]\ttrain-rmse:0.38840\tvalid-rmse:0.44907\n",
      "[500]\ttrain-rmse:0.34867\tvalid-rmse:0.43127\n",
      "[600]\ttrain-rmse:0.32022\tvalid-rmse:0.42408\n",
      "[700]\ttrain-rmse:0.29941\tvalid-rmse:0.42002\n",
      "[800]\ttrain-rmse:0.28138\tvalid-rmse:0.41786\n",
      "[900]\ttrain-rmse:0.26675\tvalid-rmse:0.41667\n",
      "[1000]\ttrain-rmse:0.25372\tvalid-rmse:0.41550\n",
      "[1086]\ttrain-rmse:0.24357\tvalid-rmse:0.41561\n",
      "[0]\ttrain-rmse:1.49890\tvalid-rmse:1.36453\n",
      "[100]\ttrain-rmse:0.92263\tvalid-rmse:0.82062\n",
      "[200]\ttrain-rmse:0.61800\tvalid-rmse:0.54823\n",
      "[300]\ttrain-rmse:0.46697\tvalid-rmse:0.43223\n",
      "[400]\ttrain-rmse:0.39289\tvalid-rmse:0.39371\n",
      "[500]\ttrain-rmse:0.35369\tvalid-rmse:0.38717\n",
      "[538]\ttrain-rmse:0.34168\tvalid-rmse:0.38817\n",
      "[0]\ttrain-rmse:1.47843\tvalid-rmse:1.45000\n",
      "[100]\ttrain-rmse:0.90577\tvalid-rmse:0.92355\n",
      "[200]\ttrain-rmse:0.60143\tvalid-rmse:0.66027\n",
      "[300]\ttrain-rmse:0.44713\tvalid-rmse:0.54269\n",
      "[400]\ttrain-rmse:0.37133\tvalid-rmse:0.49759\n",
      "[500]\ttrain-rmse:0.33048\tvalid-rmse:0.48219\n",
      "[600]\ttrain-rmse:0.30531\tvalid-rmse:0.47772\n",
      "[700]\ttrain-rmse:0.28397\tvalid-rmse:0.47667\n",
      "[791]\ttrain-rmse:0.26804\tvalid-rmse:0.47675\n",
      "[0]\ttrain-rmse:1.46696\tvalid-rmse:1.49671\n",
      "[100]\ttrain-rmse:0.89373\tvalid-rmse:0.93489\n",
      "[200]\ttrain-rmse:0.58891\tvalid-rmse:0.67724\n",
      "[300]\ttrain-rmse:0.43330\tvalid-rmse:0.58339\n",
      "[400]\ttrain-rmse:0.35717\tvalid-rmse:0.55970\n",
      "[500]\ttrain-rmse:0.31767\tvalid-rmse:0.55583\n",
      "[565]\ttrain-rmse:0.30038\tvalid-rmse:0.55589\n",
      "[0]\ttrain-rmse:1.43726\tvalid-rmse:1.60704\n",
      "[100]\ttrain-rmse:0.87506\tvalid-rmse:1.05499\n",
      "[200]\ttrain-rmse:0.57287\tvalid-rmse:0.78696\n",
      "[300]\ttrain-rmse:0.42158\tvalid-rmse:0.67490\n",
      "[400]\ttrain-rmse:0.34907\tvalid-rmse:0.63192\n",
      "[500]\ttrain-rmse:0.31239\tvalid-rmse:0.61558\n",
      "[600]\ttrain-rmse:0.28884\tvalid-rmse:0.60816\n",
      "[700]\ttrain-rmse:0.27037\tvalid-rmse:0.60275\n",
      "[800]\ttrain-rmse:0.25527\tvalid-rmse:0.60043\n",
      "[877]\ttrain-rmse:0.24502\tvalid-rmse:0.60050\n",
      "[0]\ttrain-rmse:1.65368\tvalid-rmse:1.61242\n",
      "[100]\ttrain-rmse:1.01678\tvalid-rmse:1.00405\n",
      "[200]\ttrain-rmse:0.68009\tvalid-rmse:0.70141\n",
      "[300]\ttrain-rmse:0.51286\tvalid-rmse:0.56737\n",
      "[400]\ttrain-rmse:0.43169\tvalid-rmse:0.51512\n",
      "[500]\ttrain-rmse:0.38656\tvalid-rmse:0.49669\n",
      "[600]\ttrain-rmse:0.35480\tvalid-rmse:0.48828\n",
      "[700]\ttrain-rmse:0.33097\tvalid-rmse:0.48327\n",
      "[800]\ttrain-rmse:0.31057\tvalid-rmse:0.48001\n",
      "[900]\ttrain-rmse:0.29461\tvalid-rmse:0.47856\n",
      "[1000]\ttrain-rmse:0.27959\tvalid-rmse:0.47723\n",
      "[1050]\ttrain-rmse:0.27285\tvalid-rmse:0.47740\n",
      "[0]\ttrain-rmse:1.67418\tvalid-rmse:1.52690\n",
      "[100]\ttrain-rmse:1.02997\tvalid-rmse:0.92272\n",
      "[200]\ttrain-rmse:0.68861\tvalid-rmse:0.62007\n",
      "[300]\ttrain-rmse:0.51896\tvalid-rmse:0.49323\n",
      "[400]\ttrain-rmse:0.43513\tvalid-rmse:0.45074\n",
      "[500]\ttrain-rmse:0.39114\tvalid-rmse:0.44398\n",
      "[538]\ttrain-rmse:0.37719\tvalid-rmse:0.44447\n",
      "[0]\ttrain-rmse:1.64968\tvalid-rmse:1.62889\n",
      "[100]\ttrain-rmse:1.00980\tvalid-rmse:1.04229\n",
      "[200]\ttrain-rmse:0.66896\tvalid-rmse:0.74832\n",
      "[300]\ttrain-rmse:0.49569\tvalid-rmse:0.61741\n",
      "[400]\ttrain-rmse:0.41051\tvalid-rmse:0.56646\n",
      "[500]\ttrain-rmse:0.36462\tvalid-rmse:0.54823\n",
      "[600]\ttrain-rmse:0.33582\tvalid-rmse:0.54355\n",
      "[700]\ttrain-rmse:0.31129\tvalid-rmse:0.54233\n",
      "[782]\ttrain-rmse:0.29483\tvalid-rmse:0.54265\n",
      "[0]\ttrain-rmse:1.63781\tvalid-rmse:1.67695\n",
      "[100]\ttrain-rmse:0.99687\tvalid-rmse:1.05397\n",
      "[200]\ttrain-rmse:0.65496\tvalid-rmse:0.76958\n",
      "[300]\ttrain-rmse:0.47973\tvalid-rmse:0.66801\n",
      "[400]\ttrain-rmse:0.39324\tvalid-rmse:0.64310\n",
      "[500]\ttrain-rmse:0.34806\tvalid-rmse:0.63912\n",
      "[565]\ttrain-rmse:0.32839\tvalid-rmse:0.63897\n",
      "[0]\ttrain-rmse:1.61027\tvalid-rmse:1.77939\n",
      "[100]\ttrain-rmse:0.98231\tvalid-rmse:1.15811\n",
      "[200]\ttrain-rmse:0.64489\tvalid-rmse:0.85541\n",
      "[300]\ttrain-rmse:0.47576\tvalid-rmse:0.72898\n",
      "[400]\ttrain-rmse:0.39428\tvalid-rmse:0.68043\n",
      "[500]\ttrain-rmse:0.35241\tvalid-rmse:0.66286\n",
      "[600]\ttrain-rmse:0.32512\tvalid-rmse:0.65530\n",
      "[700]\ttrain-rmse:0.30317\tvalid-rmse:0.65006\n",
      "[800]\ttrain-rmse:0.28601\tvalid-rmse:0.64724\n",
      "[885]\ttrain-rmse:0.27334\tvalid-rmse:0.64693\n",
      "[0]\ttrain-rmse:1.82620\tvalid-rmse:1.78026\n",
      "[100]\ttrain-rmse:1.12225\tvalid-rmse:1.11152\n",
      "[200]\ttrain-rmse:0.74927\tvalid-rmse:0.77963\n",
      "[300]\ttrain-rmse:0.56364\tvalid-rmse:0.63440\n",
      "[400]\ttrain-rmse:0.47319\tvalid-rmse:0.57872\n",
      "[500]\ttrain-rmse:0.42354\tvalid-rmse:0.55880\n",
      "[600]\ttrain-rmse:0.38848\tvalid-rmse:0.54968\n",
      "[700]\ttrain-rmse:0.36224\tvalid-rmse:0.54395\n",
      "[800]\ttrain-rmse:0.34050\tvalid-rmse:0.54123\n",
      "[900]\ttrain-rmse:0.32274\tvalid-rmse:0.53961\n",
      "[1000]\ttrain-rmse:0.30619\tvalid-rmse:0.53802\n",
      "[1100]\ttrain-rmse:0.29116\tvalid-rmse:0.53782\n",
      "[1103]\ttrain-rmse:0.29065\tvalid-rmse:0.53791\n",
      "[0]\ttrain-rmse:1.84803\tvalid-rmse:1.68977\n",
      "[100]\ttrain-rmse:1.13596\tvalid-rmse:1.02655\n",
      "[200]\ttrain-rmse:0.75875\tvalid-rmse:0.69637\n",
      "[300]\ttrain-rmse:0.57134\tvalid-rmse:0.56074\n",
      "[400]\ttrain-rmse:0.47832\tvalid-rmse:0.51371\n",
      "[500]\ttrain-rmse:0.42919\tvalid-rmse:0.50674\n",
      "[530]\ttrain-rmse:0.41701\tvalid-rmse:0.50655\n",
      "[0]\ttrain-rmse:1.81902\tvalid-rmse:1.80958\n",
      "[100]\ttrain-rmse:1.11232\tvalid-rmse:1.16400\n",
      "[200]\ttrain-rmse:0.73471\tvalid-rmse:0.84349\n",
      "[300]\ttrain-rmse:0.54243\tvalid-rmse:0.69924\n",
      "[400]\ttrain-rmse:0.44720\tvalid-rmse:0.64160\n",
      "[500]\ttrain-rmse:0.39590\tvalid-rmse:0.62054\n",
      "[600]\ttrain-rmse:0.36377\tvalid-rmse:0.61457\n",
      "[700]\ttrain-rmse:0.33704\tvalid-rmse:0.61349\n",
      "[800]\ttrain-rmse:0.31603\tvalid-rmse:0.61311\n",
      "[830]\ttrain-rmse:0.31074\tvalid-rmse:0.61327\n",
      "[0]\ttrain-rmse:1.80727\tvalid-rmse:1.85722\n",
      "[100]\ttrain-rmse:1.09888\tvalid-rmse:1.17519\n",
      "[200]\ttrain-rmse:0.72023\tvalid-rmse:0.86503\n",
      "[300]\ttrain-rmse:0.52693\tvalid-rmse:0.75449\n",
      "[400]\ttrain-rmse:0.43006\tvalid-rmse:0.72665\n",
      "[500]\ttrain-rmse:0.37925\tvalid-rmse:0.72212\n",
      "[600]\ttrain-rmse:0.34677\tvalid-rmse:0.72140\n",
      "[628]\ttrain-rmse:0.33928\tvalid-rmse:0.72148\n",
      "[0]\ttrain-rmse:1.78306\tvalid-rmse:1.94706\n",
      "[100]\ttrain-rmse:1.08992\tvalid-rmse:1.25538\n",
      "[200]\ttrain-rmse:0.71730\tvalid-rmse:0.91660\n",
      "[300]\ttrain-rmse:0.53086\tvalid-rmse:0.77484\n",
      "[400]\ttrain-rmse:0.44045\tvalid-rmse:0.72066\n",
      "[500]\ttrain-rmse:0.39412\tvalid-rmse:0.70173\n",
      "[600]\ttrain-rmse:0.36286\tvalid-rmse:0.69415\n",
      "[700]\ttrain-rmse:0.33814\tvalid-rmse:0.68855\n",
      "[800]\ttrain-rmse:0.31850\tvalid-rmse:0.68558\n",
      "[878]\ttrain-rmse:0.30515\tvalid-rmse:0.68507\n",
      "[0]\ttrain-rmse:1.99945\tvalid-rmse:1.94823\n",
      "[100]\ttrain-rmse:1.22885\tvalid-rmse:1.21990\n",
      "[200]\ttrain-rmse:0.81967\tvalid-rmse:0.85974\n",
      "[300]\ttrain-rmse:0.61581\tvalid-rmse:0.70364\n",
      "[400]\ttrain-rmse:0.51502\tvalid-rmse:0.64368\n",
      "[500]\ttrain-rmse:0.46065\tvalid-rmse:0.62348\n",
      "[600]\ttrain-rmse:0.42231\tvalid-rmse:0.61434\n",
      "[700]\ttrain-rmse:0.39350\tvalid-rmse:0.60860\n",
      "[800]\ttrain-rmse:0.36993\tvalid-rmse:0.60544\n",
      "[900]\ttrain-rmse:0.35087\tvalid-rmse:0.60400\n",
      "[1000]\ttrain-rmse:0.33294\tvalid-rmse:0.60269\n",
      "[1100]\ttrain-rmse:0.31638\tvalid-rmse:0.60237\n",
      "[1185]\ttrain-rmse:0.30285\tvalid-rmse:0.60262\n",
      "[0]\ttrain-rmse:2.02216\tvalid-rmse:1.85395\n",
      "[100]\ttrain-rmse:1.24313\tvalid-rmse:1.13299\n",
      "[200]\ttrain-rmse:0.83057\tvalid-rmse:0.77526\n",
      "[300]\ttrain-rmse:0.62610\tvalid-rmse:0.63080\n",
      "[400]\ttrain-rmse:0.52583\tvalid-rmse:0.58351\n",
      "[500]\ttrain-rmse:0.47032\tvalid-rmse:0.57510\n",
      "[556]\ttrain-rmse:0.44543\tvalid-rmse:0.57638\n",
      "[0]\ttrain-rmse:1.98844\tvalid-rmse:1.99293\n",
      "[100]\ttrain-rmse:1.21577\tvalid-rmse:1.29265\n",
      "[200]\ttrain-rmse:0.80155\tvalid-rmse:0.94566\n",
      "[300]\ttrain-rmse:0.59031\tvalid-rmse:0.78880\n",
      "[400]\ttrain-rmse:0.48470\tvalid-rmse:0.72509\n",
      "[500]\ttrain-rmse:0.42784\tvalid-rmse:0.70226\n",
      "[600]\ttrain-rmse:0.39312\tvalid-rmse:0.69594\n",
      "[682]\ttrain-rmse:0.37007\tvalid-rmse:0.69537\n",
      "[0]\ttrain-rmse:1.97751\tvalid-rmse:2.03700\n",
      "[100]\ttrain-rmse:1.20260\tvalid-rmse:1.29604\n",
      "[200]\ttrain-rmse:0.78795\tvalid-rmse:0.96116\n",
      "[300]\ttrain-rmse:0.57738\tvalid-rmse:0.84275\n",
      "[400]\ttrain-rmse:0.47008\tvalid-rmse:0.81284\n",
      "[500]\ttrain-rmse:0.41408\tvalid-rmse:0.80903\n",
      "[600]\ttrain-rmse:0.37784\tvalid-rmse:0.80868\n",
      "[614]\ttrain-rmse:0.37375\tvalid-rmse:0.80864\n",
      "[0]\ttrain-rmse:1.95670\tvalid-rmse:2.11400\n",
      "[100]\ttrain-rmse:1.19887\tvalid-rmse:1.35210\n",
      "[200]\ttrain-rmse:0.79210\tvalid-rmse:0.97782\n",
      "[300]\ttrain-rmse:0.58863\tvalid-rmse:0.82075\n",
      "[400]\ttrain-rmse:0.48982\tvalid-rmse:0.76179\n",
      "[500]\ttrain-rmse:0.43845\tvalid-rmse:0.74160\n",
      "[600]\ttrain-rmse:0.40317\tvalid-rmse:0.73464\n",
      "[700]\ttrain-rmse:0.37565\tvalid-rmse:0.72897\n",
      "[800]\ttrain-rmse:0.35360\tvalid-rmse:0.72470\n",
      "[878]\ttrain-rmse:0.33875\tvalid-rmse:0.72436\n",
      "[0]\ttrain-rmse:2.17313\tvalid-rmse:2.11740\n",
      "[100]\ttrain-rmse:1.33690\tvalid-rmse:1.33166\n",
      "[200]\ttrain-rmse:0.89180\tvalid-rmse:0.94240\n",
      "[300]\ttrain-rmse:0.66977\tvalid-rmse:0.77557\n",
      "[400]\ttrain-rmse:0.55962\tvalid-rmse:0.71328\n",
      "[500]\ttrain-rmse:0.50026\tvalid-rmse:0.69180\n",
      "[600]\ttrain-rmse:0.45828\tvalid-rmse:0.68143\n",
      "[700]\ttrain-rmse:0.42663\tvalid-rmse:0.67521\n",
      "[800]\ttrain-rmse:0.40124\tvalid-rmse:0.67183\n",
      "[900]\ttrain-rmse:0.38019\tvalid-rmse:0.66993\n",
      "[1000]\ttrain-rmse:0.36062\tvalid-rmse:0.66833\n",
      "[1100]\ttrain-rmse:0.34286\tvalid-rmse:0.66785\n",
      "[1200]\ttrain-rmse:0.32551\tvalid-rmse:0.66775\n",
      "[1209]\ttrain-rmse:0.32416\tvalid-rmse:0.66775\n",
      "[0]\ttrain-rmse:2.19724\tvalid-rmse:2.01791\n",
      "[100]\ttrain-rmse:1.35180\tvalid-rmse:1.23954\n",
      "[200]\ttrain-rmse:0.90427\tvalid-rmse:0.85654\n",
      "[300]\ttrain-rmse:0.68169\tvalid-rmse:0.70130\n",
      "[400]\ttrain-rmse:0.57199\tvalid-rmse:0.65114\n",
      "[500]\ttrain-rmse:0.51124\tvalid-rmse:0.64161\n",
      "[563]\ttrain-rmse:0.48151\tvalid-rmse:0.64349\n",
      "[0]\ttrain-rmse:2.15936\tvalid-rmse:2.17329\n",
      "[100]\ttrain-rmse:1.32032\tvalid-rmse:1.41880\n",
      "[200]\ttrain-rmse:0.86955\tvalid-rmse:1.04436\n",
      "[300]\ttrain-rmse:0.63925\tvalid-rmse:0.87470\n",
      "[400]\ttrain-rmse:0.52387\tvalid-rmse:0.80644\n",
      "[500]\ttrain-rmse:0.46131\tvalid-rmse:0.78140\n",
      "[600]\ttrain-rmse:0.42255\tvalid-rmse:0.77405\n",
      "[700]\ttrain-rmse:0.39203\tvalid-rmse:0.77330\n",
      "[701]\ttrain-rmse:0.39159\tvalid-rmse:0.77330\n",
      "[0]\ttrain-rmse:2.14859\tvalid-rmse:2.21687\n",
      "[100]\ttrain-rmse:1.30791\tvalid-rmse:1.41759\n",
      "[200]\ttrain-rmse:0.85775\tvalid-rmse:1.05847\n",
      "[300]\ttrain-rmse:0.62911\tvalid-rmse:0.93228\n",
      "[400]\ttrain-rmse:0.51237\tvalid-rmse:0.90090\n",
      "[500]\ttrain-rmse:0.45067\tvalid-rmse:0.89722\n",
      "[527]\ttrain-rmse:0.43901\tvalid-rmse:0.89702\n",
      "[0]\ttrain-rmse:2.12992\tvalid-rmse:2.28591\n",
      "[100]\ttrain-rmse:1.30845\tvalid-rmse:1.45601\n",
      "[200]\ttrain-rmse:0.86813\tvalid-rmse:1.04547\n",
      "[300]\ttrain-rmse:0.64782\tvalid-rmse:0.87115\n",
      "[400]\ttrain-rmse:0.54026\tvalid-rmse:0.80666\n",
      "[500]\ttrain-rmse:0.48442\tvalid-rmse:0.78469\n",
      "[600]\ttrain-rmse:0.44490\tvalid-rmse:0.77712\n",
      "[700]\ttrain-rmse:0.41443\tvalid-rmse:0.77063\n",
      "[800]\ttrain-rmse:0.38990\tvalid-rmse:0.76583\n",
      "[900]\ttrain-rmse:0.36948\tvalid-rmse:0.76554\n",
      "[913]\ttrain-rmse:0.36704\tvalid-rmse:0.76529\n",
      "[0]\ttrain-rmse:2.34740\tvalid-rmse:2.40077\n",
      "[100]\ttrain-rmse:1.44556\tvalid-rmse:1.58234\n",
      "[200]\ttrain-rmse:0.96535\tvalid-rmse:1.18869\n",
      "[300]\ttrain-rmse:0.72566\tvalid-rmse:1.02120\n",
      "[400]\ttrain-rmse:0.60589\tvalid-rmse:0.95736\n",
      "[500]\ttrain-rmse:0.54148\tvalid-rmse:0.93224\n",
      "[600]\ttrain-rmse:0.49580\tvalid-rmse:0.91966\n",
      "[700]\ttrain-rmse:0.46189\tvalid-rmse:0.91353\n",
      "[800]\ttrain-rmse:0.43452\tvalid-rmse:0.90984\n",
      "[900]\ttrain-rmse:0.41190\tvalid-rmse:0.90753\n",
      "[1000]\ttrain-rmse:0.39031\tvalid-rmse:0.90604\n",
      "[1100]\ttrain-rmse:0.37039\tvalid-rmse:0.90474\n",
      "[1200]\ttrain-rmse:0.35142\tvalid-rmse:0.90455\n",
      "[1210]\ttrain-rmse:0.34963\tvalid-rmse:0.90451\n",
      "[0]\ttrain-rmse:2.40069\tvalid-rmse:2.18233\n",
      "[100]\ttrain-rmse:1.48756\tvalid-rmse:1.34593\n",
      "[200]\ttrain-rmse:1.00641\tvalid-rmse:0.93780\n",
      "[300]\ttrain-rmse:0.76805\tvalid-rmse:0.77474\n",
      "[400]\ttrain-rmse:0.64919\tvalid-rmse:0.72412\n",
      "[500]\ttrain-rmse:0.58260\tvalid-rmse:0.71644\n",
      "[541]\ttrain-rmse:0.56043\tvalid-rmse:0.71785\n",
      "[0]\ttrain-rmse:2.35928\tvalid-rmse:2.35394\n",
      "[100]\ttrain-rmse:1.45199\tvalid-rmse:1.53352\n",
      "[200]\ttrain-rmse:0.96770\tvalid-rmse:1.12958\n",
      "[300]\ttrain-rmse:0.72235\tvalid-rmse:0.95392\n",
      "[400]\ttrain-rmse:0.59763\tvalid-rmse:0.88525\n",
      "[500]\ttrain-rmse:0.52916\tvalid-rmse:0.86181\n",
      "[600]\ttrain-rmse:0.48667\tvalid-rmse:0.85550\n",
      "[700]\ttrain-rmse:0.45253\tvalid-rmse:0.85381\n",
      "[746]\ttrain-rmse:0.44076\tvalid-rmse:0.85430\n",
      "[0]\ttrain-rmse:2.34904\tvalid-rmse:2.39571\n",
      "[100]\ttrain-rmse:1.44227\tvalid-rmse:1.52427\n",
      "[200]\ttrain-rmse:0.96050\tvalid-rmse:1.13958\n",
      "[300]\ttrain-rmse:0.71860\tvalid-rmse:1.01255\n",
      "[400]\ttrain-rmse:0.59584\tvalid-rmse:0.98803\n",
      "[474]\ttrain-rmse:0.54309\tvalid-rmse:0.98745\n",
      "[0]\ttrain-rmse:2.33182\tvalid-rmse:2.45981\n",
      "[100]\ttrain-rmse:1.44609\tvalid-rmse:1.56358\n",
      "[200]\ttrain-rmse:0.97432\tvalid-rmse:1.11764\n",
      "[300]\ttrain-rmse:0.74129\tvalid-rmse:0.93232\n",
      "[400]\ttrain-rmse:0.62531\tvalid-rmse:0.86272\n",
      "[500]\ttrain-rmse:0.56351\tvalid-rmse:0.84170\n",
      "[600]\ttrain-rmse:0.51939\tvalid-rmse:0.83658\n",
      "[700]\ttrain-rmse:0.48551\tvalid-rmse:0.83487\n",
      "[768]\ttrain-rmse:0.46734\tvalid-rmse:0.83543\n",
      "[0]\ttrain-rmse:2.52177\tvalid-rmse:2.55924\n",
      "[100]\ttrain-rmse:1.55422\tvalid-rmse:1.68005\n",
      "[200]\ttrain-rmse:1.03928\tvalid-rmse:1.25452\n",
      "[300]\ttrain-rmse:0.78173\tvalid-rmse:1.07495\n",
      "[400]\ttrain-rmse:0.65290\tvalid-rmse:1.00771\n",
      "[500]\ttrain-rmse:0.58383\tvalid-rmse:0.98125\n",
      "[600]\ttrain-rmse:0.53422\tvalid-rmse:0.96889\n",
      "[700]\ttrain-rmse:0.49775\tvalid-rmse:0.96294\n",
      "[800]\ttrain-rmse:0.46892\tvalid-rmse:0.95844\n",
      "[900]\ttrain-rmse:0.44430\tvalid-rmse:0.95605\n",
      "[1000]\ttrain-rmse:0.42137\tvalid-rmse:0.95464\n",
      "[1100]\ttrain-rmse:0.39992\tvalid-rmse:0.95325\n",
      "[1200]\ttrain-rmse:0.37978\tvalid-rmse:0.95311\n",
      "[1209]\ttrain-rmse:0.37812\tvalid-rmse:0.95313\n",
      "[0]\ttrain-rmse:2.57369\tvalid-rmse:2.34634\n",
      "[100]\ttrain-rmse:1.59425\tvalid-rmse:1.45257\n",
      "[200]\ttrain-rmse:1.07728\tvalid-rmse:1.01897\n",
      "[300]\ttrain-rmse:0.82055\tvalid-rmse:0.84679\n",
      "[400]\ttrain-rmse:0.69258\tvalid-rmse:0.79530\n",
      "[500]\ttrain-rmse:0.62045\tvalid-rmse:0.78885\n",
      "[538]\ttrain-rmse:0.59814\tvalid-rmse:0.79004\n",
      "[0]\ttrain-rmse:2.52855\tvalid-rmse:2.53269\n",
      "[100]\ttrain-rmse:1.55503\tvalid-rmse:1.65771\n",
      "[200]\ttrain-rmse:1.03464\tvalid-rmse:1.22830\n",
      "[300]\ttrain-rmse:0.76938\tvalid-rmse:1.04041\n",
      "[400]\ttrain-rmse:0.63484\tvalid-rmse:0.96700\n",
      "[500]\ttrain-rmse:0.56069\tvalid-rmse:0.94044\n",
      "[600]\ttrain-rmse:0.51464\tvalid-rmse:0.93399\n",
      "[700]\ttrain-rmse:0.47841\tvalid-rmse:0.93196\n",
      "[751]\ttrain-rmse:0.46420\tvalid-rmse:0.93238\n",
      "[0]\ttrain-rmse:2.51807\tvalid-rmse:2.57551\n",
      "[100]\ttrain-rmse:1.54534\tvalid-rmse:1.64817\n",
      "[200]\ttrain-rmse:1.02737\tvalid-rmse:1.24145\n",
      "[300]\ttrain-rmse:0.76639\tvalid-rmse:1.10944\n",
      "[400]\ttrain-rmse:0.63401\tvalid-rmse:1.08426\n",
      "[493]\ttrain-rmse:0.56569\tvalid-rmse:1.08422\n",
      "[0]\ttrain-rmse:2.50173\tvalid-rmse:2.63606\n",
      "[100]\ttrain-rmse:1.55203\tvalid-rmse:1.67359\n",
      "[200]\ttrain-rmse:1.04555\tvalid-rmse:1.19456\n",
      "[300]\ttrain-rmse:0.79487\tvalid-rmse:0.99338\n",
      "[400]\ttrain-rmse:0.67086\tvalid-rmse:0.91913\n",
      "[500]\ttrain-rmse:0.60388\tvalid-rmse:0.89681\n",
      "[600]\ttrain-rmse:0.55587\tvalid-rmse:0.89044\n",
      "[700]\ttrain-rmse:0.51924\tvalid-rmse:0.88770\n",
      "[728]\ttrain-rmse:0.51048\tvalid-rmse:0.88759\n",
      "[0]\ttrain-rmse:2.69333\tvalid-rmse:2.72929\n",
      "[100]\ttrain-rmse:1.65917\tvalid-rmse:1.79210\n",
      "[200]\ttrain-rmse:1.10794\tvalid-rmse:1.33931\n",
      "[300]\ttrain-rmse:0.83139\tvalid-rmse:1.15001\n",
      "[400]\ttrain-rmse:0.69230\tvalid-rmse:1.07913\n",
      "[500]\ttrain-rmse:0.61759\tvalid-rmse:1.05151\n",
      "[600]\ttrain-rmse:0.56480\tvalid-rmse:1.03966\n",
      "[700]\ttrain-rmse:0.52560\tvalid-rmse:1.03283\n",
      "[800]\ttrain-rmse:0.49479\tvalid-rmse:1.02870\n",
      "[900]\ttrain-rmse:0.46844\tvalid-rmse:1.02497\n",
      "[1000]\ttrain-rmse:0.44427\tvalid-rmse:1.02347\n",
      "[1100]\ttrain-rmse:0.42232\tvalid-rmse:1.02221\n",
      "[1191]\ttrain-rmse:0.40289\tvalid-rmse:1.02203\n",
      "[0]\ttrain-rmse:2.74632\tvalid-rmse:2.51218\n",
      "[100]\ttrain-rmse:1.69932\tvalid-rmse:1.56314\n",
      "[200]\ttrain-rmse:1.14597\tvalid-rmse:1.10540\n",
      "[300]\ttrain-rmse:0.86953\tvalid-rmse:0.92365\n",
      "[400]\ttrain-rmse:0.73056\tvalid-rmse:0.87121\n",
      "[500]\ttrain-rmse:0.65334\tvalid-rmse:0.86429\n",
      "[538]\ttrain-rmse:0.62909\tvalid-rmse:0.86510\n",
      "[0]\ttrain-rmse:2.70095\tvalid-rmse:2.69944\n",
      "[100]\ttrain-rmse:1.66187\tvalid-rmse:1.76446\n",
      "[200]\ttrain-rmse:1.10565\tvalid-rmse:1.30137\n",
      "[300]\ttrain-rmse:0.82185\tvalid-rmse:1.09796\n",
      "[400]\ttrain-rmse:0.67785\tvalid-rmse:1.01716\n",
      "[500]\ttrain-rmse:0.59845\tvalid-rmse:0.98716\n",
      "[600]\ttrain-rmse:0.54817\tvalid-rmse:0.97840\n",
      "[700]\ttrain-rmse:0.50956\tvalid-rmse:0.97587\n",
      "[800]\ttrain-rmse:0.48110\tvalid-rmse:0.97516\n",
      "[826]\ttrain-rmse:0.47498\tvalid-rmse:0.97553\n",
      "[0]\ttrain-rmse:2.68732\tvalid-rmse:2.75485\n",
      "[100]\ttrain-rmse:1.64836\tvalid-rmse:1.77074\n",
      "[200]\ttrain-rmse:1.09254\tvalid-rmse:1.34372\n",
      "[300]\ttrain-rmse:0.81033\tvalid-rmse:1.20353\n",
      "[400]\ttrain-rmse:0.66645\tvalid-rmse:1.17621\n",
      "[473]\ttrain-rmse:0.60552\tvalid-rmse:1.17450\n",
      "[0]\ttrain-rmse:2.67191\tvalid-rmse:2.81154\n",
      "[100]\ttrain-rmse:1.65769\tvalid-rmse:1.78434\n",
      "[200]\ttrain-rmse:1.11547\tvalid-rmse:1.27615\n",
      "[300]\ttrain-rmse:0.84570\tvalid-rmse:1.06416\n",
      "[400]\ttrain-rmse:0.71155\tvalid-rmse:0.98456\n",
      "[500]\ttrain-rmse:0.63875\tvalid-rmse:0.96185\n",
      "[600]\ttrain-rmse:0.58742\tvalid-rmse:0.95505\n",
      "[700]\ttrain-rmse:0.54819\tvalid-rmse:0.95209\n",
      "[800]\ttrain-rmse:0.51786\tvalid-rmse:0.94966\n",
      "[850]\ttrain-rmse:0.50467\tvalid-rmse:0.95157\n",
      "[0]\ttrain-rmse:2.95167\tvalid-rmse:2.88297\n",
      "[100]\ttrain-rmse:1.88104\tvalid-rmse:1.88904\n",
      "[200]\ttrain-rmse:1.32790\tvalid-rmse:1.41199\n",
      "[300]\ttrain-rmse:1.05602\tvalid-rmse:1.21678\n",
      "[400]\ttrain-rmse:0.91902\tvalid-rmse:1.14484\n",
      "[500]\ttrain-rmse:0.83731\tvalid-rmse:1.12252\n",
      "[600]\ttrain-rmse:0.77302\tvalid-rmse:1.11760\n",
      "[700]\ttrain-rmse:0.72260\tvalid-rmse:1.11502\n",
      "[800]\ttrain-rmse:0.68121\tvalid-rmse:1.11289\n",
      "[900]\ttrain-rmse:0.64459\tvalid-rmse:1.11019\n",
      "[1000]\ttrain-rmse:0.60966\tvalid-rmse:1.10879\n",
      "[1100]\ttrain-rmse:0.57788\tvalid-rmse:1.10620\n",
      "[1171]\ttrain-rmse:0.55438\tvalid-rmse:1.10608\n",
      "[0]\ttrain-rmse:3.00071\tvalid-rmse:2.67571\n",
      "[100]\ttrain-rmse:1.91800\tvalid-rmse:1.66632\n",
      "[200]\ttrain-rmse:1.36318\tvalid-rmse:1.18478\n",
      "[300]\ttrain-rmse:1.09170\tvalid-rmse:1.00086\n",
      "[400]\ttrain-rmse:0.95230\tvalid-rmse:0.95237\n",
      "[500]\ttrain-rmse:0.86705\tvalid-rmse:0.95338\n",
      "[508]\ttrain-rmse:0.86077\tvalid-rmse:0.95450\n",
      "[0]\ttrain-rmse:2.86736\tvalid-rmse:3.20581\n",
      "[100]\ttrain-rmse:1.76454\tvalid-rmse:2.35223\n",
      "[200]\ttrain-rmse:1.17391\tvalid-rmse:1.97766\n",
      "[300]\ttrain-rmse:0.87214\tvalid-rmse:1.83032\n",
      "[400]\ttrain-rmse:0.71814\tvalid-rmse:1.77634\n",
      "[500]\ttrain-rmse:0.63392\tvalid-rmse:1.75703\n",
      "[600]\ttrain-rmse:0.58078\tvalid-rmse:1.75155\n",
      "[700]\ttrain-rmse:0.54013\tvalid-rmse:1.74955\n",
      "[791]\ttrain-rmse:0.51146\tvalid-rmse:1.74954\n",
      "[0]\ttrain-rmse:2.94045\tvalid-rmse:2.93172\n",
      "[100]\ttrain-rmse:1.87056\tvalid-rmse:1.89052\n",
      "[200]\ttrain-rmse:1.31539\tvalid-rmse:1.44158\n",
      "[300]\ttrain-rmse:1.04062\tvalid-rmse:1.29767\n",
      "[400]\ttrain-rmse:0.90194\tvalid-rmse:1.26955\n",
      "[471]\ttrain-rmse:0.83768\tvalid-rmse:1.27102\n",
      "[0]\ttrain-rmse:2.92642\tvalid-rmse:2.98382\n",
      "[100]\ttrain-rmse:1.87576\tvalid-rmse:1.89143\n",
      "[200]\ttrain-rmse:1.33459\tvalid-rmse:1.35663\n",
      "[300]\ttrain-rmse:1.06949\tvalid-rmse:1.13636\n",
      "[400]\ttrain-rmse:0.93623\tvalid-rmse:1.05915\n",
      "[500]\ttrain-rmse:0.85443\tvalid-rmse:1.04021\n",
      "[587]\ttrain-rmse:0.80022\tvalid-rmse:1.03823\n",
      "[0]\ttrain-rmse:3.11704\tvalid-rmse:3.03690\n",
      "[100]\ttrain-rmse:1.98037\tvalid-rmse:1.98581\n",
      "[200]\ttrain-rmse:1.39137\tvalid-rmse:1.48334\n",
      "[300]\ttrain-rmse:1.10091\tvalid-rmse:1.27906\n",
      "[400]\ttrain-rmse:0.95357\tvalid-rmse:1.20442\n",
      "[500]\ttrain-rmse:0.86715\tvalid-rmse:1.18015\n",
      "[600]\ttrain-rmse:0.79992\tvalid-rmse:1.17470\n",
      "[700]\ttrain-rmse:0.74753\tvalid-rmse:1.17252\n",
      "[800]\ttrain-rmse:0.70433\tvalid-rmse:1.17075\n",
      "[900]\ttrain-rmse:0.66634\tvalid-rmse:1.16886\n",
      "[1000]\ttrain-rmse:0.62989\tvalid-rmse:1.16756\n",
      "[1100]\ttrain-rmse:0.59763\tvalid-rmse:1.16650\n",
      "[1200]\ttrain-rmse:0.56429\tvalid-rmse:1.16590\n",
      "[1216]\ttrain-rmse:0.56002\tvalid-rmse:1.16609\n",
      "[0]\ttrain-rmse:3.16356\tvalid-rmse:2.84090\n",
      "[100]\ttrain-rmse:2.01372\tvalid-rmse:1.77349\n",
      "[200]\ttrain-rmse:1.42220\tvalid-rmse:1.26815\n",
      "[300]\ttrain-rmse:1.13143\tvalid-rmse:1.07348\n",
      "[400]\ttrain-rmse:0.98277\tvalid-rmse:1.02133\n",
      "[500]\ttrain-rmse:0.89279\tvalid-rmse:1.01890\n",
      "[508]\ttrain-rmse:0.88633\tvalid-rmse:1.01985\n",
      "[0]\ttrain-rmse:3.03349\tvalid-rmse:3.35867\n",
      "[100]\ttrain-rmse:1.86774\tvalid-rmse:2.44424\n",
      "[200]\ttrain-rmse:1.24260\tvalid-rmse:2.03537\n",
      "[300]\ttrain-rmse:0.92262\tvalid-rmse:1.87423\n",
      "[400]\ttrain-rmse:0.75925\tvalid-rmse:1.81258\n",
      "[500]\ttrain-rmse:0.66941\tvalid-rmse:1.79071\n",
      "[600]\ttrain-rmse:0.61251\tvalid-rmse:1.78426\n",
      "[700]\ttrain-rmse:0.57005\tvalid-rmse:1.78183\n",
      "[800]\ttrain-rmse:0.53683\tvalid-rmse:1.78074\n",
      "[824]\ttrain-rmse:0.53037\tvalid-rmse:1.78092\n",
      "[0]\ttrain-rmse:3.10106\tvalid-rmse:3.10503\n",
      "[100]\ttrain-rmse:1.96543\tvalid-rmse:2.00803\n",
      "[200]\ttrain-rmse:1.37353\tvalid-rmse:1.53847\n",
      "[300]\ttrain-rmse:1.07837\tvalid-rmse:1.38769\n",
      "[400]\ttrain-rmse:0.92965\tvalid-rmse:1.35747\n",
      "[471]\ttrain-rmse:0.86228\tvalid-rmse:1.35916\n",
      "[0]\ttrain-rmse:3.08696\tvalid-rmse:3.15734\n",
      "[100]\ttrain-rmse:1.97239\tvalid-rmse:2.00428\n",
      "[200]\ttrain-rmse:1.39547\tvalid-rmse:1.43815\n",
      "[300]\ttrain-rmse:1.11125\tvalid-rmse:1.20704\n",
      "[400]\ttrain-rmse:0.96844\tvalid-rmse:1.12373\n",
      "[500]\ttrain-rmse:0.88293\tvalid-rmse:1.10389\n",
      "[586]\ttrain-rmse:0.82713\tvalid-rmse:1.10099\n",
      "[0]\ttrain-rmse:3.28180\tvalid-rmse:3.19257\n",
      "[100]\ttrain-rmse:2.08031\tvalid-rmse:2.08485\n",
      "[200]\ttrain-rmse:1.45559\tvalid-rmse:1.55647\n",
      "[300]\ttrain-rmse:1.14623\tvalid-rmse:1.34152\n",
      "[400]\ttrain-rmse:0.98975\tvalid-rmse:1.26421\n",
      "[500]\ttrain-rmse:0.89764\tvalid-rmse:1.23763\n",
      "[600]\ttrain-rmse:0.82784\tvalid-rmse:1.23431\n",
      "[700]\ttrain-rmse:0.77288\tvalid-rmse:1.23063\n",
      "[800]\ttrain-rmse:0.72811\tvalid-rmse:1.22837\n",
      "[900]\ttrain-rmse:0.68969\tvalid-rmse:1.22636\n",
      "[953]\ttrain-rmse:0.66914\tvalid-rmse:1.22613\n",
      "[0]\ttrain-rmse:3.32634\tvalid-rmse:3.00536\n",
      "[100]\ttrain-rmse:2.11028\tvalid-rmse:1.88460\n",
      "[200]\ttrain-rmse:1.48401\tvalid-rmse:1.35311\n",
      "[300]\ttrain-rmse:1.17515\tvalid-rmse:1.15040\n",
      "[400]\ttrain-rmse:1.01708\tvalid-rmse:1.09840\n",
      "[500]\ttrain-rmse:0.92281\tvalid-rmse:1.09498\n",
      "[542]\ttrain-rmse:0.89184\tvalid-rmse:1.09775\n",
      "[0]\ttrain-rmse:3.19931\tvalid-rmse:3.51203\n",
      "[100]\ttrain-rmse:1.97031\tvalid-rmse:2.53610\n",
      "[200]\ttrain-rmse:1.31091\tvalid-rmse:2.09548\n",
      "[300]\ttrain-rmse:0.97353\tvalid-rmse:1.92222\n",
      "[400]\ttrain-rmse:0.80034\tvalid-rmse:1.85556\n",
      "[500]\ttrain-rmse:0.70573\tvalid-rmse:1.83045\n",
      "[600]\ttrain-rmse:0.64478\tvalid-rmse:1.82212\n",
      "[700]\ttrain-rmse:0.59996\tvalid-rmse:1.81973\n",
      "[800]\ttrain-rmse:0.56567\tvalid-rmse:1.81893\n",
      "[829]\ttrain-rmse:0.55792\tvalid-rmse:1.81904\n",
      "[0]\ttrain-rmse:3.26203\tvalid-rmse:3.27628\n",
      "[100]\ttrain-rmse:2.06124\tvalid-rmse:2.12549\n",
      "[200]\ttrain-rmse:1.43237\tvalid-rmse:1.63514\n",
      "[300]\ttrain-rmse:1.11681\tvalid-rmse:1.47838\n",
      "[400]\ttrain-rmse:0.95796\tvalid-rmse:1.44916\n",
      "[474]\ttrain-rmse:0.88455\tvalid-rmse:1.45087\n",
      "[0]\ttrain-rmse:3.24731\tvalid-rmse:3.33034\n",
      "[100]\ttrain-rmse:2.06998\tvalid-rmse:2.11557\n",
      "[200]\ttrain-rmse:1.45801\tvalid-rmse:1.52070\n",
      "[300]\ttrain-rmse:1.15541\tvalid-rmse:1.27676\n",
      "[400]\ttrain-rmse:1.00373\tvalid-rmse:1.18807\n",
      "[500]\ttrain-rmse:0.91458\tvalid-rmse:1.16687\n",
      "[600]\ttrain-rmse:0.84759\tvalid-rmse:1.16511\n",
      "[627]\ttrain-rmse:0.83203\tvalid-rmse:1.16669\n",
      "[0]\ttrain-rmse:3.44759\tvalid-rmse:3.35014\n",
      "[100]\ttrain-rmse:2.18106\tvalid-rmse:2.18594\n",
      "[200]\ttrain-rmse:1.52032\tvalid-rmse:1.63279\n",
      "[300]\ttrain-rmse:1.19242\tvalid-rmse:1.40927\n",
      "[400]\ttrain-rmse:1.02531\tvalid-rmse:1.32980\n",
      "[500]\ttrain-rmse:0.92936\tvalid-rmse:1.30349\n",
      "[600]\ttrain-rmse:0.85636\tvalid-rmse:1.29770\n",
      "[700]\ttrain-rmse:0.79871\tvalid-rmse:1.29315\n",
      "[800]\ttrain-rmse:0.75211\tvalid-rmse:1.29058\n",
      "[900]\ttrain-rmse:0.71171\tvalid-rmse:1.28968\n",
      "[1000]\ttrain-rmse:0.67285\tvalid-rmse:1.28803\n",
      "[1100]\ttrain-rmse:0.63736\tvalid-rmse:1.28677\n",
      "[1179]\ttrain-rmse:0.60962\tvalid-rmse:1.28690\n",
      "[0]\ttrain-rmse:3.49039\tvalid-rmse:3.17136\n",
      "[100]\ttrain-rmse:2.20946\tvalid-rmse:1.99554\n",
      "[200]\ttrain-rmse:1.54766\tvalid-rmse:1.44034\n",
      "[300]\ttrain-rmse:1.21936\tvalid-rmse:1.23133\n",
      "[400]\ttrain-rmse:1.05185\tvalid-rmse:1.17776\n",
      "[500]\ttrain-rmse:0.95332\tvalid-rmse:1.17539\n",
      "[511]\ttrain-rmse:0.94393\tvalid-rmse:1.17714\n",
      "[0]\ttrain-rmse:3.36630\tvalid-rmse:3.66647\n",
      "[100]\ttrain-rmse:2.07465\tvalid-rmse:2.62765\n",
      "[200]\ttrain-rmse:1.38243\tvalid-rmse:2.15706\n",
      "[300]\ttrain-rmse:1.02673\tvalid-rmse:1.96981\n",
      "[400]\ttrain-rmse:0.84439\tvalid-rmse:1.89818\n",
      "[500]\ttrain-rmse:0.74429\tvalid-rmse:1.87039\n",
      "[600]\ttrain-rmse:0.68021\tvalid-rmse:1.86102\n",
      "[700]\ttrain-rmse:0.63277\tvalid-rmse:1.85818\n",
      "[800]\ttrain-rmse:0.59654\tvalid-rmse:1.85695\n",
      "[819]\ttrain-rmse:0.59066\tvalid-rmse:1.85728\n",
      "[0]\ttrain-rmse:3.42468\tvalid-rmse:3.44701\n",
      "[100]\ttrain-rmse:2.15769\tvalid-rmse:2.24157\n",
      "[200]\ttrain-rmse:1.49272\tvalid-rmse:1.73030\n",
      "[300]\ttrain-rmse:1.15756\tvalid-rmse:1.56884\n",
      "[400]\ttrain-rmse:0.98805\tvalid-rmse:1.53789\n",
      "[472]\ttrain-rmse:0.91405\tvalid-rmse:1.54047\n",
      "[0]\ttrain-rmse:3.40893\tvalid-rmse:3.50508\n",
      "[100]\ttrain-rmse:2.16876\tvalid-rmse:2.23087\n",
      "[200]\ttrain-rmse:1.52255\tvalid-rmse:1.60831\n",
      "[300]\ttrain-rmse:1.20117\tvalid-rmse:1.35526\n",
      "[400]\ttrain-rmse:1.04008\tvalid-rmse:1.26763\n",
      "[500]\ttrain-rmse:0.94743\tvalid-rmse:1.24480\n",
      "[600]\ttrain-rmse:0.87787\tvalid-rmse:1.24195\n",
      "[625]\ttrain-rmse:0.86261\tvalid-rmse:1.24263\n",
      "[0]\ttrain-rmse:3.61390\tvalid-rmse:3.50906\n",
      "[100]\ttrain-rmse:2.28280\tvalid-rmse:2.28734\n",
      "[200]\ttrain-rmse:1.58646\tvalid-rmse:1.70684\n",
      "[300]\ttrain-rmse:1.24043\tvalid-rmse:1.47342\n",
      "[400]\ttrain-rmse:1.06428\tvalid-rmse:1.39213\n",
      "[500]\ttrain-rmse:0.96312\tvalid-rmse:1.36575\n",
      "[600]\ttrain-rmse:0.88608\tvalid-rmse:1.36143\n",
      "[700]\ttrain-rmse:0.82562\tvalid-rmse:1.35649\n",
      "[800]\ttrain-rmse:0.77816\tvalid-rmse:1.35251\n",
      "[900]\ttrain-rmse:0.73665\tvalid-rmse:1.35133\n",
      "[1000]\ttrain-rmse:0.69654\tvalid-rmse:1.35077\n",
      "[1100]\ttrain-rmse:0.66094\tvalid-rmse:1.34901\n",
      "[1200]\ttrain-rmse:0.62472\tvalid-rmse:1.34905\n",
      "[1224]\ttrain-rmse:0.61772\tvalid-rmse:1.34889\n",
      "[0]\ttrain-rmse:3.65533\tvalid-rmse:3.33665\n",
      "[100]\ttrain-rmse:2.30914\tvalid-rmse:2.10743\n",
      "[200]\ttrain-rmse:1.61166\tvalid-rmse:1.52656\n",
      "[300]\ttrain-rmse:1.26451\tvalid-rmse:1.30885\n",
      "[400]\ttrain-rmse:1.08798\tvalid-rmse:1.25394\n",
      "[500]\ttrain-rmse:0.98604\tvalid-rmse:1.25159\n",
      "[512]\ttrain-rmse:0.97529\tvalid-rmse:1.25348\n",
      "[0]\ttrain-rmse:3.53404\tvalid-rmse:3.82106\n",
      "[100]\ttrain-rmse:2.18020\tvalid-rmse:2.72062\n",
      "[200]\ttrain-rmse:1.45463\tvalid-rmse:2.22072\n",
      "[300]\ttrain-rmse:1.08143\tvalid-rmse:2.02212\n",
      "[400]\ttrain-rmse:0.89078\tvalid-rmse:1.94341\n",
      "[500]\ttrain-rmse:0.78488\tvalid-rmse:1.91182\n",
      "[600]\ttrain-rmse:0.71720\tvalid-rmse:1.90103\n",
      "[700]\ttrain-rmse:0.66660\tvalid-rmse:1.89830\n",
      "[800]\ttrain-rmse:0.62889\tvalid-rmse:1.89616\n",
      "[851]\ttrain-rmse:0.61251\tvalid-rmse:1.89628\n",
      "[0]\ttrain-rmse:3.58782\tvalid-rmse:3.61897\n",
      "[100]\ttrain-rmse:2.25588\tvalid-rmse:2.35574\n",
      "[200]\ttrain-rmse:1.55487\tvalid-rmse:1.82585\n",
      "[300]\ttrain-rmse:1.19969\tvalid-rmse:1.66090\n",
      "[400]\ttrain-rmse:1.01964\tvalid-rmse:1.62828\n",
      "[472]\ttrain-rmse:0.94170\tvalid-rmse:1.62910\n",
      "[0]\ttrain-rmse:3.57088\tvalid-rmse:3.68076\n",
      "[100]\ttrain-rmse:2.26806\tvalid-rmse:2.34704\n",
      "[200]\ttrain-rmse:1.58699\tvalid-rmse:1.69685\n",
      "[300]\ttrain-rmse:1.24782\tvalid-rmse:1.43277\n",
      "[400]\ttrain-rmse:1.07728\tvalid-rmse:1.34391\n",
      "[500]\ttrain-rmse:0.97983\tvalid-rmse:1.32195\n",
      "[587]\ttrain-rmse:0.91628\tvalid-rmse:1.31819\n",
      "[0]\ttrain-rmse:3.77898\tvalid-rmse:3.79647\n",
      "[100]\ttrain-rmse:2.38423\tvalid-rmse:2.54407\n",
      "[200]\ttrain-rmse:1.65216\tvalid-rmse:1.95706\n",
      "[300]\ttrain-rmse:1.28620\tvalid-rmse:1.71633\n",
      "[400]\ttrain-rmse:1.10150\tvalid-rmse:1.62861\n",
      "[500]\ttrain-rmse:0.99549\tvalid-rmse:1.59734\n",
      "[600]\ttrain-rmse:0.91602\tvalid-rmse:1.58850\n",
      "[700]\ttrain-rmse:0.85381\tvalid-rmse:1.57825\n",
      "[800]\ttrain-rmse:0.80364\tvalid-rmse:1.56845\n",
      "[900]\ttrain-rmse:0.76062\tvalid-rmse:1.56534\n",
      "[1000]\ttrain-rmse:0.72033\tvalid-rmse:1.56246\n",
      "[1100]\ttrain-rmse:0.68330\tvalid-rmse:1.55890\n",
      "[1181]\ttrain-rmse:0.65297\tvalid-rmse:1.55853\n",
      "[0]\ttrain-rmse:3.84977\tvalid-rmse:3.50279\n",
      "[100]\ttrain-rmse:2.43801\tvalid-rmse:2.22150\n",
      "[200]\ttrain-rmse:1.70736\tvalid-rmse:1.62198\n",
      "[300]\ttrain-rmse:1.34434\tvalid-rmse:1.39692\n",
      "[400]\ttrain-rmse:1.16070\tvalid-rmse:1.33891\n",
      "[500]\ttrain-rmse:1.05762\tvalid-rmse:1.33803\n",
      "[502]\ttrain-rmse:1.05571\tvalid-rmse:1.33797\n",
      "[0]\ttrain-rmse:3.73232\tvalid-rmse:3.97644\n",
      "[100]\ttrain-rmse:2.31661\tvalid-rmse:2.81400\n",
      "[200]\ttrain-rmse:1.56232\tvalid-rmse:2.28413\n",
      "[300]\ttrain-rmse:1.17839\tvalid-rmse:2.07246\n",
      "[400]\ttrain-rmse:0.98358\tvalid-rmse:1.98826\n",
      "[500]\ttrain-rmse:0.87452\tvalid-rmse:1.95758\n",
      "[600]\ttrain-rmse:0.80175\tvalid-rmse:1.94851\n",
      "[700]\ttrain-rmse:0.74897\tvalid-rmse:1.94639\n",
      "[765]\ttrain-rmse:0.72081\tvalid-rmse:1.94645\n",
      "[0]\ttrain-rmse:3.78245\tvalid-rmse:3.78539\n",
      "[100]\ttrain-rmse:2.38446\tvalid-rmse:2.45885\n",
      "[200]\ttrain-rmse:1.65079\tvalid-rmse:1.91064\n",
      "[300]\ttrain-rmse:1.27868\tvalid-rmse:1.75071\n",
      "[400]\ttrain-rmse:1.08914\tvalid-rmse:1.73058\n",
      "[438]\ttrain-rmse:1.04235\tvalid-rmse:1.73425\n",
      "[0]\ttrain-rmse:3.76396\tvalid-rmse:3.85423\n",
      "[100]\ttrain-rmse:2.39931\tvalid-rmse:2.45794\n",
      "[200]\ttrain-rmse:1.68674\tvalid-rmse:1.78398\n",
      "[300]\ttrain-rmse:1.33554\tvalid-rmse:1.51189\n",
      "[400]\ttrain-rmse:1.16005\tvalid-rmse:1.42088\n",
      "[500]\ttrain-rmse:1.05903\tvalid-rmse:1.39654\n",
      "[587]\ttrain-rmse:0.99565\tvalid-rmse:1.39592\n",
      "[0]\ttrain-rmse:3.95223\tvalid-rmse:3.93553\n",
      "[100]\ttrain-rmse:2.49521\tvalid-rmse:2.62499\n",
      "[200]\ttrain-rmse:1.72939\tvalid-rmse:2.01379\n",
      "[300]\ttrain-rmse:1.34651\tvalid-rmse:1.76686\n",
      "[400]\ttrain-rmse:1.15152\tvalid-rmse:1.67848\n",
      "[500]\ttrain-rmse:1.04046\tvalid-rmse:1.64630\n",
      "[600]\ttrain-rmse:0.95550\tvalid-rmse:1.64136\n",
      "[700]\ttrain-rmse:0.88999\tvalid-rmse:1.63137\n",
      "[800]\ttrain-rmse:0.83776\tvalid-rmse:1.62248\n",
      "[900]\ttrain-rmse:0.79378\tvalid-rmse:1.62188\n",
      "[1000]\ttrain-rmse:0.75118\tvalid-rmse:1.61878\n",
      "[1100]\ttrain-rmse:0.71275\tvalid-rmse:1.61522\n",
      "[1170]\ttrain-rmse:0.68644\tvalid-rmse:1.61596\n",
      "[0]\ttrain-rmse:4.01723\tvalid-rmse:3.66543\n",
      "[100]\ttrain-rmse:2.54392\tvalid-rmse:2.33480\n",
      "[200]\ttrain-rmse:1.77875\tvalid-rmse:1.71028\n",
      "[300]\ttrain-rmse:1.39729\tvalid-rmse:1.47870\n",
      "[400]\ttrain-rmse:1.20340\tvalid-rmse:1.41975\n",
      "[500]\ttrain-rmse:1.09480\tvalid-rmse:1.42003\n",
      "[502]\ttrain-rmse:1.09287\tvalid-rmse:1.42028\n",
      "[0]\ttrain-rmse:3.89231\tvalid-rmse:4.16728\n",
      "[100]\ttrain-rmse:2.41663\tvalid-rmse:2.95819\n",
      "[200]\ttrain-rmse:1.62879\tvalid-rmse:2.40406\n",
      "[300]\ttrain-rmse:1.22644\tvalid-rmse:2.18208\n",
      "[400]\ttrain-rmse:1.02149\tvalid-rmse:2.09178\n",
      "[500]\ttrain-rmse:0.90689\tvalid-rmse:2.05833\n",
      "[600]\ttrain-rmse:0.83159\tvalid-rmse:2.04698\n",
      "[700]\ttrain-rmse:0.77670\tvalid-rmse:2.04371\n",
      "[800]\ttrain-rmse:0.73389\tvalid-rmse:2.04369\n",
      "[830]\ttrain-rmse:0.72250\tvalid-rmse:2.04333\n",
      "[0]\ttrain-rmse:3.94872\tvalid-rmse:3.95226\n",
      "[100]\ttrain-rmse:2.48771\tvalid-rmse:2.56425\n",
      "[200]\ttrain-rmse:1.72021\tvalid-rmse:1.98609\n",
      "[300]\ttrain-rmse:1.32854\tvalid-rmse:1.81479\n",
      "[400]\ttrain-rmse:1.12891\tvalid-rmse:1.79127\n",
      "[438]\ttrain-rmse:1.07948\tvalid-rmse:1.79454\n",
      "[0]\ttrain-rmse:3.92855\tvalid-rmse:4.02728\n",
      "[100]\ttrain-rmse:2.50181\tvalid-rmse:2.57205\n",
      "[200]\ttrain-rmse:1.75578\tvalid-rmse:1.87710\n",
      "[300]\ttrain-rmse:1.38588\tvalid-rmse:1.60410\n",
      "[400]\ttrain-rmse:1.20064\tvalid-rmse:1.51174\n",
      "[500]\ttrain-rmse:1.09403\tvalid-rmse:1.48707\n",
      "[600]\ttrain-rmse:1.01758\tvalid-rmse:1.48693\n",
      "[624]\ttrain-rmse:1.00110\tvalid-rmse:1.48783\n",
      "[0]\ttrain-rmse:4.20341\tvalid-rmse:4.08965\n",
      "[100]\ttrain-rmse:2.73634\tvalid-rmse:2.74017\n",
      "[200]\ttrain-rmse:1.98089\tvalid-rmse:2.10449\n",
      "[300]\ttrain-rmse:1.60772\tvalid-rmse:1.84113\n",
      "[400]\ttrain-rmse:1.41231\tvalid-rmse:1.74536\n",
      "[500]\ttrain-rmse:1.29382\tvalid-rmse:1.71033\n",
      "[600]\ttrain-rmse:1.20271\tvalid-rmse:1.69760\n",
      "[700]\ttrain-rmse:1.12508\tvalid-rmse:1.68365\n",
      "[800]\ttrain-rmse:1.06360\tvalid-rmse:1.67389\n",
      "[883]\ttrain-rmse:1.01404\tvalid-rmse:1.67339\n",
      "[0]\ttrain-rmse:4.17887\tvalid-rmse:4.19403\n",
      "[100]\ttrain-rmse:2.64044\tvalid-rmse:3.03712\n",
      "[200]\ttrain-rmse:1.83966\tvalid-rmse:2.57897\n",
      "[300]\ttrain-rmse:1.43807\tvalid-rmse:2.43839\n",
      "[400]\ttrain-rmse:1.23328\tvalid-rmse:2.41272\n",
      "[448]\ttrain-rmse:1.17303\tvalid-rmse:2.41512\n",
      "[0]\ttrain-rmse:4.14502\tvalid-rmse:4.32150\n",
      "[100]\ttrain-rmse:2.66068\tvalid-rmse:3.06093\n",
      "[200]\ttrain-rmse:1.88625\tvalid-rmse:2.48080\n",
      "[300]\ttrain-rmse:1.50018\tvalid-rmse:2.24715\n",
      "[400]\ttrain-rmse:1.29955\tvalid-rmse:2.15549\n",
      "[500]\ttrain-rmse:1.18222\tvalid-rmse:2.12163\n",
      "[600]\ttrain-rmse:1.09590\tvalid-rmse:2.10906\n",
      "[700]\ttrain-rmse:1.02503\tvalid-rmse:2.10813\n",
      "[741]\ttrain-rmse:1.00115\tvalid-rmse:2.10876\n",
      "[0]\ttrain-rmse:4.19661\tvalid-rmse:4.12171\n",
      "[100]\ttrain-rmse:2.72717\tvalid-rmse:2.69525\n",
      "[200]\ttrain-rmse:1.97058\tvalid-rmse:2.08992\n",
      "[300]\ttrain-rmse:1.59081\tvalid-rmse:1.90732\n",
      "[400]\ttrain-rmse:1.39366\tvalid-rmse:1.87744\n",
      "[440]\ttrain-rmse:1.34019\tvalid-rmse:1.87970\n",
      "[0]\ttrain-rmse:4.17552\tvalid-rmse:4.20099\n",
      "[100]\ttrain-rmse:2.73509\tvalid-rmse:2.69731\n",
      "[200]\ttrain-rmse:1.99249\tvalid-rmse:1.98842\n",
      "[300]\ttrain-rmse:1.62872\tvalid-rmse:1.70756\n",
      "[400]\ttrain-rmse:1.44077\tvalid-rmse:1.61154\n",
      "[500]\ttrain-rmse:1.32286\tvalid-rmse:1.58651\n",
      "[597]\ttrain-rmse:1.23404\tvalid-rmse:1.58781\n",
      "[0]\ttrain-rmse:4.36361\tvalid-rmse:4.24557\n",
      "[100]\ttrain-rmse:2.83267\tvalid-rmse:2.84094\n",
      "[200]\ttrain-rmse:2.04272\tvalid-rmse:2.17730\n",
      "[300]\ttrain-rmse:1.65067\tvalid-rmse:1.90156\n",
      "[400]\ttrain-rmse:1.44613\tvalid-rmse:1.80347\n",
      "[500]\ttrain-rmse:1.32245\tvalid-rmse:1.76605\n",
      "[600]\ttrain-rmse:1.22923\tvalid-rmse:1.75432\n",
      "[700]\ttrain-rmse:1.14914\tvalid-rmse:1.74103\n",
      "[800]\ttrain-rmse:1.08538\tvalid-rmse:1.73066\n",
      "[900]\ttrain-rmse:1.02714\tvalid-rmse:1.73057\n",
      "[969]\ttrain-rmse:0.98889\tvalid-rmse:1.73246\n",
      "[0]\ttrain-rmse:4.34140\tvalid-rmse:4.34102\n",
      "[100]\ttrain-rmse:2.73885\tvalid-rmse:3.12920\n",
      "[200]\ttrain-rmse:1.90228\tvalid-rmse:2.64651\n",
      "[300]\ttrain-rmse:1.48115\tvalid-rmse:2.49624\n",
      "[400]\ttrain-rmse:1.26526\tvalid-rmse:2.46630\n",
      "[447]\ttrain-rmse:1.20288\tvalid-rmse:2.46860\n",
      "[0]\ttrain-rmse:4.30579\tvalid-rmse:4.47516\n",
      "[100]\ttrain-rmse:2.75829\tvalid-rmse:3.15853\n",
      "[200]\ttrain-rmse:1.95039\tvalid-rmse:2.54819\n",
      "[300]\ttrain-rmse:1.54553\tvalid-rmse:2.30143\n",
      "[400]\ttrain-rmse:1.33496\tvalid-rmse:2.20538\n"
     ]
    }
   ],
   "source": [
    "# Run the full XGBoost pipeline\n",
    "models, oof_preds, test_preds, nll_score, submission = xgb_pipeline(\n",
    "    X_features, y, X_features_test, optimize=True\n",
    ")\n",
    "\n",
    "print(f\"Final NLL Score: {nll_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "feature_names = train_features.drop('geology_id', axis=1).columns.tolist()\n",
    "visualize_feature_importance(models, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11372669,
     "sourceId": 95697,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
